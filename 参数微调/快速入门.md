> 用 hugging face 做参数微调
>

[GitHub - huggingface/peft: 🤗 PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.](https://github.com/huggingface/peft)

<font style="background-color:rgba(255, 255, 255, 0);">Install PEFT from pip:</font>

```python
pip install peft
```

<font style="background-color:rgba(255, 255, 255, 0);">Prepare a model for training with a PEFT method such as LoRA by wrapping the base model and PEFT configuration with</font><font style="background-color:rgba(255, 255, 255, 0);"> </font>`<font style="background-color:rgba(255, 255, 255, 0);">get_peft_model</font>`<font style="background-color:rgba(255, 255, 255, 0);">. For the bigscience/mt0-large model, you're only training 0.19% of the parameters!</font>

```python
from transformers import AutoModelForSeq2SeqLM
from peft import get_peft_config, get_peft_model, LoraConfig, TaskType
model_name_or_path = "bigscience/mt0-large"
tokenizer_name_or_path = "bigscience/mt0-large"

peft_config = LoraConfig(
    task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1
)

model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)
model = get_peft_model(model, peft_config)
model.print_trainable_parameters()
"trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282"
```

<font style="background-color:rgba(255, 255, 255, 0);">To load a PEFT model for inference:</font>

```python
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer
import torch

model = AutoPeftModelForCausalLM.from_pretrained("ybelkada/opt-350m-lora").to("cuda")
tokenizer = AutoTokenizer.from_pretrained("facebook/opt-350m")

model.eval()
inputs = tokenizer("Preheat the oven to 350 degrees and place the cookie dough", return_tensors="pt")

outputs = model.generate(input_ids=inputs["input_ids"].to("cuda"), max_new_tokens=50)
print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])

"Preheat the oven to 350 degrees and place the cookie dough in the center of the oven. In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon. In a separate bowl, combine the egg yolks, sugar, and vanilla."
```

<font style="background-color:rgba(255, 255, 255, 0);">  
</font>

---

在 Hugging Face 上进行 Parameter-efficient Fine-Tuning (PEFT) 是一种在不需要调整整个模型的参数情况下进行微调的技术。PEFT 旨在通过少量的参数更新来优化模型，同时尽量减少计算和存储开销。最常见的 PEFT 技术包括 LoRA (Low-Rank Adaptation)、Adapter、Prompt Tuning 和 Prefix Tuning 等。

在 Hugging Face 中，PEFT 可以通过几个不同的库和工具来实现，比如 `peft` 库，或者通过 `transformers` 库结合自定义的 PEFT 方法。

### 1. 安装必要的库
首先，确保你已经安装了 Hugging Face 的 `transformers` 库和 `peft` 库：

```bash
pip install transformers
pip install peft
```

### 2. 使用 LoRA（Low-Rank Adaptation）
LoRA 是 PEFT 中一种非常流行的技术，它通过引入低秩矩阵来在每一层中修改权重矩阵，从而在不更新大量参数的情况下完成微调。

#### 2.1 加载预训练模型
使用 Hugging Face 的 `transformers` 加载预训练模型（比如 GPT 或 BERT）：

```python
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# 以 BERT 为例
model_name = "bert-base-uncased"
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

#### 2.2 配置 LoRA
在 `peft` 库中，你可以通过 `LoraConfig` 和 `get_peft_model` 来配置 LoRA 参数。

```python
from peft import LoraConfig, get_peft_model

# 配置 LoRA 参数
lora_config = LoraConfig(
    r=8,  # 低秩矩阵的秩
    lora_alpha=32,  # LoRA 损失系数
    lora_dropout=0.1,  # Dropout 比例
    bias="none",  # 控制是否调整偏置
)

# 通过 LoRA 进行微调
peft_model = get_peft_model(model, lora_config)
```

#### 2.3 微调模型
现在，你可以像通常一样进行模型微调。你只需要在训练过程中微调 LoRA 参数，而无需调整模型的所有参数。

```python
from transformers import Trainer, TrainingArguments

# 配置训练参数
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=10,
)

# 定义 Trainer
trainer = Trainer(
    model=peft_model,
    args=training_args,
    train_dataset=train_dataset,  # 需要准备好的训练数据集
    eval_dataset=eval_dataset,    # 需要准备好的验证数据集
)

# 开始训练
trainer.train()
```

#### 2.4 保存模型
训练完成后，你可以保存微调后的模型：

```python
peft_model.save_pretrained("./peft_model")
```

### 3. 使用其他 PEFT 技术
除了 LoRA，你还可以使用 Adapter、Prompt Tuning 等其他 PEFT 技术。在 Hugging Face 中，通常是通过配置不同的 `peft` 库或者 `transformers` 配置来实现。

例如，使用 Adapter：

```python
from transformers import AdapterConfig

# 配置 Adapter
adapter_config = AdapterConfig.load("pfeiffer")

# 将 Adapter 添加到模型中
model.add_adapter("my_adapter", config=adapter_config)
model.train_adapter("my_adapter")
```

### 总结
通过 Hugging Face 进行 PEFT 微调，关键是选择合适的技术（例如 LoRA 或 Adapter），然后加载预训练模型并配置相应的 PEFT 参数。微调过程中的大部分计算只会涉及这些额外的参数，而不需要对原始模型的所有参数进行调整，从而提高了训练效率和节省了资源。

