> 大语言模型推理框架 LLM Inference Framework 
>
> LLM Deployment Engine 部署与配置引擎
>

# ⭐vllm
+ [vllm-project/vllm](https://github.com/vllm-project/vllm) ![](https://img.shields.io/github/stars/vllm-project/vllm?style=social) : A high-throughput and memory-efficient inference and serving engine for LLMs. [vllm.readthedocs.io](https://vllm.readthedocs.io/en/latest/)

# MLC LLM
+ [MLC LLM](https://github.com/mlc-ai/mlc-llm) ![](https://img.shields.io/github/stars/mlc-ai/mlc-llm?style=social) : Enable everyone to develop, optimize and deploy AI models natively on everyone's devices. [mlc.ai/mlc-llm](https://mlc.ai/mlc-llm/)

# Lamini
+ [Lamini](https://github.com/lamini-ai/lamini) ![](https://img.shields.io/github/stars/lamini-ai/lamini?style=social) : Lamini: The LLM engine for rapidly customizing models 🦙.

# Self-LLM
+ [datawhalechina/self-llm](https://github.com/datawhalechina/self-llm) ![](https://img.shields.io/github/stars/datawhalechina/self-llm?style=social) :  《开源大模型食用指南》基于Linux环境快速部署开源大模型，更适合中国宝宝的部署教程。



