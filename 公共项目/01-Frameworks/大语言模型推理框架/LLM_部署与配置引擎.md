> å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ¡†æ¶ LLM Inference Framework 
>
> LLM Deployment Engine éƒ¨ç½²ä¸é…ç½®å¼•æ“
>

# â­vllm
+ [vllm-project/vllm](https://github.com/vllm-project/vllm) ![](https://img.shields.io/github/stars/vllm-project/vllm?style=social) : A high-throughput and memory-efficient inference and serving engine for LLMs. [vllm.readthedocs.io](https://vllm.readthedocs.io/en/latest/)

# MLC LLM
+ [MLC LLM](https://github.com/mlc-ai/mlc-llm) ![](https://img.shields.io/github/stars/mlc-ai/mlc-llm?style=social) : Enable everyone to develop, optimize and deploy AI models natively on everyone's devices. [mlc.ai/mlc-llm](https://mlc.ai/mlc-llm/)

# Lamini
+ [Lamini](https://github.com/lamini-ai/lamini) ![](https://img.shields.io/github/stars/lamini-ai/lamini?style=social) : Lamini: The LLM engine for rapidly customizing models ğŸ¦™.

# Self-LLM
+ [datawhalechina/self-llm](https://github.com/datawhalechina/self-llm) ![](https://img.shields.io/github/stars/datawhalechina/self-llm?style=social) :  ã€Šå¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—ã€‹åŸºäºLinuxç¯å¢ƒå¿«é€Ÿéƒ¨ç½²å¼€æºå¤§æ¨¡å‹ï¼Œæ›´é€‚åˆä¸­å›½å®å®çš„éƒ¨ç½²æ•™ç¨‹ã€‚



