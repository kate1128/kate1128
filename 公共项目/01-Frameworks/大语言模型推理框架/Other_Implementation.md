> 大语言模型推理框架 LLM Inference Framework 
>

### C Implementation
+ [llm.c](https://github.com/karpathy/llm.c) ![](https://img.shields.io/github/stars/karpathy/llm.c?style=social) : LLM training in simple, pure C/CUDA. There is no need for 245MB of PyTorch or 107MB of cPython. For example, training GPT-2 (CPU, fp32) is ~1,000 lines of clean code in a single file. It compiles and runs instantly, and exactly matches the PyTorch reference implementation.
+ [llama2.c](https://github.com/karpathy/llama2.c) ![](https://img.shields.io/github/stars/karpathy/llama2.c?style=social) : Inference Llama 2 in one file of pure C. Train the Llama 2 LLM architecture in PyTorch then inference it with one simple 700-line C file (run.c).

### CPP Implementation
+ [TensorRT](https://github.com/NVIDIA/TensorRT) ![](https://img.shields.io/github/stars/NVIDIA/TensorRT?style=social) : NVIDIA® TensorRT™ is an SDK for high-performance deep learning inference on NVIDIA GPUs. This repository contains the open source components of TensorRT. [developer.nvidia.com/tensorrt](https://developer.nvidia.com/tensorrt)
+ [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) ![](https://img.shields.io/github/stars/NVIDIA/TensorRT-LLM?style=social) : TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines. [nvidia.github.io/TensorRT-LLM](https://nvidia.github.io/TensorRT-LLM)
+ [gemma.cpp](https://github.com/google/gemma.cpp) ![](https://img.shields.io/github/stars/google/gemma.cpp?style=social) :  gemma.cpp is a lightweight, standalone C++ inference engine for the Gemma foundation models from Google.
+ [llama.cpp](https://github.com/ggerganov/llama.cpp) ![](https://img.shields.io/github/stars/ggerganov/llama.cpp?style=social) : Inference of [LLaMA](https://github.com/facebookresearch/llama) model in pure C/C++.
+ [whisper.cpp](https://github.com/ggerganov/whisper.cpp) ![](https://img.shields.io/github/stars/ggerganov/whisper.cpp?style=social) : High-performance inference of [OpenAI's Whisper](https://github.com/openai/whisper) automatic speech recognition (ASR) model.
+ [ChatGLM.cpp](https://github.com/li-plus/chatglm.cpp) ![](https://img.shields.io/github/stars/li-plus/chatglm.cpp?style=social) : C++ implementation of [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) and [ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B).
+ [MegEngine/InferLLM](https://github.com/MegEngine/InferLLM) ![](https://img.shields.io/github/stars/MegEngine/InferLLM?style=social) : InferLLM is a lightweight LLM model inference framework that mainly references and borrows from the llama.cpp project.
+ [DeployAI/nndeploy](https://github.com/DeployAI/nndeploy) ![](https://img.shields.io/github/stars/DeployAI/nndeploy?style=social) : nndeploy是一款模型端到端部署框架。以多端推理以及基于有向无环图模型部署为内核，致力为用户提供跨平台、简单易用、高性能的模型部署体验。[nndeploy-zh.readthedocs.io/zh/latest/](https://nndeploy-zh.readthedocs.io/zh/latest/)
+ [zjhellofss/KuiperInfer (自制深度学习推理框架)](https://github.com/zjhellofss/KuiperInfer) ![](https://img.shields.io/github/stars/zjhellofss/KuiperInfer?style=social) :  带你从零实现一个高性能的深度学习推理库，支持llama 、Unet、Yolov5、Resnet等模型的推理。Implement a high-performance deep learning inference library step by step.
+ [skeskinen/llama-lite](https://github.com/skeskinen/llama-lite) ![](https://img.shields.io/github/stars/skeskinen/llama-lite?style=social) : Embeddings focused small version of Llama NLP model.
+ [Const-me/Whisper](https://github.com/Const-me/Whisper) ![](https://img.shields.io/github/stars/Const-me/Whisper?style=social) : High-performance GPGPU inference of OpenAI's Whisper automatic speech recognition (ASR) model.
+ [wangzhaode/ChatGLM-MNN](https://github.com/wangzhaode/ChatGLM-MNN) ![](https://img.shields.io/github/stars/wangzhaode/ChatGLM-MNN?style=social) : Pure C++, Easy Deploy ChatGLM-6B.
+ [ztxz16/fastllm](https://github.com/ztxz16/fastllm) ![](https://img.shields.io/github/stars/ztxz16/fastllm?style=social) : 纯c++实现，无第三方依赖的大模型库，支持CUDA加速，目前支持国产大模型ChatGLM-6B，MOSS; 可以在安卓设备上流畅运行ChatGLM-6B。
+ [davidar/eigenGPT](https://github.com/davidar/eigenGPT) ![](https://img.shields.io/github/stars/davidar/eigenGPT?style=social) : Minimal C++ implementation of GPT2.
+ [Tlntin/Qwen-TensorRT-LLM](https://github.com/Tlntin/Qwen-TensorRT-LLM) ![](https://img.shields.io/github/stars/Tlntin/Qwen-TensorRT-LLM?style=social) : 使用TRT-LLM完成对Qwen-7B-Chat实现推理加速。
+ [FeiGeChuanShu/trt2023](https://github.com/FeiGeChuanShu/trt2023) ![](https://img.shields.io/github/stars/FeiGeChuanShu/trt2023?style=social) : NVIDIA TensorRT Hackathon 2023复赛选题：通义千问Qwen-7B用TensorRT-LLM模型搭建及优化。
+ [TRT2022/trtllm-llama](https://github.com/TRT2022/trtllm-llama) ![](https://img.shields.io/github/stars/TRT2022/trtllm-llama?style=social) : ☢️ TensorRT 2023复赛——基于TensorRT-LLM的Llama模型推断加速优化。
+ [AmeyaWagh/llama2.cpp](https://github.com/AmeyaWagh/llama2.cpp) ![](https://img.shields.io/github/stars/AmeyaWagh/llama2.cpp?style=social) : Inference Llama 2 in C++.

### Python Implementation
+ [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) ![](https://img.shields.io/github/stars/abetlen/llama-cpp-python?style=social) : Python bindings for llama.cpp. [llama-cpp-python.readthedocs.io](https://llama-cpp-python.readthedocs.io/)
+ [ggml-python](https://github.com/abetlen/ggml-python) ![](https://img.shields.io/github/stars/abetlen/ggml-python?style=social) : Python bindings for ggml. [ggml-python.readthedocs.io](https://ggml-python.readthedocs.io/)

### Mojo Implementation
+ [llama2.mojo](https://github.com/tairov/llama2.mojo) ![](https://img.shields.io/github/stars/tairov/llama2.mojo?style=social) : Inference Llama 2 in one file of pure 🔥
+ [dorjeduck/llm.mojo](https://github.com/dorjeduck/llm.mojo) ![](https://img.shields.io/github/stars/dorjeduck/llm.mojo?style=social) : port of Andrjey Karpathy's llm.c to Mojo.

### Rust Implementation
+ [Candle](https://github.com/huggingface/candle) ![](https://img.shields.io/github/stars/huggingface/candle?style=social) : Minimalist ML framework for Rust.
+ [Safetensors](https://github.com/huggingface/safetensors) ![](https://img.shields.io/github/stars/huggingface/safetensors?style=social) : Simple, safe way to store and distribute tensors. [huggingface.co/docs/safetensors](https://huggingface.co/docs/safetensors/index)
+ [Tokenizers](https://github.com/huggingface/tokenizers) ![](https://img.shields.io/github/stars/huggingface/tokenizers?style=social) : 💥 Fast State-of-the-Art Tokenizers optimized for Research and Production. [huggingface.co/docs/tokenizers](https://huggingface.co/docs/tokenizers/index)
+ [Burn](https://github.com/burn-rs/burn) ![](https://img.shields.io/github/stars/burn-rs/burn?style=social) : Burn - A Flexible and Comprehensive Deep Learning Framework in Rust. [burn-rs.github.io/](https://burn-rs.github.io/)
+ [dfdx](https://github.com/coreylowman/dfdx) ![](https://img.shields.io/github/stars/coreylowman/dfdx?style=social) : Deep learning in Rust, with shape checked tensors and neural networks.
+ [luminal](https://github.com/jafioti/luminal) ![](https://img.shields.io/github/stars/jafioti/luminal?style=social) : Deep learning at the speed of light. [www.luminalai.com/](https://www.luminalai.com/)
+ [crabml](https://github.com/crabml/crabml) ![](https://img.shields.io/github/stars/crabml/crabml?style=social) : crabml is focusing on the reimplementation of GGML using the Rust programming language.
+ [TensorFlow Rust](https://github.com/tensorflow/rust) ![](https://img.shields.io/github/stars/tensorflow/rust?style=social) : Rust language bindings for TensorFlow.
+ [tch-rs](https://github.com/LaurentMazare/tch-rs) ![](https://img.shields.io/github/stars/LaurentMazare/tch-rs?style=social) : Rust bindings for the C++ api of PyTorch.
+ [rustai-solutions/candle_demo_openchat_35](https://github.com/rustai-solutions/candle_demo_openchat_35) ![](https://img.shields.io/github/stars/rustai-solutions/candle_demo_openchat_35?style=social) : candle_demo_openchat_35.
+ [llama2.rs](https://github.com/srush/llama2.rs) ![](https://img.shields.io/github/stars/srush/llama2.rs?style=social) : A fast llama2 decoder in pure Rust.
+ [Llama2-burn](https://github.com/Gadersd/llama2-burn) ![](https://img.shields.io/github/stars/Gadersd/llama2-burn?style=social) : Llama2 LLM ported to Rust burn.
+ [gaxler/llama2.rs](https://github.com/gaxler/llama2.rs) ![](https://img.shields.io/github/stars/gaxler/llama2.rs?style=social) : Inference Llama 2 in one file of pure Rust 🦀
+ [whisper-burn](https://github.com/Gadersd/whisper-burn) ![](https://img.shields.io/github/stars/Gadersd/whisper-burn?style=social) : A Rust implementation of OpenAI's Whisper model using the burn framework.
+ [stable-diffusion-burn](https://github.com/Gadersd/stable-diffusion-burn) ![](https://img.shields.io/github/stars/Gadersd/stable-diffusion-burn?style=social) : Stable Diffusion v1.4 ported to Rust's burn framework.
+ [coreylowman/llama-dfdx](https://github.com/coreylowman/llama-dfdx) ![](https://img.shields.io/github/stars/coreylowman/llama-dfdx?style=social) : [LLaMa 7b](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) with CUDA acceleration implemented in rust. Minimal GPU memory needed!
+ [tazz4843/whisper-rs](https://github.com/tazz4843/whisper-rs) ![](https://img.shields.io/github/stars/tazz4843/whisper-rs?style=social) : Rust bindings to [whisper.cpp](https://github.com/ggerganov/whisper.cpp).
+ [rustformers/llm](https://github.com/rustformers/llm) ![](https://img.shields.io/github/stars/rustformers/llm?style=social) : Run inference for Large Language Models on CPU, with Rust 🦀🚀🦙.
+ [Chidori](https://github.com/ThousandBirdsInc/chidori) ![](https://img.shields.io/github/stars/ThousandBirdsInc/chidori?style=social) : A reactive runtime for building durable AI agents. [docs.thousandbirds.ai](https://docs.thousandbirds.ai/).
+ [llm-chain](https://github.com/sobelio/llm-chain) ![](https://img.shields.io/github/stars/sobelio/llm-chain?style=social) : llm-chain is a collection of Rust crates designed to help you work with Large Language Models (LLMs) more effectively. [llm-chain.xyz](https://llm-chain.xyz/)
+ [Abraxas-365/langchain-rust](https://github.com/Abraxas-365/langchain-rust) ![](https://img.shields.io/github/stars/Abraxas-365/langchain-rust?style=social) : 🦜️🔗LangChain for Rust, the easiest way to write LLM-based programs in Rust.
+ [Atome-FE/llama-node](https://github.com/Atome-FE/llama-node) ![](https://img.shields.io/github/stars/Atome-FE/llama-node?style=social) : Believe in AI democratization. llama for nodejs backed by llama-rs and llama.cpp, work locally on your laptop CPU. support llama/alpaca/gpt4all/vicuna model. [www.npmjs.com/package/llama-node](https://www.npmjs.com/package/llama-node)
+ [Noeda/rllama](https://github.com/Noeda/rllama) ![](https://img.shields.io/github/stars/Noeda/rllama?style=social) : Rust+OpenCL+AVX2 implementation of LLaMA inference code.
+ [lencx/ChatGPT](https://github.com/lencx/ChatGPT) ![](https://img.shields.io/github/stars/lencx/ChatGPT?style=social) : 🔮 ChatGPT Desktop Application (Mac, Windows and Linux). [NoFWL](https://app.nofwl.com/).
+ [Synaptrix/ChatGPT-Desktop](https://github.com/Synaptrix/ChatGPT-Desktop) ![](https://img.shields.io/github/stars/Synaptrix/ChatGPT-Desktop?style=social) : Fuel your productivity with ChatGPT-Desktop - Blazingly fast and supercharged!
+ [Poordeveloper/chatgpt-app](https://github.com/Poordeveloper/chatgpt-app) ![](https://img.shields.io/github/stars/Poordeveloper/chatgpt-app?style=social) : A ChatGPT App for all platforms. Built with Rust + Tauri + Vue + Axum.
+ [mxismean/chatgpt-app](https://github.com/mxismean/chatgpt-app) ![](https://img.shields.io/github/stars/mxismean/chatgpt-app?style=social) : Tauri 项目：ChatGPT App.
+ [sonnylazuardi/chat-ai-desktop](https://github.com/sonnylazuardi/chat-ai-desktop) ![](https://img.shields.io/github/stars/sonnylazuardi/chat-ai-desktop?style=social) : Chat AI Desktop App. Unofficial ChatGPT desktop app for Mac & Windows menubar using Tauri & Rust.
+ [yetone/openai-translator](https://github.com/yetone/openai-translator) ![](https://img.shields.io/github/stars/yetone/openai-translator?style=social) : The translator that does more than just translation - powered by OpenAI.
+ [m1guelpf/browser-agent](https://github.com/m1guelpf/browser-agent) ![](https://img.shields.io/github/stars/m1guelpf/browser-agent?style=social) : A browser AI agent, using GPT-4. [docs.rs/browser-agent](https://docs.rs/browser-agent/latest/browser_agent/)
+ [sigoden/aichat](https://github.com/sigoden/aichat) ![](https://img.shields.io/github/stars/sigoden/aichat?style=social) : Using ChatGPT/GPT-3.5/GPT-4 in the terminal.
+ [uiuifree/rust-openai-chatgpt-api](https://github.com/uiuifree/rust-openai-chatgpt-api) ![](https://img.shields.io/github/stars/uiuifree/rust-openai-chatgpt-api?style=social) : "rust-openai-chatgpt-api" is a Rust library for accessing the ChatGPT API, a powerful NLP platform by OpenAI. The library provides a simple and efficient interface for sending requests and receiving responses, including chat. It uses reqwest and serde for HTTP requests and JSON serialization.
+ [1595901624/gpt-aggregated-edition](https://github.com/1595901624/gpt-aggregated-edition) ![](https://img.shields.io/github/stars/1595901624/gpt-aggregated-edition?style=social) : 聚合ChatGPT官方版、ChatGPT免费版、文心一言、Poe、chatchat等多平台，支持自定义导入平台。
+ [Cormanz/smartgpt](https://github.com/Cormanz/smartgpt) ![](https://img.shields.io/github/stars/Cormanz/smartgpt?style=social) : A program that provides LLMs with the ability to complete complex tasks using plugins.
+ [femtoGPT](https://github.com/keyvank/femtoGPT) ![](https://img.shields.io/github/stars/keyvank/femtoGPT?style=social) : femtoGPT is a pure Rust implementation of a minimal Generative Pretrained Transformer. [discord.gg/wTJFaDVn45](https://github.com/keyvank/femtoGPT)
+ [shafishlabs/llmchain-rs](https://github.com/shafishlabs/llmchain-rs) ![](https://img.shields.io/github/stars/shafishlabs/llmchain-rs?style=social) : 🦀Rust + Large Language Models - Make AI Services Freely and Easily. Inspired by LangChain.
+ [flaneur2020/llama2.rs](https://github.com/flaneur2020/llama2.rs) ![](https://img.shields.io/github/stars/flaneur2020/llama2.rs?style=social) : An rust reimplementatin of [https://github.com/karpathy/llama2.c](https://github.com/karpathy/llama2.c).
+ [Heng30/chatbox](https://github.com/Heng30/chatbox) ![](https://img.shields.io/github/stars/Heng30/chatbox?style=social) : A Chatbot for OpenAI ChatGPT. Based on Slint-ui and Rust.
+ [fairjm/dioxus-openai-qa-gui](https://github.com/fairjm/dioxus-openai-qa-gui) ![](https://img.shields.io/github/stars/fairjm/dioxus-openai-qa-gui?style=social) : a simple openai qa desktop app built with dioxus.
+ [purton-tech/bionicgpt](https://github.com/purton-tech/bionicgpt) ![](https://img.shields.io/github/stars/purton-tech/bionicgpt?style=social) : Accelerate LLM adoption in your organisation. Chat with your confidential data safely and securely. [bionic-gpt.com](https://bionic-gpt.com/)
+ [InfiniTensor/transformer-rs](https://github.com/InfiniTensor/transformer-rs) ![](https://img.shields.io/github/stars/InfiniTensor/transformer-rs?style=social) : 从 [YdrMaster/llama2.rs](https://github.com/YdrMaster/llama2.rs) 发展来的手写 transformer 模型项目。

### Zig Implementation
+ [llama2.zig](https://github.com/cgbur/llama2.zig) ![](https://img.shields.io/github/stars/cgbur/llama2.zig?style=social) : Inference Llama 2 in one file of pure Zig.
+ [renerocksai/gpt4all.zig](https://github.com/renerocksai/gpt4all.zig) ![](https://img.shields.io/github/stars/renerocksai/gpt4all.zig?style=social) : ZIG build for a terminal-based chat client for an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMa.
+ [EugenHotaj/zig_inference](https://github.com/EugenHotaj/zig_inference) ![](https://img.shields.io/github/stars/EugenHotaj/zig_inference?style=social) : Neural Network Inference Engine in Zig.



