> å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ¡†æ¶ LLM Inference Framework 
>

### C Implementation
+ [llm.c](https://github.com/karpathy/llm.c) ![](https://img.shields.io/github/stars/karpathy/llm.c?style=social) : LLM training in simple, pure C/CUDA. There is no need for 245MB of PyTorch or 107MB of cPython. For example, training GPT-2 (CPU, fp32) is ~1,000 lines of clean code in a single file. It compiles and runs instantly, and exactly matches the PyTorch reference implementation.
+ [llama2.c](https://github.com/karpathy/llama2.c) ![](https://img.shields.io/github/stars/karpathy/llama2.c?style=social) : Inference Llama 2 in one file of pure C. Train the Llama 2 LLM architecture in PyTorch then inference it with one simple 700-line C file (run.c).

### CPP Implementation
+ [TensorRT](https://github.com/NVIDIA/TensorRT) ![](https://img.shields.io/github/stars/NVIDIA/TensorRT?style=social) : NVIDIAÂ® TensorRTâ„¢ is an SDK for high-performance deep learning inference on NVIDIA GPUs. This repository contains the open source components of TensorRT. [developer.nvidia.com/tensorrt](https://developer.nvidia.com/tensorrt)
+ [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) ![](https://img.shields.io/github/stars/NVIDIA/TensorRT-LLM?style=social) : TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines. [nvidia.github.io/TensorRT-LLM](https://nvidia.github.io/TensorRT-LLM)
+ [gemma.cpp](https://github.com/google/gemma.cpp) ![](https://img.shields.io/github/stars/google/gemma.cpp?style=social) :  gemma.cpp is a lightweight, standalone C++ inference engine for the Gemma foundation models from Google.
+ [llama.cpp](https://github.com/ggerganov/llama.cpp) ![](https://img.shields.io/github/stars/ggerganov/llama.cpp?style=social) : Inference of [LLaMA](https://github.com/facebookresearch/llama) model in pure C/C++.
+ [whisper.cpp](https://github.com/ggerganov/whisper.cpp) ![](https://img.shields.io/github/stars/ggerganov/whisper.cpp?style=social) : High-performance inference of [OpenAI's Whisper](https://github.com/openai/whisper) automatic speech recognition (ASR) model.
+ [ChatGLM.cpp](https://github.com/li-plus/chatglm.cpp) ![](https://img.shields.io/github/stars/li-plus/chatglm.cpp?style=social) : C++ implementation of [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) and [ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B).
+ [MegEngine/InferLLM](https://github.com/MegEngine/InferLLM) ![](https://img.shields.io/github/stars/MegEngine/InferLLM?style=social) : InferLLM is a lightweight LLM model inference framework that mainly references and borrows from the llama.cpp project.
+ [DeployAI/nndeploy](https://github.com/DeployAI/nndeploy) ![](https://img.shields.io/github/stars/DeployAI/nndeploy?style=social) : nndeployæ˜¯ä¸€æ¬¾æ¨¡å‹ç«¯åˆ°ç«¯éƒ¨ç½²æ¡†æ¶ã€‚ä»¥å¤šç«¯æ¨ç†ä»¥åŠåŸºäºæœ‰å‘æ— ç¯å›¾æ¨¡å‹éƒ¨ç½²ä¸ºå†…æ ¸ï¼Œè‡´åŠ›ä¸ºç”¨æˆ·æä¾›è·¨å¹³å°ã€ç®€å•æ˜“ç”¨ã€é«˜æ€§èƒ½çš„æ¨¡å‹éƒ¨ç½²ä½“éªŒã€‚[nndeploy-zh.readthedocs.io/zh/latest/](https://nndeploy-zh.readthedocs.io/zh/latest/)
+ [zjhellofss/KuiperInfer (è‡ªåˆ¶æ·±åº¦å­¦ä¹ æ¨ç†æ¡†æ¶)](https://github.com/zjhellofss/KuiperInfer) ![](https://img.shields.io/github/stars/zjhellofss/KuiperInfer?style=social) :  å¸¦ä½ ä»é›¶å®ç°ä¸€ä¸ªé«˜æ€§èƒ½çš„æ·±åº¦å­¦ä¹ æ¨ç†åº“ï¼Œæ”¯æŒllama ã€Unetã€Yolov5ã€Resnetç­‰æ¨¡å‹çš„æ¨ç†ã€‚Implement a high-performance deep learning inference library step by step.
+ [skeskinen/llama-lite](https://github.com/skeskinen/llama-lite) ![](https://img.shields.io/github/stars/skeskinen/llama-lite?style=social) : Embeddings focused small version of Llama NLP model.
+ [Const-me/Whisper](https://github.com/Const-me/Whisper) ![](https://img.shields.io/github/stars/Const-me/Whisper?style=social) : High-performance GPGPU inference of OpenAI's Whisper automatic speech recognition (ASR) model.
+ [wangzhaode/ChatGLM-MNN](https://github.com/wangzhaode/ChatGLM-MNN) ![](https://img.shields.io/github/stars/wangzhaode/ChatGLM-MNN?style=social) : Pure C++, Easy Deploy ChatGLM-6B.
+ [ztxz16/fastllm](https://github.com/ztxz16/fastllm) ![](https://img.shields.io/github/stars/ztxz16/fastllm?style=social) : çº¯c++å®ç°ï¼Œæ— ç¬¬ä¸‰æ–¹ä¾èµ–çš„å¤§æ¨¡å‹åº“ï¼Œæ”¯æŒCUDAåŠ é€Ÿï¼Œç›®å‰æ”¯æŒå›½äº§å¤§æ¨¡å‹ChatGLM-6Bï¼ŒMOSS; å¯ä»¥åœ¨å®‰å“è®¾å¤‡ä¸Šæµç•…è¿è¡ŒChatGLM-6Bã€‚
+ [davidar/eigenGPT](https://github.com/davidar/eigenGPT) ![](https://img.shields.io/github/stars/davidar/eigenGPT?style=social) : Minimal C++ implementation of GPT2.
+ [Tlntin/Qwen-TensorRT-LLM](https://github.com/Tlntin/Qwen-TensorRT-LLM) ![](https://img.shields.io/github/stars/Tlntin/Qwen-TensorRT-LLM?style=social) : ä½¿ç”¨TRT-LLMå®Œæˆå¯¹Qwen-7B-Chatå®ç°æ¨ç†åŠ é€Ÿã€‚
+ [FeiGeChuanShu/trt2023](https://github.com/FeiGeChuanShu/trt2023) ![](https://img.shields.io/github/stars/FeiGeChuanShu/trt2023?style=social) : NVIDIA TensorRT Hackathon 2023å¤èµ›é€‰é¢˜ï¼šé€šä¹‰åƒé—®Qwen-7Bç”¨TensorRT-LLMæ¨¡å‹æ­å»ºåŠä¼˜åŒ–ã€‚
+ [TRT2022/trtllm-llama](https://github.com/TRT2022/trtllm-llama) ![](https://img.shields.io/github/stars/TRT2022/trtllm-llama?style=social) : â˜¢ï¸ TensorRT 2023å¤èµ›â€”â€”åŸºäºTensorRT-LLMçš„Llamaæ¨¡å‹æ¨æ–­åŠ é€Ÿä¼˜åŒ–ã€‚
+ [AmeyaWagh/llama2.cpp](https://github.com/AmeyaWagh/llama2.cpp) ![](https://img.shields.io/github/stars/AmeyaWagh/llama2.cpp?style=social) : Inference Llama 2 in C++.

### Python Implementation
+ [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) ![](https://img.shields.io/github/stars/abetlen/llama-cpp-python?style=social) : Python bindings for llama.cpp. [llama-cpp-python.readthedocs.io](https://llama-cpp-python.readthedocs.io/)
+ [ggml-python](https://github.com/abetlen/ggml-python) ![](https://img.shields.io/github/stars/abetlen/ggml-python?style=social) : Python bindings for ggml. [ggml-python.readthedocs.io](https://ggml-python.readthedocs.io/)

### Mojo Implementation
+ [llama2.mojo](https://github.com/tairov/llama2.mojo) ![](https://img.shields.io/github/stars/tairov/llama2.mojo?style=social) : Inference Llama 2 in one file of pure ğŸ”¥
+ [dorjeduck/llm.mojo](https://github.com/dorjeduck/llm.mojo) ![](https://img.shields.io/github/stars/dorjeduck/llm.mojo?style=social) : port of Andrjey Karpathy's llm.c to Mojo.

### Rust Implementation
+ [Candle](https://github.com/huggingface/candle) ![](https://img.shields.io/github/stars/huggingface/candle?style=social) : Minimalist ML framework for Rust.
+ [Safetensors](https://github.com/huggingface/safetensors) ![](https://img.shields.io/github/stars/huggingface/safetensors?style=social) : Simple, safe way to store and distribute tensors. [huggingface.co/docs/safetensors](https://huggingface.co/docs/safetensors/index)
+ [Tokenizers](https://github.com/huggingface/tokenizers) ![](https://img.shields.io/github/stars/huggingface/tokenizers?style=social) : ğŸ’¥ Fast State-of-the-Art Tokenizers optimized for Research and Production. [huggingface.co/docs/tokenizers](https://huggingface.co/docs/tokenizers/index)
+ [Burn](https://github.com/burn-rs/burn) ![](https://img.shields.io/github/stars/burn-rs/burn?style=social) : Burn - A Flexible and Comprehensive Deep Learning Framework in Rust. [burn-rs.github.io/](https://burn-rs.github.io/)
+ [dfdx](https://github.com/coreylowman/dfdx) ![](https://img.shields.io/github/stars/coreylowman/dfdx?style=social) : Deep learning in Rust, with shape checked tensors and neural networks.
+ [luminal](https://github.com/jafioti/luminal) ![](https://img.shields.io/github/stars/jafioti/luminal?style=social) : Deep learning at the speed of light. [www.luminalai.com/](https://www.luminalai.com/)
+ [crabml](https://github.com/crabml/crabml) ![](https://img.shields.io/github/stars/crabml/crabml?style=social) : crabml is focusing on the reimplementation of GGML using the Rust programming language.
+ [TensorFlow Rust](https://github.com/tensorflow/rust) ![](https://img.shields.io/github/stars/tensorflow/rust?style=social) : Rust language bindings for TensorFlow.
+ [tch-rs](https://github.com/LaurentMazare/tch-rs) ![](https://img.shields.io/github/stars/LaurentMazare/tch-rs?style=social) : Rust bindings for the C++ api of PyTorch.
+ [rustai-solutions/candle_demo_openchat_35](https://github.com/rustai-solutions/candle_demo_openchat_35) ![](https://img.shields.io/github/stars/rustai-solutions/candle_demo_openchat_35?style=social) : candle_demo_openchat_35.
+ [llama2.rs](https://github.com/srush/llama2.rs) ![](https://img.shields.io/github/stars/srush/llama2.rs?style=social) : A fast llama2 decoder in pure Rust.
+ [Llama2-burn](https://github.com/Gadersd/llama2-burn) ![](https://img.shields.io/github/stars/Gadersd/llama2-burn?style=social) : Llama2 LLM ported to Rust burn.
+ [gaxler/llama2.rs](https://github.com/gaxler/llama2.rs) ![](https://img.shields.io/github/stars/gaxler/llama2.rs?style=social) : Inference Llama 2 in one file of pure Rust ğŸ¦€
+ [whisper-burn](https://github.com/Gadersd/whisper-burn) ![](https://img.shields.io/github/stars/Gadersd/whisper-burn?style=social) : A Rust implementation of OpenAI's Whisper model using the burn framework.
+ [stable-diffusion-burn](https://github.com/Gadersd/stable-diffusion-burn) ![](https://img.shields.io/github/stars/Gadersd/stable-diffusion-burn?style=social) : Stable Diffusion v1.4 ported to Rust's burn framework.
+ [coreylowman/llama-dfdx](https://github.com/coreylowman/llama-dfdx) ![](https://img.shields.io/github/stars/coreylowman/llama-dfdx?style=social) : [LLaMa 7b](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) with CUDA acceleration implemented in rust. Minimal GPU memory needed!
+ [tazz4843/whisper-rs](https://github.com/tazz4843/whisper-rs) ![](https://img.shields.io/github/stars/tazz4843/whisper-rs?style=social) : Rust bindings to [whisper.cpp](https://github.com/ggerganov/whisper.cpp).
+ [rustformers/llm](https://github.com/rustformers/llm) ![](https://img.shields.io/github/stars/rustformers/llm?style=social) : Run inference for Large Language Models on CPU, with Rust ğŸ¦€ğŸš€ğŸ¦™.
+ [Chidori](https://github.com/ThousandBirdsInc/chidori) ![](https://img.shields.io/github/stars/ThousandBirdsInc/chidori?style=social) : A reactive runtime for building durable AI agents. [docs.thousandbirds.ai](https://docs.thousandbirds.ai/).
+ [llm-chain](https://github.com/sobelio/llm-chain) ![](https://img.shields.io/github/stars/sobelio/llm-chain?style=social) : llm-chain is a collection of Rust crates designed to help you work with Large Language Models (LLMs) more effectively. [llm-chain.xyz](https://llm-chain.xyz/)
+ [Abraxas-365/langchain-rust](https://github.com/Abraxas-365/langchain-rust) ![](https://img.shields.io/github/stars/Abraxas-365/langchain-rust?style=social) : ğŸ¦œï¸ğŸ”—LangChain for Rust, the easiest way to write LLM-based programs in Rust.
+ [Atome-FE/llama-node](https://github.com/Atome-FE/llama-node) ![](https://img.shields.io/github/stars/Atome-FE/llama-node?style=social) : Believe in AI democratization. llama for nodejs backed by llama-rs and llama.cpp, work locally on your laptop CPU. support llama/alpaca/gpt4all/vicuna model. [www.npmjs.com/package/llama-node](https://www.npmjs.com/package/llama-node)
+ [Noeda/rllama](https://github.com/Noeda/rllama) ![](https://img.shields.io/github/stars/Noeda/rllama?style=social) : Rust+OpenCL+AVX2 implementation of LLaMA inference code.
+ [lencx/ChatGPT](https://github.com/lencx/ChatGPT) ![](https://img.shields.io/github/stars/lencx/ChatGPT?style=social) : ğŸ”® ChatGPT Desktop Application (Mac, Windows and Linux). [NoFWL](https://app.nofwl.com/).
+ [Synaptrix/ChatGPT-Desktop](https://github.com/Synaptrix/ChatGPT-Desktop) ![](https://img.shields.io/github/stars/Synaptrix/ChatGPT-Desktop?style=social) : Fuel your productivity with ChatGPT-Desktop - Blazingly fast and supercharged!
+ [Poordeveloper/chatgpt-app](https://github.com/Poordeveloper/chatgpt-app) ![](https://img.shields.io/github/stars/Poordeveloper/chatgpt-app?style=social) : A ChatGPT App for all platforms. Built with Rust + Tauri + Vue + Axum.
+ [mxismean/chatgpt-app](https://github.com/mxismean/chatgpt-app) ![](https://img.shields.io/github/stars/mxismean/chatgpt-app?style=social) : Tauri é¡¹ç›®ï¼šChatGPT App.
+ [sonnylazuardi/chat-ai-desktop](https://github.com/sonnylazuardi/chat-ai-desktop) ![](https://img.shields.io/github/stars/sonnylazuardi/chat-ai-desktop?style=social) : Chat AI Desktop App. Unofficial ChatGPT desktop app for Mac & Windows menubar using Tauri & Rust.
+ [yetone/openai-translator](https://github.com/yetone/openai-translator) ![](https://img.shields.io/github/stars/yetone/openai-translator?style=social) : The translator that does more than just translation - powered by OpenAI.
+ [m1guelpf/browser-agent](https://github.com/m1guelpf/browser-agent) ![](https://img.shields.io/github/stars/m1guelpf/browser-agent?style=social) : A browser AI agent, using GPT-4. [docs.rs/browser-agent](https://docs.rs/browser-agent/latest/browser_agent/)
+ [sigoden/aichat](https://github.com/sigoden/aichat) ![](https://img.shields.io/github/stars/sigoden/aichat?style=social) : Using ChatGPT/GPT-3.5/GPT-4 in the terminal.
+ [uiuifree/rust-openai-chatgpt-api](https://github.com/uiuifree/rust-openai-chatgpt-api) ![](https://img.shields.io/github/stars/uiuifree/rust-openai-chatgpt-api?style=social) : "rust-openai-chatgpt-api" is a Rust library for accessing the ChatGPT API, a powerful NLP platform by OpenAI. The library provides a simple and efficient interface for sending requests and receiving responses, including chat. It uses reqwest and serde for HTTP requests and JSON serialization.
+ [1595901624/gpt-aggregated-edition](https://github.com/1595901624/gpt-aggregated-edition) ![](https://img.shields.io/github/stars/1595901624/gpt-aggregated-edition?style=social) : èšåˆChatGPTå®˜æ–¹ç‰ˆã€ChatGPTå…è´¹ç‰ˆã€æ–‡å¿ƒä¸€è¨€ã€Poeã€chatchatç­‰å¤šå¹³å°ï¼Œæ”¯æŒè‡ªå®šä¹‰å¯¼å…¥å¹³å°ã€‚
+ [Cormanz/smartgpt](https://github.com/Cormanz/smartgpt) ![](https://img.shields.io/github/stars/Cormanz/smartgpt?style=social) : A program that provides LLMs with the ability to complete complex tasks using plugins.
+ [femtoGPT](https://github.com/keyvank/femtoGPT) ![](https://img.shields.io/github/stars/keyvank/femtoGPT?style=social) : femtoGPT is a pure Rust implementation of a minimal Generative Pretrained Transformer. [discord.gg/wTJFaDVn45](https://github.com/keyvank/femtoGPT)
+ [shafishlabs/llmchain-rs](https://github.com/shafishlabs/llmchain-rs) ![](https://img.shields.io/github/stars/shafishlabs/llmchain-rs?style=social) : ğŸ¦€Rust + Large Language Models - Make AI Services Freely and Easily. Inspired by LangChain.
+ [flaneur2020/llama2.rs](https://github.com/flaneur2020/llama2.rs) ![](https://img.shields.io/github/stars/flaneur2020/llama2.rs?style=social) : An rust reimplementatin of [https://github.com/karpathy/llama2.c](https://github.com/karpathy/llama2.c).
+ [Heng30/chatbox](https://github.com/Heng30/chatbox) ![](https://img.shields.io/github/stars/Heng30/chatbox?style=social) : A Chatbot for OpenAI ChatGPT. Based on Slint-ui and Rust.
+ [fairjm/dioxus-openai-qa-gui](https://github.com/fairjm/dioxus-openai-qa-gui) ![](https://img.shields.io/github/stars/fairjm/dioxus-openai-qa-gui?style=social) : a simple openai qa desktop app built with dioxus.
+ [purton-tech/bionicgpt](https://github.com/purton-tech/bionicgpt) ![](https://img.shields.io/github/stars/purton-tech/bionicgpt?style=social) : Accelerate LLM adoption in your organisation. Chat with your confidential data safely and securely. [bionic-gpt.com](https://bionic-gpt.com/)
+ [InfiniTensor/transformer-rs](https://github.com/InfiniTensor/transformer-rs) ![](https://img.shields.io/github/stars/InfiniTensor/transformer-rs?style=social) : ä» [YdrMaster/llama2.rs](https://github.com/YdrMaster/llama2.rs) å‘å±•æ¥çš„æ‰‹å†™ transformer æ¨¡å‹é¡¹ç›®ã€‚

### Zig Implementation
+ [llama2.zig](https://github.com/cgbur/llama2.zig) ![](https://img.shields.io/github/stars/cgbur/llama2.zig?style=social) : Inference Llama 2 in one file of pure Zig.
+ [renerocksai/gpt4all.zig](https://github.com/renerocksai/gpt4all.zig) ![](https://img.shields.io/github/stars/renerocksai/gpt4all.zig?style=social) : ZIG build for a terminal-based chat client for an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMa.
+ [EugenHotaj/zig_inference](https://github.com/EugenHotaj/zig_inference) ![](https://img.shields.io/github/stars/EugenHotaj/zig_inference?style=social) : Neural Network Inference Engine in Zig.



