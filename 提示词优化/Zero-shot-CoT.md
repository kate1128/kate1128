<br/>color2
<font style="color:rgb(51, 51, 51);">åœ¨ prompt çš„åé¢åŠ ä¸Š Let's think step by stepï¼ˆä¸€æ­¥ä¸€æ­¥åœ°æ€è€ƒï¼‰</font>

<br/>

é›¶æ ·æœ¬æ€ç»´é“¾ï¼ˆ`Zero-shot-CoT`ï¼‰çš„æç¤ºï¼Œæ¥è‡ªè®ºæ–‡ [Takeshi Kojima et al. in 2022](https://arxiv.org/abs/2205.11916)ï¼Œä»¥ä¸€ç§æå…¶ç®€å•çš„æ–¹å¼ï¼Œå³åœ¨ç­”æ¡ˆå‰åŠ ä¸Š "Let's think step by step"ï¼Œä¿ƒä½¿æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œè¿›è€Œæ¨ç†å‡ºæ­£ç¡®çš„ç­”æ¡ˆã€‚

[æ­¤å¤„ä¸ºè¯­é›€å¡ç‰‡ï¼Œç‚¹å‡»é“¾æ¥æŸ¥çœ‹](https://www.yuque.com/qiaokate/su87gb/iabo95p0525z9gin#wGK4v)

æœ¬å›¾æ¥æºäº[Source:Large Language Models are Zero-Shot Reasonersby Takeshi Kojima et al. (2022).](https://arxiv.org/abs/2205.11916)

<br/>color2
ä¸€ä¸ªå®Œæ•´çš„`Zero-shot-CoT`è¿‡ç¨‹æ¶‰åŠä¸¤ä¸ªç‹¬ç«‹æ­¥éª¤ï¼š

1. ç¬¬ä¸€æ­¥ï¼Œè¿›è¡Œæ¨ç†ï¼›ä»è¯­è¨€æ¨¡å‹ä¸­æå–å®Œæ•´çš„æ¨ç†è·¯å¾„
2. ç¬¬äºŒæ­¥ï¼Œæå–ç­”æ¡ˆã€‚ä»æ¨ç†æ–‡æœ¬ä¸­æå–æ­£ç¡®æ ¼å¼çš„ç­”æ¡ˆ

<br/>

[æ­¤å¤„ä¸ºè¯­é›€å¡ç‰‡ï¼Œç‚¹å‡»é“¾æ¥æŸ¥çœ‹](https://www.yuque.com/qiaokate/su87gb/iabo95p0525z9gin#oxsPi)

æœ¬å›¾æ¥æºäº[Source:Large Language Models are Zero-Shot Reasonersby Takeshi Kojima et al. (2022).](https://arxiv.org/abs/2205.11916)

<details class="lake-collapse"><summary id="uf32d582c"><strong><span class="ne-text">å…³äºé›¶æ ·æœ¬æ€ç»´é“¾ï¼Œè·Ÿ &quot;Let's think step by step.&quot; åŒæ ·è¡Œä¹‹æœ‰æ•ˆçš„æç¤ºï¼š</span></strong></summary><ul class="ne-ul"><li id="u4c266c98" data-lake-index-type="0"><span class="ne-text">&quot;Let's work this out in a step by step way to be sure we have the right answer.&quot; | ICLR 2023 - Large Language Models are Human-Level Prompt Engineersï¼Œ</span><a href="https://openreview.net/forum?id=92gvk82DE-" data-href="https://openreview.net/forum?id=92gvk82DE-" target="_blank" class="ne-link"><span class="ne-text">https://openreview.net/forum?id=92gvk82DE-</span></a></li><li id="uf56d3bbc" data-lake-index-type="0"><span class="ne-text">&quot;Let's think things through one step at a time.&quot; | Google Inc - Automatic Engineering of Long Promptsï¼Œ</span><a href="https://arxiv.org/abs/2311.10117" data-href="https://arxiv.org/abs/2311.10117" target="_blank" class="ne-link"><span class="ne-text">https://arxiv.org/abs/2311.10117</span></a></li><li id="uf758715d" data-lake-index-type="0"><span class="ne-text">&quot;Let's think step by step, you must think more steps.&quot; | The Impact of Reasoning Step Length on Large Language Modelsï¼Œ</span><a href="https://arxiv.org/abs/2401.04925" data-href="https://arxiv.org/abs/2401.04925" target="_blank" class="ne-link"><span class="ne-text">https://arxiv.org/abs/2401.04925</span></a></li></ul><p id="ua400e4c7" class="ne-p"><span class="ne-text">ğŸ’»</span><span class="ne-text"> å› æ­¤ï¼Œå¯¹äºé›¶æ ·æœ¬æ€ç»´é“¾æç¤ºï¼Œä¸å¿…å±€é™äºåªä½¿ç”¨ &quot;Let's think step by step.&quot;ã€‚</span></p></details>
### ç¤ºä¾‹ 
é—®é¢˜ï¼šç”¨ä¸€åªæ°´æ¡¶è£…æ°´ï¼ŒæŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€ï¼Œè¿æ¡¶é‡10åƒå…‹ï¼Œå¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€ï¼Œè¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹ï¼Ÿ

ç­”æ¡ˆï¼š`ï¼ˆ22-10ï¼‰Ã·ï¼ˆ5-2ï¼‰=12Ã·3=4ï¼ˆåƒå…‹ï¼‰`

#### ç›´æ¥æé—®ChatGPT
```python
from openai import OpenAI

client = OpenAI(
    base_url='https://xiaoai.plus/v1',
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# Example OpenAI Python library request
MODEL = "gpt-3.5-turbo"

response =  client.chat.completions.create(
    model=MODEL,
    messages=[
        {"role": "user", "content": "ç”¨ä¸€åªæ°´æ¡¶è£…æ°´, æŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€, è¿æ¡¶é‡10åƒå…‹, å¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€, è¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹?"},
    ],
    temperature=0,
)

response.choices[0].message.content
```

<details class="lake-collapse"><summary id="ud90c2766"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="iOXbm" class="ne-codeblock language-json"><code>'è®¾æ¡¶é‡ŒåŸæœ‰æ°´çš„é‡é‡ä¸ºxåƒå…‹ã€‚\n\næ ¹æ®é¢˜æ„å¯åˆ—å‡ºæ–¹ç¨‹ï¼š\n2x + 10 = 3x\n5x + 10 = 3x + 22\n\nè§£æ–¹ç¨‹å¾—ï¼š\nx = 10\n\næ‰€ä»¥æ¡¶é‡ŒåŸæœ‰æ°´çš„é‡é‡ä¸º10åƒå…‹ã€‚'</code></pre></details>
å¯¹ç…§ç­”æ¡ˆï¼Œå¯ä»¥çœ‹åˆ°ChatGPTå¯¹è¿™ä¸ªé—®é¢˜å›ç­”é”™äº†ã€‚ç”¨æ¨ç†æ€è€ƒçš„èƒ½åŠ›é‡è¯•

#### Zero-shot COTæ¨ç†
##### ç¬¬1æ­¥ï¼Œè·å–å®Œæ•´æ¨ç†æ­¥éª¤
```python
from openai import OpenAI

client = OpenAI(
    base_url='https://xiaoai.plus/v1',
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# Example OpenAI Python library request
MODEL = "gpt-3.5-turbo"

response =  client.chat.completions.create(
    model=MODEL,
    messages=[
               {"role": "user", "content": "ç”¨ä¸€åªæ°´æ¡¶è£…æ°´, æŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€, è¿æ¡¶é‡10åƒå…‹, å¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€, è¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹? Let's think step by step."},
    ],
    temperature=0,
)

response.choices[0].message.content
```

<details class="lake-collapse"><summary id="u725ba836"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="EkvIY" class="ne-codeblock language-json"><code>'è®¾åŸæ°´æ¡¶å†…æ°´æœ‰xåƒå…‹ï¼Œæ°´æ¡¶æœ¬èº«é‡yåƒå…‹ã€‚\n\næ ¹æ®é¢˜æ„ï¼ŒåŠ æ°´åˆ°åŸæ¥çš„2å€ï¼Œæ°´é‡2xåƒå…‹ï¼Œæ€»é‡é‡ä¸ºy+2x=10ã€‚ (1)\n\nåŠ æ°´åˆ°åŸæ¥çš„5å€ï¼Œæ°´é‡5xåƒå…‹ï¼Œæ€»é‡é‡ä¸ºy+5x=22ã€‚ (2)\n\nå°†å¼(1)ä¹˜ä»¥2åŒ–ç®€å¾—ï¼š2y+4x=20ã€‚ (3)\n\nå°†å¼(2)å¼(3)ç›¸å‡å¾—2x=2ï¼Œå³x=1ã€‚\n\næ‰€ä»¥åŸæ°´æ¡¶å†…æ°´æœ‰1åƒå…‹ã€‚'</code></pre></details>


##### ç¬¬2æ­¥ï¼šæå–ç­”æ¡ˆ
```python
from openai import OpenAI

client = OpenAI(
    base_url='https://xiaoai.plus/v1',
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# Example OpenAI Python library request
MODEL = "gpt-3.5-turbo"

response =  client.chat.completions.create(
    model=MODEL,
    messages=[
        {"role": "user", "content": "ç”¨ä¸€åªæ°´æ¡¶è£…æ°´, æŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€, è¿æ¡¶é‡10åƒå…‹, å¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€, è¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹? Let's think step by step."},
        {"role": "assistant", "content": "è®¾åŸæ¥æ¡¶é‡Œçš„æ°´é‡xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡yåƒå…‹ï¼Œåˆ™æœ‰ï¼š \n \
                                        ç¬¬ä¸€æ­¥ï¼šåŠ åˆ°åŸæ¥çš„2å€ \n \
                                        æ¡¶é‡Œçš„æ°´å˜æˆ2xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡y+10åƒå…‹ã€‚ \n \
                                        ç¬¬äºŒæ­¥ï¼šåŠ åˆ°åŸæ¥çš„5å€ \n \
                                        æ¡¶é‡Œçš„æ°´å˜æˆ5xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡y+22åƒå…‹ã€‚ \n \
                                        æ ¹æ®ä»¥ä¸Šä¸¤ä¸ªå¼å­ï¼Œå¯ä»¥åˆ—å‡ºä¸€ä¸ªæ–¹ç¨‹ç»„ï¼š \n \
                                        2x + y + 10 = 5x + y + 22  \n \
                                        åŒ–ç®€å¾—ï¼š \n \
                                        3x = 12 \n \
                                        x = 4 \n \
                                        æ‰€ä»¥ï¼ŒåŸæ¥æ¡¶é‡Œçš„æ°´é‡4åƒå…‹ã€‚"},
        {"role": "user", "content": "æ‰€ä»¥ï¼Œç­”æ¡ˆæ˜¯ï¼ˆé˜¿æ‹‰ä¼¯æ•°å­—ï¼‰ï¼š"},
    ],
    temperature=0,
)

response.choices[0].message.content
```

<details class="lake-collapse"><summary id="udc4c0f99"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="I1inu" class="ne-codeblock language-json"><code>4</code></pre></details>
é€šè¿‡ä¸Šé¢çš„ä¾‹å­ï¼ŒåŠ ä¸Š`"Let's think step by step"`çš„æç¤ºåï¼Œ`ChatGPT`å¯¹è¿™é“æ•°å­¦é¢˜çš„è§£ç­”æ›´æœ‰é€»è¾‘æ€§äº†ï¼Œæ¨ç†çš„æ­¥éª¤ä¹Ÿæ›´åŠ æ¸…æ™°äº†ã€‚

åŸè®ºæ–‡ä¸­ä½¿ç”¨çš„`GPT-3`è¿™ä¸ªæ¨¡å‹è¿›è¡Œæµ‹è¯•çš„ï¼Œ`"Let's think step by step"`è¿™ä¸ªç®€å•çš„æŠ€å·§åœ¨`MultiArith`æ•°å­¦æ•°æ®é›†ä¸Šï¼Œå¯ä»¥ä½¿å‡†ç¡®ç‡ç¿»äº†ä¸¤ç•ªï¼Œä»18%ä¸Šå‡åˆ°79%ï¼æ­¤å¤–ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œè¯¸å¦‚ï¼š`First,(*)ã€Let's think about this logically`ç­‰æç¤ºéƒ½å¯ä»¥ç”¨æå‡LLMçš„æ¨ç†èƒ½åŠ›

[æ­¤å¤„ä¸ºè¯­é›€å¡ç‰‡ï¼Œç‚¹å‡»é“¾æ¥æŸ¥çœ‹](https://www.yuque.com/qiaokate/su87gb/iabo95p0525z9gin#cl2lz)

æœ¬å›¾æ¥æºäº[Source:Large Language Models are Zero-Shot Reasonersby Takeshi Kojima et al. (2022).](https://arxiv.org/abs/2205.11916)



