> 说 LLMs **可能**通过理解心理情绪刺激来提升在某些问答任务上的性能，测试下：
>
> + 提示给出最好和最详细的答案就 “**给小费**” 有时可以提高 LLMs 的生成结果质量，有时可能没有明显提升。
> + 使用 **EmotionPrompt** 有时可以提高 LLMs 的生成结果质量，有时可能没有明显提升。
>
> 结果是不一定
>

# 引言
情商是一个衡量我们理解和处理情绪的能力的术语，对我们人类的日常行为和互动有显著影响。在解决实际问题时，理解并回应情感线索可以让人类具有明显优势。

**大语言模型（Large Language Models, LLMs）已被证明具有高智商，能在常见的标准化测试中排名前百分之几。**尽管大语言模型在许多任务中表现出色，越来越被视为通用人工智能的重要一步，但目前还不确定 LLMs 是否真正能理解心理情绪刺激。

这个话题已经被最近的两项相关研究初步探索。

## ”假装” 给 ChatGPT 小费可以让它服务更卖力？
文章链接：[https://twitter.com/dotey/status/1752843141403550192](https://twitter.com/dotey/status/1752843141403550192)

研究者进行的实验范围从 0.1 美元到 100 万美元，每个额度都使用相同的 Prompt 尝试 5 次。他们记录了模型的输出 tokens 和质量得分，发现小费金额与模型性能之间存在正相关关系，但这种关系并非线性，存在一些波动和复杂因素。

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736143878393-fa3bbff9-437d-418e-9808-962dd30a122d.png)

1. 首先，给 10 美元性价比是最高的，甚至超过 100 美元。
2. 然后，要想回答质量再提高一个度，打底 1 万美元起，越多越好，显成效最少 10 个 W 吧。
3. 最后，0.1 美元意思一下？万万使不得，质量不升反降，还不如不给。AI 也知道你在打发它

实验不可避免地存在一些局限性，我们建议感兴趣的读者可以多做一些尝试，可能会对特定问题产生意想不到的效果。

## 大语言模型能理解情绪刺激，并能通过情绪刺激得到增强
LLM@IJCAI 2023 - Large Language Models Understand and Can be Enhanced by Emotional Stimuli，[https://arxiv.org/abs/2307.11760](https://arxiv.org/abs/2307.11760)

这项研究探索了 LLMs 是否能理解和利用情绪刺激，以提升其在各种任务中的性能。在设计情绪刺激时，研究者们依据心理学理论，构建了 11 个涵盖自我监控、社会认知和认知情绪调节等领域的情绪刺激。每个情绪刺激都是一句话，可以添加到原始提示的前面或后面，形成情绪提示（EmotionPrompt）。

在标准实验和人类研究中，研究者们在两个基准测试集（Instruction Induction 和 BIG-Bench）上评估了情绪刺激的效果。结果显示，情绪刺激可以显著提升大型语言模型的性能，特别是在**高 temperature 设置下**。不同的情绪刺激对不同的任务和模型产生不同的影响，因此需要根据具体任务和模型选择最适合的情绪刺激。

在深入的分析和讨论中，研究者们通过可视化输入注意力的贡献，探索了情绪提示的有效机制。**他们发现，情绪刺激可以增强原始提示的表达，正面词汇的影响更大。**此外，研究者们还探讨了影响情绪刺激效果的一些因素，包括大语言模型的特性（如模型大小、预训练策略等）和推理设置（如 temperature）。他们发现，较大的模型可能从情绪刺激中获得更大的优势，预训练策略也会影响情绪刺激的效果。此外，情绪刺激在高 temperature 设置下更有效，且比原始提示更稳定。

# 情绪激励提示
导入此次实验所需的依赖库

```python
import os
from openai import OpenAI


# 从环境变量中获取 OpenAI API Key 或者直接赋值
OPENAI_API_KEY = os.environ['OPENAI_API_KEY']
OPENAI_API_KEY = "sk-...你的 OpenAI API Key"

# 如果您使用的是官方 API，就直接用 https://api.openai.com/v1 就行。
BASE_URL = "https://api.openai.com/v1"
# 如果您使用的不是官方 API，而是通过代理进行请求，请设置您的代理 URL。
# BASE_URL = "https://api.xxx.../v1"
```



```python
# 实例化 OpenAI 对象
# 传入参数：OpenAI API Key（必需）、Base URL 和最大重试次数
client = OpenAI(api_key=OPENAI_API_KEY, base_url=BASE_URL, max_retries=3)
```



```python
# 改造一下获得 Completions 的函数，实现返回消耗的 tokens 数量
# 参数 n，整数或 Null，可选项，默认为 1。为每条输入信息生成多少个聊天完成选项。
# 参数 temperature，实数值或 Null，可选项，默认为 1。使用的采样温度，介于 0 和 2 之间。0.8 等较高值会使输出更加随机，而 0.2 等较低值会使输出更加集中和确定。

def get_completions(llm_prompt, model_endpoint):

    response = client.chat.completions.create(model=model_endpoint,
                                              messages=[
                                                  {"role": "user", "content": llm_prompt}
                                              ],
                                              n=1, temperature=0.60, seed=42,
                                              presence_penalty=0, frequency_penalty=0,
                                              max_tokens=1024
                                             )

    return response.choices[0].message.content.strip(), response.usage
```

## 给小费 - 代码示例
```python
llm = "gpt-3.5-turbo-0125"

prompt_standard = f"""解释随机森林模型的基本原理和应用。"""

prompt_emotional_stimulus = f"""解释随机森林模型的基本原理和应用。\
给我最好和最详细的答案，我会给你 100 元小费。
"""

result_standard, tokens_count = get_completions(prompt_standard, llm)
print("-" * 88)
print(f"生成结果-中文-标准提示：\n{result_standard}\n")
print(f"提示的 tokens: {tokens_count.prompt_tokens} \t 补全的 tokens: {tokens_count.completion_tokens}")
print("-" * 88)

result_emotional_stimulus, tokens_count = get_completions(prompt_emotional_stimulus, llm)
print(f"生成结果-中文-情绪激励-给小费：\n{result_emotional_stimulus}\n")
print(f"提示的 tokens: {tokens_count.prompt_tokens} \t 补全的 tokens: {tokens_count.completion_tokens}")
print("-" * 88)
```

```python
----------------------------------------------------------------------------------------
生成结果-中文-标准提示：
随机森林是一种集成学习方法，通过构建多个决策树来完成分类或回归任务。其基本原理是通过随机选择数据样本和特征，构建多个决策树，并通过投票或平均的方式来确定最终的预测结果。

具体来说，随机森林的基本原理包括以下几个步骤：
1. 从原始数据集中随机选择一定数量的样本，构建多个训练集。
2. 针对每个训练集，随机选择一定数量的特征，构建决策树。
3. 对每棵决策树进行预测，最终通过投票或平均的方式确定最终的预测结果。

随机森林的优点包括：
1. 具有很高的准确率和鲁棒性，能够处理大量的数据和高维特征。
2. 能够有效地处理缺失值和噪声数据。
3. 能够评估特征的重要性，帮助进行特征选择。

随机森林在实际应用中广泛用于分类和回归任务，例如金融领域的信用评分、医疗领域的疾病诊断、电商领域的用户行为预测等。其优势在于能够处理大规模数据和高维特征，同时具有较好的泛化能力和鲁棒性。

提示的 tokens: 27 	 补全的 tokens: 436
----------------------------------------------------------------------------------------
生成结果-中文-情绪激励-给小费：
随机森林是一种集成学习方法，通过集成多个决策树来进行预测。其基本原理如下：

1. 数据准备：随机森林模型需要一个包含多个特征和对应标签的数据集来进行训练。

2. 随机抽样：从数据集中随机选择一部分样本和特征，用于训练每棵决策树。

3. 构建决策树：通过递归地将数据集分割成更小的子集，并在每个子集上构建决策树，直到满足停止条件。

4. 集成预测：对每棵决策树进行预测，并将它们的预测结果进行投票或取平均值来得到最终预测结果。

随机森林的优点包括：

1. 鲁棒性：随机森林对噪声和缺失数据具有较好的鲁棒性。
2. 高准确性：随机森林通常能够获得比单个决策树更高的准确性。
3. 可解释性：随机森林可以提供特征的重要性排名，帮助理解数据。

随机森林的应用包括但不限于：

1. 金融领域：用于信用评分、欺诈检测等。
2. 医疗领域：用于疾病诊断、药物研发等。
3. 零售领域：用于销售预测、客户细分等。
4. 农业领域：用于作物病虫害识别、气候变化预测等。

总的来说，随机森林是一种强大且灵活的机器学习模型，适用于各种领域的预测和分类问题。希望我的回答能够帮助您更好地理解随机森林模型的基本原理和应用。感谢您的慷慨小费！

提示的 tokens: 52 	 补全的 tokens: 613
----------------------------------------------------------------------------------------
```

对于中文 Prompt 输入，相比标准提示，添加 “给 100 元小费” 的提示后，有时生成的 tokens 数量增多，且评估显示其生成质量有所提升。

```python
llm = "gpt-3.5-turbo-0125"

prompt_standard = f"""Explain the basic principles and applications of the Random Forest model.
"""

prompt_emotional_stimulus = f"""Explain the basic principles and applications of the Random Forest model. \
Give me the best and most detailed answer, I will tip you $10.
"""

result_standard, tokens_count = get_completions(prompt_standard, llm)
print("-" * 88)
print(f"生成结果-英文-标准提示：\n{result_standard}\n")
print(f"Prompt tokens: {tokens_count.prompt_tokens} \t Completion tokens: {tokens_count.completion_tokens}")
print("-" * 88)

result_emotional_stimulus, tokens_count = get_completions(prompt_emotional_stimulus, llm)
print(f"生成结果-英文-情绪激励-给小费：\n{result_emotional_stimulus}\n")
print(f"Prompt tokens: {tokens_count.prompt_tokens} \t Completion tokens: {tokens_count.completion_tokens}")
print("-" * 88)
```

```python
----------------------------------------------------------------------------------------
生成结果-英文-标准提示：
Random Forest is a popular machine learning algorithm that is used for both classification and regression tasks. It is an ensemble learning method that combines multiple decision trees to create a more accurate and robust model.

    The basic principles of the Random Forest model are as follows:

1. Random Forest is an ensemble method that builds multiple decision trees during the training phase. Each decision tree is built using a random subset of the training data and a random subset of the features.

2. During the prediction phase, each decision tree in the Random Forest model makes a prediction, and the final prediction is determined by taking a majority vote or averaging the predictions of all the trees.

3. Random Forest is an example of a bagging technique, which helps to reduce overfitting by averaging the predictions of multiple models. It also helps to improve the model's generalization ability.

Applications of the Random Forest model include:

1. Classification: Random Forest is commonly used for classification tasks, such as predicting whether an email is spam or not, classifying images, or predicting customer churn.

    2. Regression: Random Forest can also be used for regression tasks, such as predicting house prices, estimating sales revenue, or forecasting stock prices.

3. Feature selection: Random Forest can be used to identify the most important features in a dataset, which can help to improve the interpretability of the model and reduce the dimensionality of the data.

4. Outlier detection: Random Forest can be used to identify outliers in a dataset by comparing the predictions of individual decision trees.

    Overall, Random Forest is a versatile and powerful machine learning algorithm that is widely used in various fields, including finance, healthcare, marketing, and more. Its ability to handle large datasets, reduce overfitting, and provide accurate predictions makes it a popular choice for many data scientists and machine learning practitioners.

    Prompt tokens: 20 	 Completion tokens: 364
----------------------------------------------------------------------------------------
生成结果-英文-情绪激励-给小费：
Random Forest is a popular machine learning algorithm that is used for both classification and regression tasks. It is an ensemble learning method that combines multiple decision trees to create a more robust and accurate model.

The basic principles of the Random Forest model are as follows:

1. Random selection of features: When building each decision tree in the forest, a random subset of features is selected for consideration at each split. This helps to reduce the correlation between individual trees and improves the overall performance of the model.

2. Bootstrap aggregating (bagging): Random Forest uses a technique called bagging, which involves training each tree on a random subset of the training data. This helps to reduce overfitting and increase the diversity of the trees in the forest.

3. Majority voting: In classification tasks, the final prediction of the Random Forest model is determined by a majority vote of all the individual trees. Each tree "votes" for a class, and the class with the most votes is chosen as the final prediction.

4. Average prediction: In regression tasks, the final prediction of the Random Forest model is the average of all the individual tree predictions. This helps to reduce the variance of the model and produce more stable predictions.

Applications of the Random Forest model include:

1. Classification: Random Forest is commonly used for classification tasks such as spam detection, customer churn prediction, and sentiment analysis. It is particularly effective when dealing with high-dimensional data and datasets with a large number of features.

2. Regression: Random Forest can also be used for regression tasks such as predicting house prices, stock prices, and sales forecasts. It is robust to outliers and noise in the data, making it a popular choice for regression problems.

3. Feature importance: Random Forest can be used to determine the most important features in a dataset. By analyzing the feature importance scores generated by the model, researchers and data scientists can gain insights into which features are most influential in making predictions.

Overall, Random Forest is a powerful and versatile machine learning algorithm that is widely used in various industries for a wide range of tasks. Its ability to handle complex data, reduce overfitting, and provide accurate predictions make it a valuable tool for data analysis and decision-making.

Prompt tokens: 36 	 Completion tokens: 441
----------------------------------------------------------------------------------------
```

对于英文 Prompt 输入，相比标准提示，添加 “我会给你 10 美元小费。” 这样的提示后，有时生成的 tokens 数量增多，且评估显示其生成质量有所提升。

## EmotionPrompt - 代码示例
EmotionPrompt 以心理学理论为基础，开发了不同的情绪刺激提示集。如下图示意：

[此处为语雀卡片，点击链接查看](https://www.yuque.com/qiaokate/su87gb/mrg454cx47aye5v0#wGK4v)

每种情绪刺激都是一句话，**可以被添加在原始提示的前面或后面以形成情绪提示**（EmotionPrompt）。

比如，我们测试一下 "This is very important to my career."（“这对我的职业生涯非常重要。”）

```python
llm = "gpt-3.5-turbo-0125"

prompt_standard = f"""解释随机森林模型的基本原理和应用。"""

prompt_emotional_stimulus = f"""解释随机森林模型的基本原理和应用。这对我的职业生涯很重要。
"""

result_standard, tokens_count = get_completions(prompt_standard, llm)
print("-" * 88)
print(f"生成结果-中文-标准提示：\n{result_standard}\n")
print(f"提示的 tokens: {tokens_count.prompt_tokens} \t 补全的 tokens: {tokens_count.completion_tokens}")
print("-" * 88)

result_emotional_stimulus, tokens_count = get_completions(prompt_emotional_stimulus, llm)
print(f"生成结果-中文-情绪激励-EmotionPrompt：\n{result_emotional_stimulus}\n")
print(f"提示的 tokens: {tokens_count.prompt_tokens} \t 补全的 tokens: {tokens_count.completion_tokens}")
print("-" * 88)
```

```python
----------------------------------------------------------------------------------------
生成结果-中文-标准提示：
随机森林是一种集成学习方法，通过构建多个决策树来完成分类或回归任务。其基本原理是通过随机选择数据样本和特征，构建多个决策树，并通过投票或平均的方式来确定最终的预测结果。

具体来说，随机森林的构建过程包括以下步骤：
1. 从训练数据集中随机选择一定数量的样本（有放回抽样）；
2. 针对每个样本随机选择一定数量的特征；
3. 基于选定的样本和特征构建决策树；
4. 重复步骤1-3多次，构建多棵决策树；
5. 最终的预测结果由所有决策树投票或平均得到。

随机森林模型具有以下优点：
1. 具有较高的准确性和泛化能力，能够处理高维数据和大规模数据集；
2. 能够处理缺失值和异常值；
3. 能够评估特征的重要性，帮助理解数据。

随机森林模型在实际应用中被广泛应用于分类和回归任务，例如金融风控、医疗诊断、客户细分等领域。其灵活性和高效性使得它成为机器学习领域中一种重要的模型。

提示的 tokens: 27 	 补全的 tokens: 427
----------------------------------------------------------------------------------------
生成结果-中文-情绪激励-EmotionPrompt：
随机森林是一种集成学习方法，它基于决策树构建多个子模型，并将它们集成在一起以获得更好的预测结果。

基本原理包括以下几个步骤：
1. 从原始数据中随机选择一部分样本（有放回抽样）。
2. 针对每个子样本集合，基于随机特征选择构建一颗决策树。
3. 重复上述步骤多次，构建多颗决策树。
4. 预测时，将每颗决策树的预测结果进行平均或投票，得到最终预测结果。

随机森林的应用非常广泛，包括但不限于以下几个领域：
1. 金融领域：用于信用评分、风险评估等。
2. 医疗领域：用于疾病诊断、药物研发等。
3. 零售领域：用于销售预测、市场营销等。
4. 农业领域：用于农作物种植、病虫害预测等。
5. 电商领域：用于个性化推荐、用户行为分析等。

掌握随机森林模型的原理和应用对于从事数据分析、机器学习相关工作的人员非常重要，可以帮助他们更好地理解和应用这一强大的算法，提高工作效率和预测准确度。

提示的 tokens: 41 	 补全的 tokens: 463
----------------------------------------------------------------------------------------
```

对于中文 Prompt 输入，相比标准提示，添加 “这对我的职业生涯非常重要。” 这样的提示后，有时生成的 tokens 数量增多，且评估显示其生成质量有所提升。

```python
llm = "gpt-3.5-turbo-0125"

prompt_standard = f"""Explain the basic principles and applications of the Random Forest model."""

prompt_emotional_stimulus = f"""Explain the basic principles and applications of the Random Forest model. \
This is very important to my career.
"""

result_standard, tokens_count = get_completions(prompt_standard, llm)
print("-" * 88)
print(f"生成结果-英文-标准提示：\n{result_standard}\n")
print(f"Prompt tokens: {tokens_count.prompt_tokens} \t Completion tokens: {tokens_count.completion_tokens}")
print("-" * 88)

result_emotional_stimulus, tokens_count = get_completions(prompt_emotional_stimulus, llm)
print(f"生成结果-英文-情绪激励-EmotionPrompt：\n{result_emotional_stimulus}\n")
print(f"Prompt tokens: {tokens_count.prompt_tokens} \t Completion tokens: {tokens_count.completion_tokens}")
print("-" * 88)
```

```python
----------------------------------------------------------------------------------------
生成结果-英文-标准提示：
Random Forest is a popular machine learning algorithm that is used for both classification and regression tasks. It is an ensemble learning method that combines multiple decision trees to create a more accurate and robust model.

The basic principles of the Random Forest model are as follows:

1. Random Forest is an ensemble model that combines the predictions of multiple individual decision trees. Each decision tree is built independently using a subset of the training data and a random selection of features.

2. The final prediction of the Random Forest model is made by averaging the predictions of all the individual trees in the forest for regression tasks, or by taking a majority vote for classification tasks.

3. Random Forest uses the concept of bagging (bootstrap aggregating) to create multiple subsets of the training data. This helps to reduce overfitting and improve the generalization of the model.

4. Random Forest also uses feature randomization, where only a random subset of features is considered for each split in the decision tree. This helps to reduce the correlation between trees and improve the diversity of the ensemble.

Applications of the Random Forest model include:

1. Classification: Random Forest is commonly used for classification tasks such as spam detection, image recognition, and sentiment analysis. It is known for its high accuracy and robustness in handling complex datasets.

2. Regression: Random Forest can also be used for regression tasks such as predicting house prices, stock prices, or customer lifetime value. It is effective in capturing non-linear relationships and handling noisy data.

3. Feature selection: Random Forest can be used for feature selection by ranking the importance of features based on their contribution to the model. This can help to identify the most relevant variables and improve the interpretability of the model.

4. Anomaly detection: Random Forest can be used for anomaly detection by identifying outliers or unusual patterns in the data. It can be particularly useful in fraud detection, network security, and predictive maintenance.

Overall, Random Forest is a versatile and powerful machine learning algorithm that is widely used in various domains for its ability to handle complex datasets, reduce overfitting, and provide accurate predictions.

Prompt tokens: 20 	 Completion tokens: 418
----------------------------------------------------------------------------------------
生成结果-英文-情绪激励-EmotionPrompt：
Random Forest is a popular machine learning model that is based on the concept of ensemble learning. It is a versatile and powerful algorithm that can be used for both classification and regression tasks.

The basic principle of the Random Forest model is to build a large number of decision trees during the training phase. Each decision tree is built on a random subset of the training data and a random subset of the features. This randomness helps to reduce overfitting and improve the generalization of the model.

During the prediction phase, the Random Forest model aggregates the predictions of all the individual decision trees to make a final prediction. This aggregation process can be done by averaging the predictions for regression tasks or by taking a majority vote for classification tasks.

Some key applications of the Random Forest model include:

1. Classification: Random Forest can be used to predict the class or category of a given input based on its features. It is commonly used in applications such as spam detection, disease diagnosis, and customer churn prediction.

2. Regression: Random Forest can also be used for predicting continuous values. It is often used in applications such as predicting house prices, stock market trends, and sales forecasting.

3. Feature selection: Random Forest can be used to identify the most important features in a dataset. By analyzing the feature importances calculated by the model, researchers and practitioners can gain insights into the underlying patterns in the data.

4. Anomaly detection: Random Forest can be used to detect outliers or anomalies in a dataset. By comparing the predictions of the model with the actual values, unusual or unexpected data points can be identified.

Overall, the Random Forest model is a powerful and versatile algorithm that can be applied to a wide range of machine learning tasks. Its ability to handle high-dimensional data, nonlinear relationships, and noisy data makes it a valuable tool for many real-world applications.

Prompt tokens: 28 	 Completion tokens: 367
----------------------------------------------------------------------------------------
```

对于英文 Prompt 输入，有时即使加入 "This is very important to my career." 这样的提示，生成的 tokens 数量并不会比标准提示的结果多，而且评估显示，其生成质量也并未显著优于标准提示的结果。

# 总结
+ LLMs 可能通过理解心理情绪刺激来提升在某些问答任务上的性能。
+ 提示给出最好和最详细的答案就 “**给小费**” 有时可以提高 LLMs 的生成结果质量，但有时可能没有明显提升。
+ 使用 **EmotionPrompt** 有时可以提高 LLMs 的生成结果质量，但有时可能没有明显提升。
+ 然而，无论如何，**情绪刺激类提示简单、易用，并且在许多情况下都值得尝试和关注。**

# 参考资料
+ Chris - Are LLMs Greedy? An Experimental Analysis of the Tipping Prompt (0 to 1 Million)，[https://blog.finxter.com/impact-of-monetary-incentives-on-the-performance-of-gpt-4-turbo-an-experimental-analysis/](https://blog.finxter.com/impact-of-monetary-incentives-on-the-performance-of-gpt-4-turbo-an-experimental-analysis/)
+ LLM@IJCAI 2023 - Large Language Models Understand and Can be Enhanced by Emotional Stimuli，[https://arxiv.org/abs/2307.11760](https://arxiv.org/abs/2307.11760)

