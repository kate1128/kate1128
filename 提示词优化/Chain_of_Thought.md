<br/>color2
<font style="color:rgb(51, 51, 51);">å±•ç¤ºä¸€ä¸ªç›¸ä¼¼é—®é¢˜çš„æ¨ç†è¿‡ç¨‹ï¼Œå‘Šè¯‰ChatGPTåº”è¯¥è¿™ä¹ˆæ¥ï¼ˆæ¨èä½¿ç”¨</font><font style="color:rgb(51, 51, 51);">ğŸ‘</font><font style="color:rgb(51, 51, 51);">ï¼‰</font>

é€šè¿‡å‘LLMå±•ç¤ºä¸€äº›å°‘é‡çš„å…¸èŒƒï¼Œåœ¨æ ·ä¾‹ä¸­è§£é‡Šæ¨ç†è¿‡ç¨‹ï¼Œå¤§è¯­è¨€æ¨¡å‹åœ¨å›ç­”æç¤ºæ—¶ä¹Ÿä¼šè·Ÿç€è¿›è¡Œæ¨ç†ã€‚

<br/>

æ€ç»´é“¾ï¼ˆCoTï¼‰æç¤ºæ˜¯ä¸€ç§æœ€è¿‘å¼€å‘çš„æç¤ºæ–¹æ³•ï¼Œæ—¨åœ¨é¼“åŠ±å¤§è¯­è¨€æ¨¡å‹è§£é‡Šå…¶æ¨ç†è¿‡ç¨‹ã€‚ä¸‹å›¾æ˜¾ç¤ºäº† `few shot standard prompt`ï¼ˆå·¦ï¼‰ä¸ `COT` è¿‡ç¨‹ï¼ˆå³ï¼‰çš„æ¯”è¾ƒã€‚

[æ­¤å¤„ä¸ºè¯­é›€å¡ç‰‡ï¼Œç‚¹å‡»é“¾æ¥æŸ¥çœ‹](https://www.yuque.com/qiaokate/su87gb/xdfm49579ay9goaa#wGK4v)

æœ¬å›¾æ¥æºäº[Source:Chain of Thought Prompting Elicits Reasoning in Large Language ModelsJason Wei and Denny Zhou et al. (2022)](https://arxiv.org/pdf/2201.11903)

CoTçš„ä¸»è¦æ€æƒ³æ˜¯ï¼Œé€šè¿‡å‘LLMå±•ç¤ºä¸€äº›å°‘é‡çš„å…¸èŒƒï¼Œåœ¨æ ·ä¾‹ä¸­è§£é‡Šæ¨ç†è¿‡ç¨‹ï¼Œå¤§è¯­è¨€æ¨¡å‹åœ¨å›ç­”æç¤ºæ—¶ä¹Ÿä¼šè·Ÿç€è¿›è¡Œæ¨ç†ã€‚

### ç¤ºä¾‹
ï¼ˆæœ¬ä¾‹æ¥æºäº[å¢å¼ºChatGPTå›ç­”çš„é€»è¾‘æ€§](https://mp.weixin.qq.com/s?__biz=MzI1MTE3MTIwOQ==&mid=2247483750&idx=1&sn=ef559cfaadda6947e99ea0a16e36a69d&chksm=e9f65980de81d09616e4be6d7a46a39c1f878812b247b8a5a4dea7eceade827ea9491b10211d#rd)ï¼‰

```python
from openai import OpenAI

client = OpenAI(
    base_url='https://xiaoai.plus/v1',
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# Example OpenAI Python library request
MODEL = "gpt-3.5-turbo"

response =  client.chat.completions.create(
    model=MODEL,
    messages=[
        {"role": "user", "content": "åœ¨è¿™äº›æ•°å­—3ã€56ã€35ã€96ã€40ã€10ã€84ã€923ã€32ã€20 ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼Ÿ"},
    ],
    temperature=0,
)

response.choices[0].message.content
```

<details class="lake-collapse"><summary id="ufd0086bc"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="PSBLE" class="ne-codeblock language-json"><code>è¿™äº›æ•°å­—ä¸­ï¼Œæœ‰3ä¸ªå¥‡æ•°ï¼ˆ3ã€35ã€923ï¼‰å’Œ7ä¸ªå¶æ•°ï¼ˆ56ã€96ã€40ã€10ã€84ã€32ã€20ï¼‰ã€‚</code></pre></details>
ä¸‹é¢åŠ ä¸Š`Let's think step by step`

```python
response = openai.ChatCompletion.create(
    model=MODEL,
    messages=[
        {"role": "user", "content": "åœ¨è¿™äº›æ•°å­—3ã€56ã€35ã€96ã€40ã€10ã€84ã€923ã€32ã€20 ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼ŸLet's think step by step."},
    ],
    temperature=0,
)

print(response['choices'][0]['message']['content'])
```

<details class="lake-collapse"><summary id="u2bccf1e0"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="fyYrI" class="ne-codeblock language-json"><code>'Step 1: Identify odd and even numbers \n\nOdd numbers: 3, 35, 96, 923\nEven numbers: 56, 40, 10, 84, 32, 20\n\nStep 2: Count the number of odd and even numbers\n\nNumber of odd numbers: 4\nNumber of even numbers: 6\n\nTherefore, there are 4 odd numbers and 6 even numbers in the list provided.'</code></pre></details>
é”™äº†ï¼Œæ—¢ç„¶`â€œLet's think step by step.â€`å¤±æ•ˆäº†ï¼Œæ¢ä¸ªæ‰‹æ®µï¼Œç»™ChatGPTä¾‹å­å­¦ä¹ ä¸€ä¸‹

```python
from openai import OpenAI

client = OpenAI(
    base_url='https://xiaoai.plus/v1',
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)

# Example OpenAI Python library request
MODEL = "gpt-3.5-turbo"

response =  client.chat.completions.create(
    model=MODEL,
    messages=[
        {"role": "user", "content": "åœ¨è¿™äº›æ•°å­— 38ã€31ã€89ã€224ç§ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼Ÿ."},
        {"role": "assistant", "content": "ä¸€ä¸ªä¸€ä¸ªæ•°ï¼š\n \
            1. 38æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°0ä¸ªï¼› \n \
            2. 31æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°1ä¸ªï¼› \n \
            3. 89æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°2ï¼› \n \
            4. 224æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°2ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \n \
            æ‰€ä»¥,ä¸€å…±æœ‰2ä¸ªå¶æ•°ï¼Œ2ä¸ªå¥‡æ•°ã€‚"},
        {"role": "user", "content": "åœ¨è¿™äº›æ•°å­—3ã€56ã€35ã€96ã€40ã€10ã€84ã€923ã€32ã€20 ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼Ÿ"},
    ],
    temperature=0,
)

response.choices[0].message.content
```

<details class="lake-collapse"><summary id="uaffa97ea"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="FX8UF" class="ne-codeblock language-json"><code>'ä¸€ä¸ªä¸€ä¸ªæ•°ï¼š\n1. 3æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°0ä¸ªï¼Œå¥‡æ•°1ä¸ªï¼›\n2. 56æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°1ä¸ªï¼›\n3. 35æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼›\n4. 96æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°2ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼›\n5. 40æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°3ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼›\n6. 10æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°4ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼›\n7. 84æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°5ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼›\n8. 923æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°5ä¸ªï¼Œå¥‡æ•°3ä¸ªï¼›\n9. 32æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°6ä¸ªï¼Œå¥‡æ•°3ä¸ªï¼›\n10. 20æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°7ä¸ªï¼Œå¥‡æ•°3ä¸ªï¼›\n\næ‰€ä»¥ï¼Œä¸€å…±æœ‰7ä¸ªå¶æ•°ï¼Œ3ä¸ªå¥‡æ•°ã€‚'</code></pre></details>
æ€ç»´é“¾å·²è¢«è¯æ˜å¯¹äºç®—æœ¯ã€å¸¸è¯†å’Œç¬¦å·æ¨ç†ç­‰ä»»åŠ¡çš„ç»“æœæœ‰æ‰€æ”¹è¿›ã€‚ç‰¹åˆ«æ˜¯ï¼Œåœ¨GSM8KåŸºå‡†æµ‹è¯•ä¸Šï¼ŒPaLM 540Bé€šè¿‡æç¤ºè¾¾åˆ°äº†57%çš„å‡†ç¡®æ€§ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1737687790377-0d537be1-3a57-4183-b44d-4f80867e703d.png)

æœ¬å›¾æ¥æºäº[Source:Chain of Thought Prompting Elicits Reasoning in Large Language ModelsJason Wei and Denny Zhou et al. (2022)](https://arxiv.org/pdf/2201.11903)



