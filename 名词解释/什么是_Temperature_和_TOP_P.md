<font style="color:rgb(0, 0, 0);">这两个概念是用于调节生成模型（比如 GPT）输出的多样性和创造性的参数。通常，</font>**<font style="color:rgb(0, 0, 0);">Temperature</font>**<font style="color:rgb(0, 0, 0);"> 和 </font>**<font style="color:rgb(0, 0, 0);">Top-p</font>**<font style="color:rgb(0, 0, 0);"> 可以联合使用，调整模型输出的创造性和流畅度。</font>

## <font style="color:rgb(0, 0, 0);">Temperature（温度）</font>
+ **<font style="color:rgb(0, 0, 0);">定义</font>**<font style="color:rgb(0, 0, 0);">：温度是控制模型输出随机性的参数。它影响模型预测下一个词时的“概率分布”。</font>
+ **<font style="color:rgb(0, 0, 0);">作用</font>**<font style="color:rgb(0, 0, 0);">：</font>
    - **<font style="color:rgb(0, 0, 0);">低温度（</font>****接近 0****<font style="color:rgb(0, 0, 0);">）</font>**<font style="color:rgb(0, 0, 0);">：</font>预测的随机性会较低，产生更**保守、可预测**的文本，<font style="color:rgb(0, 0, 0);">不太可能生成意想不到或不寻常的词。</font>
    - **<font style="color:rgb(0, 0, 0);">高温度（</font>****接近 1****<font style="color:rgb(0, 0, 0);">）</font>**<font style="color:rgb(0, 0, 0);">：</font>预测的随机性会较高，所有词被选择的可能性更大，会产生更有创意、多样化的文本<font style="color:rgb(0, 0, 0);">，更有可能生成不寻常或意想不到的词。</font>

## <font style="color:rgb(0, 0, 0);">Top-p（顶点采样）</font>
+ **<font style="color:rgb(0, 0, 0);">定义</font>**<font style="color:rgb(0, 0, 0);">：Top-p 采样（也叫做</font>**<font style="color:rgb(0, 0, 0);">核采样</font>**<font style="color:rgb(0, 0, 0);">）是一种根据概率分布进行采样的方法。在每次预测时，模型会选择一个总概率大于等于 p 的最小集合，并在其中进行采样。</font>
+ **<font style="color:rgb(0, 0, 0);">作用</font>**<font style="color:rgb(0, 0, 0);">：</font>
    - **<font style="color:rgb(0, 0, 0);">p 越小</font>**<font style="color:rgb(0, 0, 0);">：生成的文本会变得</font>**<font style="color:rgb(0, 0, 0);">更加保守</font>**<font style="color:rgb(0, 0, 0);">和一致，因为模型仅在最可能的几个词中选择。</font>
    - **<font style="color:rgb(0, 0, 0);">p 越大</font>**<font style="color:rgb(0, 0, 0);">：生成的文本更加多样化，因为模型有更大的选择空间。</font>
+ <font style="color:rgb(0, 0, 0);">例如，如果 p=0.9，那么模型会将所有累计概率超过 90% 的词汇作为候选，从中随机选一个。</font>

##  示例 1
[第二步：参数调整](https://www.yuque.com/qiaokate/su87gb/num7da5sb4xg7iri)

## 示例 2
 当使用 ChatGPT 要求其为想一个关于跨语言模型的硕士毕业论文选题，当将 temperature 设置为 0 时，模型回复为：

```properties
题目：基于跨语言模型的机器翻译性能优化研究

摘要：随着全球化的发展，跨语言交流的需求日益增长。机器翻译作为一种自动化翻译技术，为跨语言交流提供了便利。然而，由于语言之间的差异性，机器翻译系统在不同语言对之间的性能存在差异。本论文旨在通过研究跨语言模型，探索如何优化机器翻译的性能，提高翻译质量和准确性。

关键词：跨语言模型，机器翻译，性能优化，翻译质量，准确性

1. 引言
1.1 研究背景和意义
1.2 国内外研究现状
1.3 研究目标和内容

2. 跨语言模型的原理和方法
2.1 传统机器翻译方法
2.2 跨语言模型的基本原理
2.3 跨语言模型的常用方法和技术

3. 跨语言模型在机器翻译中的应用
3.1 跨语言模型在机器翻译中的优势和挑战
3.2 跨语言模型在不同语言对上的性能表现比较
3.3 跨语言模型在特定领域机器翻译中的应用案例分析

4. 跨语言模型的性能优化方法
4.1 数据预处理和特征选择
4.2 模型参数调优和训练策略
4.3 跨语言模型与其他技术的结合应用

5. 实验设计与结果分析
5.1 实验设计和数据集介绍
5.2 实验结果分析和对比
5.3 实验结果的可行性和可靠性验证

6. 结论与展望
6.1 研究工作总结
6.2 存在的问题和不足
6.3 进一步研究方向和展望

参考文献

注：以上仅为一个选题示例，具体选题应根据个人兴趣和研究背景进行调整和修改。
```

当将 temperature 设置为 0.95 时，模型回复为：

```properties
以下是关于跨语言模型的几个硕士毕业论文选题建议：

1. 跨语言文本分类模型的比较和优化——通过比较不同跨语言模型的性能，分析其在不同语言之间的适应性和准确性，并尝试优化现有模型，提高跨语言文本分类的效果。

2. 基于跨语言模型的机器翻译性能分析——通过比较不同跨语言模型在机器翻译任务中的表现，研究不同语言之间的短板和优势，并探讨如何针对性地改进跨语言机器翻译的性能。

3. 跨语言情感分析模型的构建与应用——使用跨语言模型构建情感分析模型，通过比较模型在不同语言上的准确性和一致性，分析不同语言中情感表达的差异，并探索在多语言场景下的情感分析应用。

4. 多任务学习下的跨语言模型训练——探索多任务学习下跨语言模型的训练方法和效果，通过同时训练多个任务来提高跨语言模型的泛化能力和性能，并验证多任务学习对跨语言模型的影响。

5. 跨语言问答系统的构建与评估——构建跨语言问答系统，通过跨语言模型实现问题的自动解析和答案的生成，并评估系统在多语言环境下的效果和可用性。

6. 基于预训练的跨语言模型的应用于语音识别——将预训练的跨语言模型应用于语音识别任务中，研究其对语音识别准确性和多语种适应性的影响，并比较不同模型对多语种语音数据的处理能力。

选择适合自己兴趣和研究方向的选题，并与导师进行深入讨论和确认。
```

<br/>color2
对于不同的问题与应用场景，可能需要设置不同的 temperature。

<br/>

+ 在搭建的**个人知识库助手项目**中，一般将 temperature **设置为 0**，从而保证助手对知识库内容的稳定使用，规避错误内容、模型幻觉；
+ 在**产品智能客服、科研论文写作**等场景中，同样更需要**稳定性**而不是创造性；
+ 但在**个性化 AI、创意营销文案生成**等场景中，就**更需要创意性**，从而更倾向于将 temperature 设置为较高的值。



