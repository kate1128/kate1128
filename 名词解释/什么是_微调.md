<br/>color2
**微调： 通过在特定数据集上进一步训练大语言模型，来提升模型在特定任务上的表现。**

<br/>

# 什么是 模型微调
模型微调是通过微调工具，使用独特的场景数据对平台的基础模型进行调整，帮助你快速定制一个更符合业务需求的大型模型。其优势在于对基础模型进行小幅调整以满足特定需求，相比于训练一个新模型，这种方法更为高效且成本更低。

微调就是把通用的东西像GPT-3这样的模型，对它们进行专业化变成ChatGPT之类的东西，具体的聊天用例，使它能很好地聊天。或者使用GPT-4，将它变成一个专门的GitHub代码助手，自动完成补全代码。

# 何时适合微调
你可以首先尝试调整提示或使用函数调用和检索功能等工具来改善结果。如果你发现基础模型及相关工具仍无法提供满意的答案或处理复杂的推理任务，则可以使用微调来获得更好的结果。

微调可以改善结果的典型场景包括：

+ 需要特定的风格或语气
+ 需要处理复杂任务
+ 需要提高输出可靠性
+ 新任务难以通过提示解释

# 有哪些微调方法？
## LoRA微调
含义： 通过在现有权重矩阵中添加低秩矩阵来调整模型，可以在增加少量计算负担的情况下有效调整模型。

优势：

+ 仅增加少量参数，参数效率高；
+ 资源利用少，训练周期短

## 全参数微调
含义： 调整预训练模型的所有参数以获得新模型。

优势：

+ 允许对模型进行全面调整，更好地适应新任务；
+ 在有足够数据和计算资源的情况下，更有可能达到最佳性能。

# RAG 和 微调的对比
可以参考下表，表格来源：

[Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997)

[面向大语言模型的检索增强生成技术：综述 [译]](https://baoyu.io/translations/ai-paper/2312.10997-retrieval-augmented-generation-for-large-language-models-a-survey)

| 特征比较 | RAG | 微调 |
| --- | --- | --- |
| 知识更新 | 直接更新检索知识库，**无需重新训练**。信息更新成本低，适合动态变化的数据。 | 通常需要**重新训练**来保持知识和数据的更新。更新成本高，适合静态数据。 |
| 外部知识 | **擅长利用外部资源**，特别适合处理文档或其他结构化/非结构化数据库。 | 将**外部知识学习到 LLM 内部**。 |
| 数据处理 | 对数据的处理和操作要求极低。 | 依赖于**构建高质量的数据集**，有限的数据集可能无法显著提高性能。 |
| 模型定制 | 侧重于信息检索和融合外部知识，但可能无法充分定制模型行为或写作风格。 | 可以**根据特定风格或术语调整 LLM 行为、写作风格或特定领域知识**。 |
| 可解释性 | 可以**追溯到具体的数据来源，有较好的可解释性和可追踪性**。 | 黑盒子，可解释性相对较低。 |
| 计算资源 | 需要额外的资源来支持检索机制和数据库的维护。 | 依赖**高质量的训练数据集和微调目标，对计算资源的要求较高**。 |
| 推理延迟 | **增加了检索步骤的耗时** | **单纯 LLM 生成的耗时** |
| 降低幻觉 | 通过**检索到的真实信息生成回答，降低了产生幻觉的概率**。 | **模型学习特定领域的数据有助于减少幻觉，但面对未见过的输入时仍可能出现幻觉**。 |
| 伦理隐私 | 检索和使用外部数据可能引发伦理和隐私方面的问题。 | **训练数据中的敏感信息需要妥善处理，以防泄露**。 |


