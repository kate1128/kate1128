2021 年，**提示学习**（Prompt Learning）的研究浪潮兴起。而早在 2020 年，OpenAI 在 NeurIPS 2020 发表的一篇论文 [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) 中就已经探讨了如何利用提示学习来提升大语言模型（Large Language Models, LLMs）的推理能力。

论文中介绍了` Zero-shot、One-shot、Few-shot` 三种不同的提示方法，如下图示意。

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736143804901-faa31fe3-ad0b-403e-ac7a-ddbc0ec17748.png)

**在提示学习中，Zero-shot、One-shot 和 Few-shot 三者之间的差异为**：

+ `Zero-shot` 学习指的是模型在没有看到任何具体示例的情况下，直接对未知类别进行分类或执行任务的能力。在这种情况下，模型仅依赖于其在训练过程中获得的知识和泛化能力。对于提示学习来说，**Zero-shot 场景通常意味着你会给模型一个任务描述或一个问题，但不提供任何具体的示例作为参考**。模型需要根据其先前的知识和理解来生成答案。
+ `One-shot` 学习是指模型在看到一个（或每类一个）具体示例后，就能够执行某项任务或识别新类别的能力。这意味着模型通过观察单一实例就能够学习新概念或任务。在提示学习中，**这通常涉及到向模型展示一个示例**（包括问题和答案），然后立即要求它处理一个类似但不同的问题。这要求模型能够从极少量的数据中迅速学习并泛化。
+ `Few-shot` 学习与 One-shot 学习类似，指的是模型在看到少量（通常是几个而非一个，但远少于传统机器学习项目中使用的样本数量）示例后执行任务的能力。**这种方法允许模型通过观察几个示例来更好地理解新任务或类别**。在提示学习框架下，**这意味着你会给模型提供几个相关问题及其答案作为示例**，然后让它处理新问题。

<br/>color2
`"Few-shot" prompting`（少样本提示），即在要求模型执行实际任务之前，给模型提供一两个参考样例，让模型了解的要求和期望的输出样式。

<br/>

**小结**：Zero-shot、One-shot 和 Few-shot 学习代表了 LLM 处理未知任务时依赖已有知识量级的不同阶段。Zero-shot 依赖于模型的泛化能力；One-shot 要求模型能从单一实例中快速学习；而 Few-shot 则提供了稍微多一些的示例来帮助模型适应新任务。提示学习作为一种灵活的方法，在所有这三种情况下都非常有用，因为它允许研究人员以自然语言形式直接与模型交互，从而更容易地引导模型理解和执行新任务。

##  示例
[第四步：示例设计](https://www.yuque.com/qiaokate/su87gb/qk67engyx1vuv3h7)

