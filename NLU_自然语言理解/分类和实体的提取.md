# 概念
## ChatGPT API
这里我们介绍`openai`的`ChatGPT`接口，利用大模型的`In-Context`能力进行`Zero-Shot`或`Few-Shot`的推理。这里有四个概念需要先稍微解释一下：

<br/>success
+ `GPT`：全称是`Generative Pretrained Transformer`，生成式预训练`Transformer`。大家只要知道它是一个大模型的名字即可。
+ `In-Context`：简单来说就是一种上下文能力，也就是模型只要根据输入的文本就可以自动给出对应的结果，这种能力是大模型在学习了非常多的文本后获得的。可以看作是一种内在的理解能力。
+ `**Zero-Shot**`**：直接给模型文本，让它给出你要的标签或输出。**
+ `**Few-Shot**`**：给模型一些类似的Case（输入+输出），再拼上一个新的没有输出的输入，让模型给出输出。**

<br/>

如果对`In-Context`更多细节感兴趣的，可以阅读[GPT3 和它的 In-Context Learning | Yam](https://yam.gift/2023/01/20/NLP/2023-01-20-GPT3/)。接下来，我们就可以用同一个接口，只要通过**构造不同的输入就可以完成不同的任务**。换句话说，通过使用GPT大模型的`In-Context`能力，我们只需要输入的时候告诉模型我们的任务就行。



我们看看具体的用法，相比上一章的`Embedding`接口，它的接口参数要复杂多了，重要的参数包括：

<br/>success
+ `**model**`**：指定的模型**，`gpt-3.5-turbo`就是其中一个模型，大家可以根据自己的需要，参考官方[列表](https://platform.openai.com/docs/models/gpt-3)进行选择，一般需要综合价格和效果进行权衡。
+ `**messages**`**：会话消息，支持多轮，多轮就是多条**。每一条消息为一个字典，包含「`role`」和「`content`」两个字段。如：`[{"role": "user", "content": "Hello!"}]`
+ `**max_tokens**`**：生成的最大Token数，默认为16**。注意这里的Token数不一定是字数（但对中文来说几乎一致）。Prompt+生成的文本，所有的Token长度不能超过模型的上下文长度（一般是2048，新的是4096，具体可以参考上面的链接）。
+ `**temperature**`**：温度，默认为1**。采样温度，介于0和2之间。较高的值（如0.8）将使输出更加随机，而较低的值（如0.2）将使其更加集中和确定。通常建议调整这个参数或下面的top_p，但不能同时更改两者。
+ `**top_p**`**：采样topN分布，默认为1**。0.1意味着Next Token只选择前10%概率的。
+ `**stop**`**：停止的Token或序列，默认为null，最多4个**，如果遇到该Token或序列就停止继续生成。注意生成的结果中不包含stop。
+ `**presence_penalty**`**：存在惩罚，默认为0，介于-2.0和2.0之间的数字**。正值会根据新Token到目前为止是否出现在文本中来惩罚它们，从而增加模型讨论新主题的可能性。
+ `**frequency_penalty**`**：频率惩罚，默认为0，介于-2.0和2.0之间的数字**。正值会根据新Token到目前为止在文本中的现有频率来惩罚新Token，降低模型重复生成同一行的可能性。

<br/>

更多可以参考：[API Reference - OpenAI API](https://platform.openai.com/docs/api-reference/chat)，在大部分情况下，我们只需考虑上面这几个参数即可，甚至大部分时候只需要前两个参数，其他的用默认也行。不过熟悉上面的参数将帮助你更好地使用API。值得再次一提的是，接口支持多轮，而且多轮非常简单，只需要把历史会话加进去就可以了。

## 智谱AI接口
智谱AI接口可以参考：[智谱AI开放平台](https://open.bigmodel.cn/dev/api#glm-3-turbo)。

关于`temperature`, `top_p`, `top_k`, `freqency_penalty`等参数的原理可以参考：[hugging-llm/resources/231223早早聊.pptx at main · datawhalechina/hugging-llm](https://github.com/datawhalechina/hugging-llm/blob/main/resources/231223%E6%97%A9%E6%97%A9%E8%81%8A.pptx)

# 使用
## chatGPT
```python
from openai import OpenAI
client = OpenAI(api_key="YOUR OPENAI KEY")
```

```python
def ask(content):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo", 
        messages=[{"role": "user", "content": content}]
    )

    ans = response.choices[0].message.content
    return ans
```

### 官方示例
#### Zero-Shot
先来个最简单的情感分类的例子，我们分别展示一下`Zero-Shot`和`Few-Shot`。

```python
# Zero-Shot
# 来自openai官方文档
prompt="""The following is a list of companies and the categories they fall into:

Apple, Facebook, Fedex

Apple
Category:
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
Technology/Electronics  
  
Facebook  
Category:  
Social media/Technology  
  
Fedex  
Category:  
Logistics/Shipping

<br/>

#### Few-Shot
```python
# Few-Shot
prompt = """今天真开心。-->正向
心情不太好。-->负向
我们是快乐的年轻人。-->
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
正向

<br/>

#### 实体识别
再来个实体识别的例子。

```python
# Zero-Shot 来自openai官方文档
prompt = """
From the text below, extract the following entities in the following format:
Companies: <comma-separated list of companies mentioned>
People & titles: <comma-separated list of people mentioned (with their titles or roles appended in parentheses)>

Text:
In March 1981, United States v. AT&T came to trial under Assistant Attorney General William Baxter. AT&T chairman Charles L. Brown thought the company would be gutted. He realized that AT&T would lose and, in December 1981, resumed negotiations with the Justice Department. Reaching an agreement less than a month later, Brown agreed to divestiture—the best and only realistic alternative. AT&T's decision allowed it to retain its research and manufacturing arms. The decree, titled the Modification of Final Judgment, was an adjustment of the Consent Decree of 14 January 1956. Judge Harold H. Greene was given the authority over the modified decree....

In 1982, the U.S. government announced that AT&T would cease to exist as a monopolistic entity. On 1 January 1984, it was split into seven smaller regional companies, Bell South, Bell Atlantic, NYNEX, American Information Technologies, Southwestern Bell, US West, and Pacific Telesis, to handle regional phone services in the U.S. AT&T retains control of its long distance services, but was no longer protected from competition.
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
Companies: AT&T, Bell South, Bell Atlantic, NYNEX, American Information Technologies, Southwestern Bell, US West, Pacific Telesis  
  
People & titles:   
- Assistant Attorney General William Baxter  
- AT&T chairman Charles L. Brown  
- Judge Harold H. Greene

<br/>

### 举例
#### Few-Shot
上面是官方给的一个`Zero-Shot`的例子，我们来造一个`Few-Shot`的例子，实体给设置的稍微特殊一些。

```python
# Few-Shot
prompt = """
根据下面的示例格式抽取给定Text中的实体，格式为：
和弦: <实体用逗号分割>


示例Text:
增三和弦是大三度+大三度的增五度音，减三和弦是小三度+小三度的减五度音。
和弦：增三和弦,减三和弦

给定Text:
三和弦是由3个按照三度音程关系排列起来的一组音。大三和弦是大三度+小三度的纯五度音，小三和弦是小三度+大三度的纯五度音。
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
和弦: 三和弦,大三和弦,小三和弦

<br/>

#### 明确的要求和指令
我们也可以向它提出明确的要求和指令：

```python
prompt="""please output the category of the following companies:
Apple, Facebook, Fedex

The output format should be:
<company>
Category:
<category>
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
Apple  
Category:  
Technology/Electronics  
  
Facebook  
Category:  
Technology/Social Media  
  
Fedex  
Category:  
Logistics/Shipping

<br/>

#### 情感分类的例子
我们来试一下情感分类的例子：

```python
prompt = """请给出下面句子的情感倾向，情感倾向包括三种：正向、中性、负向。
句子：我们是快乐的年轻人。
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
正向

<br/>

#### 实体的例子
再来做一下实体的例子：

```python
prompt = """
请抽取给定Text中的实体，实体包括Company和People&Title，对于People，请同时给出它们的Title或role，跟在实体后面，用括号括起。

Text:
In March 1981, United States v. AT&T came to trial under Assistant Attorney General William Baxter. AT&T chairman Charles L. Brown thought the company would be gutted. He realized that AT&T would lose and, in December 1981, resumed negotiations with the Justice Department. Reaching an agreement less than a month later, Brown agreed to divestiture—the best and only realistic alternative. AT&T's decision allowed it to retain its research and manufacturing arms. The decree, titled the Modification of Final Judgment, was an adjustment of the Consent Decree of 14 January 1956. Judge Harold H. Greene was given the authority over the modified decree....

In 1982, the U.S. government announced that AT&T would cease to exist as a monopolistic entity. On 1 January 1984, it was split into seven smaller regional companies, Bell South, Bell Atlantic, NYNEX, American Information Technologies, Southwestern Bell, US West, and Pacific Telesis, to handle regional phone services in the U.S. AT&T retains control of its long distance services, but was no longer protected from competition.
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
实体抽取结果如下：  
  
1. Company:  
- AT&T  
- Bell South  
- Bell Atlantic  
- NYNEX  
- American Information Technologies  
- Southwestern Bell  
- US West  
- Pacific Telesis  
  
2. People & Title/Role:  
- Assistant Attorney General William Baxter  
- AT&T chairman Charles L. Brown  
- Judge Harold H. Greene

<br/>

#### 实体的另一个例子
我们最后试一下上面的另一个例子：

```python
prompt = """
根据下面的格式抽取给定Text中的和弦实体，实体必须包括“和弦”两个字。


Desired format:
和弦：<用逗号隔开>

Text:
三和弦是由3个按照三度音程关系排列起来的一组音。大三和弦是大三度+小三度的纯五度音，小三和弦是小三度+大三度的纯五度音。
"""
```

```python
ans = ask(prompt)
print(ans)
```

<br/>tips
和弦：三和弦, 大三和弦, 小三和弦

<br/>

## 智谱
```python
from zhipuai import ZhipuAI
zhipu_client = ZhipuAI(api_key="YOUR ZHIPU KEY")
```

```python
def ask_zhipu(content):
    response = zhipu_client.chat.completions.create(
        model="glm-3-turbo", 
        messages=[{"role": "user", "content": content}]
    )

    ans = response.choices[0].message.content
    return ans
```

### Few-Shot
也看一下智谱的答案：

```python
# Few-Shot
prompt = """今天真开心。-->正向
心情不太好。-->负向
我们是快乐的年轻人。-->
"""
```

```python
ask_zhipu(prompt)
```

<br/>tips
<font style="color:rgba(0, 0, 0, 0.87);">'正向激励和负向激励是团队管理中两种不同的激励方法。正向激励通常通过奖励和表扬来强化人们的行为，以提高他们的积极性和动力。例如，当一个人感到开心和快乐时，这可以被视为一种正向激励，因为这会鼓励他们保持积极的态度和行为。\n\n相反，负向激励通常通过惩罚和批评来阻止或减少不良行为。当一个人感到心情不好时，这可能是因为他们经历了负向激励，如批评或失败的经历，这可能会导致他们产生消极的情绪和态度。\n\n最后，"我们是快乐的年轻人"这句话表达了积极向上的态度和乐观的情感，这可以被视为一种正向激励，因为它鼓励人们保持快乐和积极的生活态度。'</font>

<br/>

> 看起来说的有点多
>

### Few-Shot
上面是官方给的一个`Zero-Shot`的例子，我们来造一个`Few-Shot`的例子，实体给设置的稍微特殊一些。

```python
# Few-Shot
prompt = """
根据下面的示例格式抽取给定Text中的实体，格式为：
和弦: <实体用逗号分割>


示例Text:
增三和弦是大三度+大三度的增五度音，减三和弦是小三度+小三度的减五度音。
和弦：增三和弦,减三和弦

给定Text:
三和弦是由3个按照三度音程关系排列起来的一组音。大三和弦是大三度+小三度的纯五度音，小三和弦是小三度+大三度的纯五度音。
"""
```

```python
ask_zhipu(prompt)
```

<br/>tips
<font style="color:rgba(0, 0, 0, 0.87);">'和弦：大三和弦,小三和弦'</font>

<br/>

Nice，不是么。可以尝试如果不给这个例子，它会输出什么。

### 情感分类的例子
我们来试一下情感分类的例子：

```python
prompt = """请给出下面句子的情感倾向，情感倾向包括三种：正向、中性、负向。
句子：我们是快乐的年轻人。
"""
```

```python
ask_zhipu(prompt)
```

<br/>tips
<font style="color:rgba(0, 0, 0, 0.87);">'这个句子的情感倾向是正向。'</font>

<br/>

这次好多了，大家不妨试着让其只输出情感，不要输出其他任何多余的字。

### 实体的另一个例子
我们最后试一下上面的另一个例子：

```python
prompt = """
根据下面的格式抽取给定Text中的和弦实体，实体必须包括“和弦”两个字。


Desired format:
和弦：<用逗号隔开>

Text:
三和弦是由3个按照三度音程关系排列起来的一组音。大三和弦是大三度+小三度的纯五度音，小三和弦是小三度+大三度的纯五度音。
"""
```

```python
ask_zhipu(prompt)
```

<br/>tips
<font style="color:rgba(0, 0, 0, 0.87);">'和弦：三和弦，大三和弦，小三和弦'</font>

<br/>

## 总结
模型能力差不多的时候，描述越清晰，得到的结果越相近。上面的例子中，我们还尝试用了中英文混合，它也完全没问题。

大家不妨多多尝试，也可以参考[ChatGPT Prompt 工程：设计、实践与思考 | Yam](https://yam.gift/2023/01/25/NLP/2023-01-25-ChatGPT-Prompt-Engineering/) 中的写法，总的来说，它并没有什么标准答案，最多也是一种习惯或约定。大家可以自由尝试，不用有任何负担。

实际上，关于这个怎么向“ChatGPT”提问早就有了一个成熟的技术方案：`Prompt`工程，大家可以进一步阅读[ChatGPT Prompt 工程：设计、实践与思考 | Yam](https://yam.gift/2023/01/25/NLP/2023-01-25-ChatGPT-Prompt-Engineering/)。这里给出一些常见的建议：

1. 清晰，切忌复杂或歧义，如果有术语，应定义清楚。
2. 具体，描述语言应尽量具体，不要抽象活模棱两可。
3. 聚焦，问题避免太泛或开放。
4. 简洁，避免不必要的描述。
5. 相关，主要指主题相关，而且是整个对话期间，不要东一瓢西一瓤。

一般来说，当任务比较复杂时，我们可以给它一些`**示例（Few-Shot）**`；正常情况下，只要直接描述清楚要求即可。新手容易忽略的地方：

1. 没有说明具体的输出目标。
2. 在一次对话中混合多个主题。
3. 让语言模型做数学题。
4. 没有给出想要什么的示例样本。
5. 反向提示。也就是一些反面例子。
6. 要求他一次只做一件事。可以将步骤捆绑在一起一次说清，不要拆的太碎。







