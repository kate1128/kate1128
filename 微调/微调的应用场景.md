> 在这一节中，会了解微调真正融入训练流程的地方。微调实际上是在“预训练”这一步骤后
>

#  微调的演进
1. **微调前的状态**：模型最初是随机的，没有任何知识，通过预测下一个token进行自监督学习。
2. **预训练过程**：模型从大量未标记的网络数据中学习，这一过程称为自监督学习，需要大量的数据清洗和准备工作。
3. **开源项目The Pile**：Eleuther AI创建的一个包含22个不同数据集的开源数据集，用于模型预训练。
4. **预训练的挑战**：预训练过程昂贵且耗时，因为模型需要从完全随机状态学习理解文本。
5. **微调的作用**：微调是在预训练模型的基础上进一步训练，以适应特定任务或数据集，需要的数据量较少。
6. **微调的好处**：微调可以改变模型的行为，使其更专注于特定任务，如对话、信息抽取或文本扩展等。
7. **微调的步骤**：包括识别任务、选择任务、获取数据、微调小模型等。
8. **实验**：文档提供了如何查看预训练数据集和微调数据集的示例代码，包括如何构造prompt模板和处理数据。
9. **数据存储**：讨论了如何将微调数据存储为.jsonl格式，以及如何从Hugging Face平台加载数据集。



微调模型，可以遵守下面的步骤：

1. 通过 prompt 工程首先识别可以完成的任务
2. 寻找觉得大模型做的还不错的任务
3. 挑选一个任务
4. 获取对应任务的，可以是1000对输入输出（要比原先大模型表现要好）
5. 用这些数据微调一个小模型

# 实验
接下来来看看原有大模型和微调后的效果区别：

```python
# 导入相应库
import jsonlines
import itertools
import pandas as pd
# pprint()函数作用是格式化打印输出对象，使输出更加规整美观
from pprint import pprint

import datasets
from datasets import load_dataset
```

## 查看预训练数据集
1. 导入数据集  [https://huggingface.co/datasets/allenai/c4/resolve/1ddc917116b730e1859edef32896ec5c16be51d0/en/c4-train.00000-of-01024.json.gz](https://huggingface.co/datasets/allenai/c4/resolve/1ddc917116b730e1859edef32896ec5c16be51d0/en/c4-train.00000-of-01024.json.gz)

```python
# 导入数据集  https://huggingface.co/datasets/allenai/c4/resolve/1ddc917116b730e1859edef32896ec5c16be51d0/en/c4-train.00000-of-01024.json.gz
pretrained_dataset = load_dataset("./c4-train.00000-of-01024.json/", "en", split="train", streaming=True)
```

2. 查看数据集（同时也是一个迭代器）的前n个元素

```python
# 查看数据集（同时也是一个迭代器）的前n个元素
n = 5
print("Pretrained dataset:")
# 语法itertools.islice(iterable, start, stop, step) 并返回一个迭代器对象
top_n = itertools.islice(pretrained_dataset, n)
for i in top_n:
    print(i)
```

<details class="lake-collapse"><summary id="ud90c2766"><span class="ne-text">output：</span></summary><pre data-language="json" id="iOXbm" class="ne-codeblock language-json"><code>Pretrained dataset:
{'text': 'Beginners BBQ Class Taking Place in Missoula!\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': datetime.datetime(2019, 4, 25, 12, 57, 54), 'url': 'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'}
{'text': 'Discussion in \'Mac OS X Lion (10.7)\' started by axboi87, Jan 20, 2012.\nI\'ve got a 500gb internal drive and a 240gb SSD.\nWhen trying to restore using disk utility i\'m given the error &quot;Not enough space on disk ____ to restore&quot;\nBut I shouldn\'t have to do that!!!\nAny ideas or workarounds before resorting to the above?\nUse Carbon Copy Cloner to copy one drive to the other. I\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\'t be bootable. CCC usually works in &quot;file mode&quot; and it can easily copy a larger drive (that\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\nI\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\'t fit is there was slightly more than 4 GB of data.', 'timestamp': datetime.datetime(2019, 4, 21, 10, 7, 13), 'url': 'https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-disk.1311329/'}
{'text': 'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.', 'timestamp': datetime.datetime(2019, 4, 25, 10, 40, 23), 'url': 'https://awishcometrue.com/Catalogs/Clearance/Tweens/V1960-Find-A-Way'}
{'text': &quot;How many backlinks per day for new site?\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\n2) how long do I have to let my site age before I can start making more blinks?\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?&quot;, 'timestamp': datetime.datetime(2019, 4, 21, 12, 46, 19), 'url': 'https://www.blackhatworld.com/seo/how-many-backlinks-per-day-for-new-site.258615/'}
{'text': 'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what’s included in the mill levy measure.', 'timestamp': datetime.datetime(2019, 4, 20, 14, 33, 21), 'url': 'http://bond.dpsk12.org/category/news/'}</code></pre></details>
## 数据对比
读取`.jsonl`文件，并查看

```python
# .jsonl是一种常见的JOSN行格式化文件拓展名，即JOSN Lines。
# 而且.jsonal是一种优化了的JSON格式，非常适合存储、读取大量结构化数据
# 读取.jsonl文件，并查看
filename = "lamini_docs.jsonl"
instruction_dataset_df = pd.read_json(filename, lines=True)
instruction_dataset_df
```

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736153420160-75c4c495-6fa2-4225-8755-82243aed35f0.png)

## 格式化数据
使上述数据两列的“问题”和“答案”之间形成字典，并查看连接后的第一个文本

```python
# 使上述数据两列的“问题”和“答案”之间形成字典，并查看连接后的第一个文本
examples = instruction_dataset_df.to_dict()
text = examples["question"][0] + examples["answer"][0]
text
```

<details class="lake-collapse"><summary id="u7259228b"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="w8Fka" class="ne-codeblock language-json"><code>&quot;What are the different types of documents available in the repository (e.g., installation guide, API documentation, developer's guide)?Lamini has documentation on Getting Started, Authentication, Question Answer Model, Python Library, Batching, Error Handling, Advanced topics, and class documentation on LLM Engine available at https://lamini-ai.github.io/.&quot;</code></pre></details>
将不同对应的“对子”连起来

```python
# 将不同对应的“对子”连起来
if "question" in examples and "answer" in examples:
  text = examples["question"][0] + examples["answer"][0]
elif "instruction" in examples and "response" in examples:
  text = examples["instruction"][0] + examples["response"][0]
elif "input" in examples and "output" in examples:
  text = examples["input"][0] + examples["output"][0]
else:
  text = examples["text"][0]
```

构造一个 prompt 模板（包含“问题”和“答案”）

```python
# 构造一个 prompt 模板（包含“问题”和“答案”）
prompt_template_qa = """### Question:
{question}

### Answer:
{answer}"""
```

将第一个文本的“问题”和“答案”填进 prompt 模板

```python
# 将第一个文本的“问题”和“答案”填进 prompt 模板
question = examples["question"][0]
answer = examples["answer"][0]

text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)
text_with_prompt_template
```

<details class="lake-collapse"><summary id="ufd9eec8a"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="IAvI6" class="ne-codeblock language-json"><code>&quot;### Question:\nWhat are the different types of documents available in the repository (e.g., installation guide, API documentation, developer's guide)?\n\n### Answer:\nLamini has documentation on Getting Started, Authentication, Question Answer Model, Python Library, Batching, Error Handling, Advanced topics, and class documentation on LLM Engine available at https://lamini-ai.github.io/.&quot;</code></pre></details>
构造一个 prompt 模板（仅包含“问题”）

```python
# 构造一个 prompt 模板（仅包含“问题”）
prompt_template_q = """### Question:
{question}

### Answer:"""
```

依据字典键值对长度，依次将“问题”和“答案”填充进两个模板中

```python
# 依据字典键值对长度，依次将“问题”和“答案”填充进两个模板中
num_examples = len(examples["question"])
finetuning_dataset_text_only = []
finetuning_dataset_question_answer = []
for i in range(num_examples):
  question = examples["question"][i]
  answer = examples["answer"][i]

  text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)
    
  finetuning_dataset_text_only.append({"text": text_with_prompt_template_qa})

  text_with_prompt_template_q = prompt_template_q.format(question=question)
  finetuning_dataset_question_answer.append({"question": text_with_prompt_template_q, "answer": answer})
```

打印查看文本模板下列表的第一个元素

```python
# 打印查看文本模板下列表的第一个元素
pprint(finetuning_dataset_text_only[0])
```

<details class="lake-collapse"><summary id="u1d5b016d"><span class="ne-text">output：</span></summary><pre data-language="plain" id="cNfkI" class="ne-codeblock language-plain"><code>{'text': '### Question:\n'
  'What are the different types of documents available in the '
  &quot;repository (e.g., installation guide, API documentation, developer's &quot;
  'guide)?\n'
  '\n'
  '### Answer:\n'
  'Lamini has documentation on Getting Started, Authentication, '
  'Question Answer Model, Python Library, Batching, Error Handling, '
  'Advanced topics, and class documentation on LLM Engine available at '
  'https://lamini-ai.github.io/.'}</code></pre></details>
打印查看另一个模板下列表的第一个元素

```python
# 打印查看另一个模板下列表的第一个元素
pprint(finetuning_dataset_question_answer[0])
```

<details class="lake-collapse"><summary id="u31c335d7"><span class="ne-text">output：</span></summary><pre data-language="plain" id="vSRLl" class="ne-codeblock language-plain"><code>{'answer': 'Lamini has documentation on Getting Started, Authentication, '
  'Question Answer Model, Python Library, Batching, Error Handling, '
  'Advanced topics, and class documentation on LLM Engine available '
  'at https://lamini-ai.github.io/.',
  'question': '### Question:\n'
  'What are the different types of documents available in the '
  'repository (e.g., installation guide, API documentation, '
  &quot;developer's guide)?\n&quot;
  '\n'
  '### Answer:'}</code></pre></details>
## 储存数据的常见方式
```python
# 比如存储第二个模板下的内容为.jsonl格式，每一行都是json格式
with jsonlines.open(f'lamini_docs_processed.jsonl', 'w') as writer:
    writer.write_all(finetuning_dataset_question_answer)
```

如果之前将数据上传至 Hugging Face，那么可以下面这样拉取数据

```python
# 如果之前将数据上传至 Hugging Face，那么可以下面这样拉取数据
finetuning_dataset_name = "lamini/lamini_docs"
finetuning_dataset = load_dataset(finetuning_dataset_name)
print(finetuning_dataset)
```

<details class="lake-collapse"><summary id="uaa4e7f46"><span class="ne-text">output：</span></summary><pre data-language="json" id="C882C" class="ne-codeblock language-json"><code>DatasetDict({
    train: Dataset({
        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],
        num_rows: 1260
    })
    test: Dataset({
        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],
        num_rows: 140
    })
})</code></pre></details>
 

