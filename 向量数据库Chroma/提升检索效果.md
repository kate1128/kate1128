RAG（Retrieval Augmented Generation），又称检索增强生成，通过检索相关文本，为大语言模型（LLM）提供参考资料，从而提高LLM在特定任务上的回答准确性和可靠性。这种方法的问题在于，**嵌入模型可能会找到与查询相似主题的文本，但并不包含我们想要的答案，对LLM的回答形成干扰**。为解决这个问题，我们可以采用`**查询扩展（Query Expansion）**`的方法。

+ 方式一：通过不同方式重新措辞或重写初始查询，将其扩展为多个查询；
+ 方式二：猜测或给定一个参考答案，以查看我们的文本集合中是否有更像答案的内容，而不仅仅是和查询主题有关但不含答案的干扰项。

# 路线
### 基于`embedding`的检索技术概述
[基于Embedding的检索技术概述](https://www.yuque.com/qiaokate/su87gb/av3za1uc6plt9k6h)

### 检索陷阱——为何简单向量检索有时会失效
[检索陷阱](https://www.yuque.com/qiaokate/su87gb/hm3iqgnlzxxo2403)

### 查询拓展
[查询扩展](https://www.yuque.com/qiaokate/su87gb/rqr3egtn76ad0ipo)

### 运用交叉编码器重新排序
[交叉编码器重排序](https://www.yuque.com/qiaokate/su87gb/ttfonilu2g69e0qg)

### `Embedding Adaptors`
[Embedding适配器](https://www.yuque.com/qiaokate/su87gb/nw544gfn714y6ugn)

### 其他技术
基于`embedding`的检索技术仍然是一个非常活跃的研究领域，还有一些其他方法可以尝试提升检索效果，比如：

+ 微调一个`embedding`模型
+ 微调一个用于检索的`LLM`
+ 尝试更复杂的`embedding adaptor`
+ 尝试其他的相关性建模方法
+ 尝试更好的分块（`chunk`）方法

# 帮助
[帮助代码](https://www.yuque.com/qiaokate/su87gb/qzu3xrrcdlnnnwxq)

