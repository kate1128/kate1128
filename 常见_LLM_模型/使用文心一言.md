## 千帆 SDK
### API 申请指引
百度智能云千帆大模型平台提供了多种语言的[千帆 SDK](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/wlmhm7vuo)，开发者可使用 SDK，快捷地开发功能，提升开发效率。

在使用千帆 SDK 之前，需要先获取文心一言调用密钥，在代码中需要配置自己的密钥才能实现对模型的调用，下面以 [Python SDK](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/7lq3ft3pb)为例，介绍通过千帆 SDK 调用文心模型的流程。

首先需要有一个经过实名认证的百度账号，每一个账户可以创建若干个应用，每个应用会对应一个 `API_Key` 和 `Secret_Key`。

进入[文心千帆服务平台](https://console.bce.baidu.com/qianfan/overview)，点击上述`应用接入`按钮，创建一个调用文心大模型的应用。

![](https://cdn.nlark.com/yuque/0/2024/png/2639475/1735283814849-f05e4a7a-fcd3-4323-8ae3-671320d679e3.png)

接着点击`去创建`按钮，进入应用创建界面：

![](https://cdn.nlark.com/yuque/0/2024/png/2639475/1735283924556-e3abef47-938f-4cda-87af-5e021d4daafe.png)

简单输入基本信息，选择默认配置，创建应用即可。创建完成后，可以在控制台看到创建的应用的 `API Key`、![](../figures/C2-2-baidu_qianfan_4.png)**需要注意的是，千帆目前只有 **[Prompt模板](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Alisj3ard)**、**[Yi-34B-Chat](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/vlpteyv3c)** 和 **[Fuyu-8B公有云在线调用体验服务](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Qlq4l7uw6)**这三个服务是免费调用的，如果想体验其他的模型服务，需要在**[计费管理](https://console.bce.baidu.com/qianfan/chargemanage/list)**处开通相应模型的付费服务才能体验。**

将这里获取到的 `API Key`、`Secret Key` 填写至 `.env` 文件的 `QIANFAN_AK` 和 `QIANFAN_SK` 参数。

如果使用的是安全认证的参数校验，需要在[百度智能云控制台-用户账户-安全认证](https://console.bce.baidu.com/iam/#/iam/accesslist)页，查看 `Access Key`、`Secret Key`，并将获取到的参数相应的填写到 `.env` 文件的 `QIANFAN_ACCESS_KEY`、`QIANFAN_SECRET_KEY`。

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736214273235-d0bb07a8-2058-4a8f-984e-a3edcf9794f8.png)

然后执行以下代码，将密钥加载到环境变量中。

```python
from dotenv import load_dotenv, find_dotenv

# 读取本地/项目的环境变量。

# find_dotenv() 寻找并定位 .env 文件的路径
# load_dotenv() 读取该 .env 文件，并将其中的环境变量加载到当前的运行环境中  
# 如果设置的是全局的环境变量，这行代码则没有任何作用。
_ = load_dotenv(find_dotenv())
```

### 调用文心千帆 API
百度文心同样支持在传入参数的 `messages` 字段中配置 `user`、`assistant` 两个成员角色的 `prompt`，但与 `OpenAI` 的 `prompt` 格式不同的是，`[system prompt](https://www.yuque.com/qiaokate/su87gb/wh3c2yi2ifxwainx)`** **是通过另一个参数 `system` 字段传入的，而不是在 `messages` 字段中。

下面使用 `SDK`，封装一个 `get_completion` 函数供后续使用。

<br/>tips
**如果账户中没有免费的或者购买的额度，在执行下述代码调用文心 **`ERNIE-Bot`** 时，会有如下报错：**`error code: 17, err msg: Open api daily request limit reached`**。**

<br/>

点击[模型服务](https://console.bce.baidu.com/qianfan/ais/console/onlineService)可以查看千帆支持的全部模型列表。

![](https://cdn.nlark.com/yuque/0/2024/png/2639475/1735284031506-d096505f-2ec3-4062-8c4a-545d06dd3e09.png)

```python
import qianfan

def gen_wenxin_messages(prompt):
    '''
    构造文心模型请求参数 messages

    请求参数：
        prompt: 对应的用户提示词
    '''
    messages = [{"role": "user", "content": prompt}]
    return messages


def get_completion(prompt, model="ERNIE-Bot", temperature=0.01):
    '''
    获取文心模型调用结果

    请求参数：
        prompt: 对应的提示词
        model: 调用的模型，默认为 ERNIE-Bot，也可以按需选择 ERNIE-Bot-4 等其他模型
        temperature: 模型输出的温度系数，控制输出的随机程度，取值范围是 0~1.0，且不能设置为 0。温度系数越低，输出内容越一致。
    '''

    chat_comp = qianfan.ChatCompletion()
    message = gen_wenxin_messages(prompt)

    # 模型人设是通过 system 字段传入的，而不是在 messages 字段中
    resp = chat_comp.do(messages=message, 
                        model=model,
                        temperature = temperature,
                        system="是一名个人助理-小鲸鱼")

    return resp["result"]
```

如果是免费用户，在使用上述函数时，可以在入参中指定一个免费的模型（例如 `Yi-34B-Chat`）再运行：

1. 调用`get_completion`

```python
get_completion("好，介绍一下自己", model="Yi-34B-Chat")
```

<details class="lake-collapse"><summary id="ud90c2766"><span class="ne-text">output：</span></summary><p id="u64c0bf1d" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2025/png/2639475/1736231018339-48861b3b-325e-4cfc-847e-df4f5a9dc360.png" width="1012.8" id="u643540d1" class="ne-image"></p></details>
如果有文心系列模型 `ERNIE-Bot` 的使用额度，则可直接运行如下函数：

2. 调用`get_completion`

```python
get_completion("好，介绍一下自己")
```

<details class="lake-collapse"><summary id="u8fc24808"><span class="ne-text">output：</span></summary><p id="u0b8ef8a0" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2025/png/2639475/1736230999379-7da83ab8-87fb-4ee4-b76c-4c1e2b45a67e.png" width="1021.6" id="u5f48b7e1" class="ne-image"></p></details>
百度千帆提供了多种模型接口供调用，其中，上述使用的 `ERNIE-Bot` 模型的对话 `chat` 接口，也就是常说的百度文心大模型。

<br/>color2
此处简要介绍文心大模型接口的常用参数：

1. `**messages**`**，即调用的 **`**prompt**`。

文心的 `messages` 配置与 ChatGPT 有一定区别，其不支持 `max_token` 参数，由模型自行控制最大 token 数，`messages` 中的 `content` 总长度、`functions` 和 `system` 字段总内容不能超过 `20480` 个字符，且不能超过 `5120 tokens`，否则模型就会自行对前文依次遗忘。

文心的 `messages` 有以下几点要求：

    1. 一个成员为单轮对话，多个成员为多轮对话；
    2. 最后一个 `message` 为当前对话，前面的 `message` 为历史对话；
    3. 成员数目必须为奇数，`message` 中的 `role` 必须依次是 `user`、`assistant`。

注：这里介绍的是`ERNIE-Bot`模型的字符数和 `tokens` 限制，而参数限制因模型而异，请在文心千帆官网查看对应模型的参数说明。

2. `**stream**`**，是否使用流式传输**。
3. `**temperature**`**，温度系数，默认 **`**0.8**`，文心的 `temperature` 参数要求范围为` (0, 1.0]`，不能设置为 `0`。

<br/>

## ERNIE SDK
### API 申请指引
这里将使用 `ERNIE SDK` 中的 `ERNIE Bot` 来调用文心一言。`ERNIE Bot`为开发者提供了便捷易用的接口，使其能够轻松调用文心大模型的强大功能，涵盖了文本创作、通用对话、语义向量以及AI作图等多个基础功能。

`ERNIE SDK` 并不像 `千帆 SDK` 那样支持各种大语言模型， 而是只支持百度自家的文心大模型。目前 `ERNIE Bot `支持的模型有：

<br/>tips
+ ernie-3.5               文心大模型（ernie-3.5）
+ ernie-lite              文心大模型（ernie-lite）
+ ernie-4.0               文心大模型（ernie-4.0）
+ ernie-longtext          文心大模型（ernie-longtext）
+ ernie-speed             文心大模型（ernie-speed）
+ ernie-speed-128k        文心大模型（ernie-speed-128k）
+ ernie-tiny-8k           文心大模型（ernie-tiny-8k）
+ ernie-char-8k           文心大模型（ernie-char-8k）
+ ernie-text-embedding    文心百中语义模型
+ ernie-vilg-v2           文心一格模型

<br/>

在使用 ERNIE SDK 之前，需要先获取 `AI Studio` 后端的认证鉴权（`access token`），在代码中需要配置自己的密钥才能实现对模型的调用，下面以 [Ernie Bot](https://ernie-bot-agent.readthedocs.io/zh-cn/latest/sdk/)为例，介绍通过 `ERNIE Bot `调用文心模型的流程。

首先需要在[AI Studio星河社区](https://aistudio.baidu.com/index)注册并登录账号

![](https://cdn.nlark.com/yuque/0/2024/png/2639475/1735284140085-45c7e83f-3999-4600-a5de-84e8b05aaa9d.png)

点击 `个人中心-访问令牌` 获取账户的 access token，复制 access token 并且以此形式 `EB_ACCESS_TOKEN="..."` 保存到 `.env` 文件中。  
![](https://cdn.nlark.com/yuque/0/2024/png/2639475/1735284392970-d1f68ad8-e91f-47ff-9743-e4acdb4cb86f.png)

然后执行以下代码，将密钥加载到环境变量中。

```python
from dotenv import load_dotenv, find_dotenv

# 读取本地/项目的环境变量。

# find_dotenv() 寻找并定位 .env 文件的路径
# load_dotenv() 读取该 .env 文件，并将其中的环境变量加载到当前的运行环境中  
# 如果设置的是全局的环境变量，这行代码则没有任何作用。
_ = load_dotenv(find_dotenv())
```

### 调用 Ernie Bot API
```python
import erniebot
import os

erniebot.api_type = "aistudio"
erniebot.access_token = os.environ.get("EB_ACCESS_TOKEN")

def gen_wenxin_messages(prompt):
    '''
    构造文心模型请求参数 messages

    请求参数：
        prompt: 对应的用户提示词
    '''
    messages = [{"role": "user", "content": prompt}]
    return messages


def get_completion(prompt, model="ernie-3.5", temperature=0.01):
    '''
    获取文心模型调用结果

    请求参数：
        prompt: 对应的提示词
        model: 调用的模型
        temperature: 模型输出的温度系数，控制输出的随机程度，取值范围是 0~1.0，且不能设置为 0。温度系数越低，输出内容越一致。
    '''

    chat_comp = erniebot.ChatCompletion()
    message = gen_wenxin_messages(prompt)

    resp = chat_comp.create(messages=message, 
                        model=model,
                        temperature = temperature,
                        system="是一名个人助理")

    return resp["result"]
```

1. 调用`get_completion`

```python
get_completion("好，介绍一下自己")
```

<details class="lake-collapse"><summary id="ud36fb7e2"><span class="ne-text">output：</span></summary><pre data-language="python" id="WraWN" class="ne-codeblock language-python"><code>'嗨！我是的个人助理，随时准备帮解决问题、安排日程，或者聊聊天。有啥需要，尽管找我！'</code></pre></details>




