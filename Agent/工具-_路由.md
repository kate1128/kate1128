> 通过 langchain 去定义工具，把函数集成到里面
>

# 通过 Langchain 定义工具
## 通过装饰器直接定义 Tool
1.  `tool`装饰器包装了`search`函数

```python
# tool装饰器包装了search函数
@tool
def search(query: str) -> str:
    """在网络上查询天气"""
    return "42度"
```

2. 搜索工具的函数名

```python
# 搜索工具的函数名
print(search.name)
#搜索工具的功能描述（即函数注释）
print(search.description)
# 搜索工具需要传递的参数
print(search.args)
```

<details class="lake-collapse"><summary id="ub1c9bb3c"><span class="ne-text">output：</span></summary><pre data-language="json" id="Bfwf2" class="ne-codeblock language-json"><code>search
search(query: str) -&gt; str - 在网络上查询天气
{'query': {'title': 'Query', 'type': 'string'}}</code></pre></details>
## 通过`pydantic`类定义Tool
1. 导入 `Pydantic` 库中的 BaseModel 类和 Field 函数，它们用于定义数据模型和字段。

```python
# 导入 Pydantic 库中的 BaseModel 类和 Field 函数，它们用于定义数据模型和字段。
from pydantic import BaseModel, Field

class SearchInput(BaseModel):
    """
    定义了 SearchInput 类中的一个属性 query，它是一个字符串类型。通过 Field 函数，你为这个字段提供了一些配置
    其中 description 参数用于描述这个字段的用途，即 "Thing to search for"（要搜索的内容）。
    """
    query: str = Field(description="你需要搜索的东西")
```

2. 搜索工具类需要传递的参数

```python
# 搜索工具类需要传递的参数
search.args
```

<details class="lake-collapse"><summary id="ud90c2766"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="iOXbm" class="ne-codeblock language-json"><code>{'query': {'title': 'Query', 'type': 'string'}}</code></pre></details>
3. `args_schema`参数传递`SearchInput`工具类

```python
# args_schema参数传递SearchInput工具类
@tool(args_schema=SearchInput)
def search_zh(query: str) -> str:
    """在网上查找温度"""
    return "42度"
```

4. `search.args`

```python
search.args
```

<details class="lake-collapse"><summary id="u65e44dc5"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="i31yN" class="ne-codeblock language-json"><code>{'query': {'title': 'Query', 'type': 'string'}}</code></pre></details>
5. 执行

```python
search.run("圣弗朗西斯科")
```

<details class="lake-collapse"><summary id="u1c1d83a4"><span class="ne-text" style="color: var(--jp-cell-prompt-not-active-font-color)">output：</span></summary><pre data-language="json" id="tGS8c" class="ne-codeblock language-json"><code>'42度'</code></pre></details>
## 天气查询应用案例
整体代码逻辑：

1. 使用 `Pydantic` 定义了输入类`OpenMeteoInput`，以及输入的两个参数（经度和纬度）的输入格式
2. 定义了一个函数 `get_current_temperature`，该函数使用 `OpenMeteo API `获取给定坐标位置的当前温度。
3. `get_current_temperature`函数通过发送 HTTP 请求获取 API 响应，然后从响应中提取并计算出当前时间对应的温度。
4. `get_current_temperature`函数返回一个字符串，其中包含了当前温度的信息。

```python
# 导入所需的库
import requests
from pydantic import BaseModel, Field
import datetime

# 定义输入类（input schema）
class OpenMeteoInput(BaseModel):
    latitude: float = Field(..., description="要获取天气数据的位置的纬度") 
    longitude: float = Field(..., description="要获取天气数据的位置的经度") 

# 使用 @tool 装饰器并指定输入模型
@tool(args_schema=OpenMeteoInput)
def get_current_temperature(latitude: float, longitude: float) -> dict:
    """"获取给定坐标的温度"""

    # Open Meteo API 的URL
    BASE_URL = "https://api.open-meteo.com/v1/forecast"

    # 请求参数
    params = {
        'latitude': latitude,
        'longitude': longitude,
        'hourly': 'temperature_2m',
        'forecast_days': 1,
    }

    # 发送 API 请求
    response = requests.get(BASE_URL, params=params)

    # 检查响应状态码
    if response.status_code == 200:
        # 解析 JSON 响应
        results = response.json()
    else:
        # 处理请求失败的情况
        raise Exception(f"API Request failed with status code: {response.status_code}")

    # 获取当前 UTC 时间
    current_utc_time = datetime.datetime.utcnow()

    # 将时间字符串转换为 datetime 对象
    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]

    # 获取温度列表
    temperature_list = results['hourly']['temperature_2m']

    # 找到最接近当前时间的索引
    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))

    # 获取当前温度
    current_temperature = temperature_list[closest_time_index]

    # 返回当前温度的字符串形式
    return f'当前的温度是 {current_temperature}°C'
```

打印：

```python
# 工具的名字
print(get_current_temperature.name)
# 工具的功能描述
print(get_current_temperature.description)
# 工具的输入参数
print(get_current_temperature.args)
```

<details class="lake-collapse"><summary id="u949831b1"><span class="ne-text">output：</span></summary><pre data-language="python" id="ja97w" class="ne-codeblock language-python"><code>get_current_temperature
get_current_temperature(latitude: float, longitude: float) -&gt; dict - &quot;获取给定坐标的温度
{'latitude': {'title': 'Latitude', 'description': '要获取天气数据的位置的纬度', 'type': 'number'}, 'longitude': {'title': 'Longitude', 'description': '要获取天气数据的位置的经度', 'type': 'number'}}</code></pre></details>
## 通过 tool 定义 function
```python
# 导入openai的模板
from langchain.tools.render import format_tool_to_openai_function
```

```python
# 将定义好的工具直接传入模板，打印tool的名字、描述和输入参数格式
format_tool_to_openai_function(get_current_temperature)
```

<details class="lake-collapse"><summary id="u58fe801b"><span class="ne-text">output：</span></summary><pre data-language="python" id="jMqUl" class="ne-codeblock language-python"><code>{'name': 'get_current_temperature',
 'description': 'get_current_temperature(latitude: float, longitude: float) -&gt; dict - &quot;获取给定坐标的温度',
 'parameters': {'type': 'object',
                'properties': {'latitude': {'description': '要获取天气数据的位置的纬度',
                                            'type': 'number'},
                               'longitude': {'description': '要获取天气数据的位置的经度', 'type': 'number'}},
                'required': ['latitude', 'longitude']}}</code></pre></details>
1. 调用工具

```python
# 调用工具
get_current_temperature({"latitude": 13, "longitude": 14})
```

<details class="lake-collapse"><summary id="u244c34db"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="BIMZm" class="ne-codeblock language-json"><code>'当前的温度是 41.4°C'</code></pre></details>
2. 定义维基百科搜索的tool

```python
import wikipedia

# 定义维基百科搜索的tool
@tool
def search_wikipedia(query: str) -> str:
    """打开维基百科搜索并获得页面的摘要"""
    page_titles = wikipedia.search(query)
    summaries = []
    for page_title in page_titles[: 3]: #取前三个页面标题
        try:
            #使用 wikipedia 模块的 page 函数，获取指定标题的维基百科页面对象。
            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False) 
            # 获取页面摘要
            summaries.append(f"页面: {page_title}\n摘要: {wiki_page.summary}")
        except (
            self.wiki_client.exceptions.PageError,
            self.wiki_client.exceptions.DisambiguationError,
        ):
            pass
    if not summaries:
        return "维基百科没有搜索到合适的结果"
    return "\n\n".join(summaries)
```

3. 工具的名字

```python
# 工具的名字
search_wikipedia.name
```

<details class="lake-collapse"><summary id="u0e6abb6e"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="Z8MFa" class="ne-codeblock language-json"><code>'search_wikipedia'</code></pre></details>
4. 工具的描述

```python
# 工具的描述
search_wikipedia.description
```

<details class="lake-collapse"><summary id="u380384a8"><span class="ne-text">output：</span></summary><pre data-language="json" id="zqGkn" class="ne-codeblock language-json"><code>'search_wikipedia(query: str) -&gt; str - 打开维基百科搜索并获得页面的摘要'</code></pre></details>
5. 将工具格式化为 OpenAI 函数

```python
# 将工具格式化为 OpenAI 函数
format_tool_to_openai_function(search_wikipedia)
```

<details class="lake-collapse"><summary id="u0d0e9df4"><span class="ne-text">output：</span></summary><pre data-language="json" id="WxIz8" class="ne-codeblock language-json"><code>{'name': 'search_wikipedia',
  'description': 'search_wikipedia(query: str) -&gt; str - 打开维基百科搜索并获得页面的摘要',
  'parameters': {'type': 'object',
  'properties': {'query': {'type': 'string'}},
'required': ['query']}}</code></pre></details>
6. 调用

```python
# 调用
search_wikipedia({"query": "langchain"})
```

<details class="lake-collapse"><summary id="u60be3770"><span class="ne-text">output：报错</span></summary><pre data-language="json" id="aTOxs" class="ne-codeblock language-json"><code>---------------------------------------------------------------------------
TimeoutError                              Traceback (most recent call last)
File d:\anaconda\Lib\site-packages\urllib3\util\connection.py:85, in create_connection(address, timeout, source_address, socket_options)
     84     sock.bind(source_address)
---&gt; 85 sock.connect(sa)
     86 return sock

TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

During handling of the above exception, another exception occurred:

KeyboardInterrupt                         Traceback (most recent call last)
Cell In[22], line 14, in search_wikipedia(query)
     13     # 获取页面摘要
---&gt; 14     summaries.append(f&quot;Page: {page_title}\nSummary: {wiki_page.summary}&quot;)
     15 except (
     16     self.wiki_client.exceptions.PageError,
     17     self.wiki_client.exceptions.DisambiguationError,
     18 ):

File d:\anaconda\Lib\site-packages\wikipedia\wikipedia.py:530, in WikipediaPage.summary(self)
    528    query_params['pageids'] = self.pageid
--&gt; 530 request = _wiki_request(query_params)
    531 self._summary = request['query']['pages'][self.pageid]['extract']

File d:\anaconda\Lib\site-packages\wikipedia\wikipedia.py:737, in _wiki_request(params)
    735   time.sleep(int(wait_time.total_seconds()))
--&gt; 737 r = requests.get(API_URL, params=params, headers=headers)
    739 if RATE_LIMIT:

File d:\anaconda\Lib\site-packages\requests\api.py:73, in get(url, params, **kwargs)
     63 r&quot;&quot;&quot;Sends a GET request.
     64 
     65 :param url: URL for the new :class:`Request` object.
   (...)
     70 :rtype: requests.Response
     71 &quot;&quot;&quot;
---&gt; 73 return request(&quot;get&quot;, url, params=params, **kwargs)

File d:\anaconda\Lib\site-packages\requests\api.py:59, in request(method, url, **kwargs)
     58 with sessions.Session() as session:
---&gt; 59     return session.request(method=method, url=url, **kwargs)

File d:\anaconda\Lib\site-packages\requests\sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)
    588 send_kwargs.update(settings)
--&gt; 589 resp = self.send(prep, **send_kwargs)
    591 return resp

File d:\anaconda\Lib\site-packages\requests\sessions.py:725, in Session.send(self, request, **kwargs)
    724     gen = self.resolve_redirects(r, request, **kwargs)
--&gt; 725     history = [resp for resp in gen]
    726 else:

File d:\anaconda\Lib\site-packages\requests\sessions.py:725, in &lt;listcomp&gt;(.0)
    724     gen = self.resolve_redirects(r, request, **kwargs)
--&gt; 725     history = [resp for resp in gen]
    726 else:

File d:\anaconda\Lib\site-packages\requests\sessions.py:266, in SessionRedirectMixin.resolve_redirects(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)
    264 else:
--&gt; 266     resp = self.send(
    267         req,
    268         stream=stream,
    269         timeout=timeout,
    270         verify=verify,
    271         cert=cert,
    272         proxies=proxies,
    273         allow_redirects=False,
    274         **adapter_kwargs,
    275     )
    277     extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)

File d:\anaconda\Lib\site-packages\requests\sessions.py:703, in Session.send(self, request, **kwargs)
    702 # Send the request
--&gt; 703 r = adapter.send(request, **kwargs)
    705 # Total elapsed time of the request (approximately)

File d:\anaconda\Lib\site-packages\requests\adapters.py:486, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)
    485 try:
--&gt; 486     resp = conn.urlopen(
    487         method=request.method,
    488         url=url,
    489         body=request.body,
    490         headers=request.headers,
    491         redirect=False,
    492         assert_same_host=False,
    493         preload_content=False,
    494         decode_content=False,
    495         retries=self.max_retries,
    496         timeout=timeout,
    497         chunked=chunked,
    498     )
    500 except (ProtocolError, OSError) as err:

File d:\anaconda\Lib\site-packages\urllib3\connectionpool.py:714, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    713 # Make the request on the httplib connection object.
--&gt; 714 httplib_response = self._make_request(
    715     conn,
    716     method,
    717     url,
    718     timeout=timeout_obj,
    719     body=body,
    720     headers=headers,
    721     chunked=chunked,
    722 )
    724 # If we're going to release the connection in ``finally:``, then
    725 # the response doesn't need to know about the connection. Otherwise
    726 # it will also try to release it and we'll have a double-release
    727 # mess.

File d:\anaconda\Lib\site-packages\urllib3\connectionpool.py:403, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)
    402 try:
--&gt; 403     self._validate_conn(conn)
    404 except (SocketTimeout, BaseSSLError) as e:
    405     # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.

File d:\anaconda\Lib\site-packages\urllib3\connectionpool.py:1053, in HTTPSConnectionPool._validate_conn(self, conn)
   1052 if not getattr(conn, &quot;sock&quot;, None):  # AppEngine might not have  `.sock`
-&gt; 1053     conn.connect()
   1055 if not conn.is_verified:

File d:\anaconda\Lib\site-packages\urllib3\connection.py:363, in HTTPSConnection.connect(self)
    361 def connect(self):
    362     # Add certificate verification
--&gt; 363     self.sock = conn = self._new_conn()
    364     hostname = self.host

File d:\anaconda\Lib\site-packages\urllib3\connection.py:174, in HTTPConnection._new_conn(self)
    173 try:
--&gt; 174     conn = connection.create_connection(
    175         (self._dns_host, self.port), self.timeout, **extra_kw
    176     )
    178 except SocketTimeout:

File d:\anaconda\Lib\site-packages\urllib3\util\connection.py:91, in create_connection(address, timeout, source_address, socket_options)
     90 if sock is not None:
---&gt; 91     sock.close()
     92     sock = None

File d:\anaconda\Lib\socket.py:499, in socket.close(self)
    497     _ss.close(self)
--&gt; 499 def close(self):
    500     # This function should not reference any globals. See issue #808164.
    501     self._closed = True

KeyboardInterrupt: 

During handling of the above exception, another exception occurred:

NameError                                 Traceback (most recent call last)
Cell In[27], line 2
      1 # 调用
----&gt; 2 search_wikipedia({&quot;query&quot;: &quot;langchain&quot;})

File d:\anaconda\Lib\site-packages\langchain_core\tools.py:519, in BaseTool.__call__(self, tool_input, callbacks)
    517 def __call__(self, tool_input: str, callbacks: Callbacks = None) -&gt; str:
    518     &quot;&quot;&quot;Make tool callable.&quot;&quot;&quot;
--&gt; 519     return self.run(tool_input, callbacks=callbacks)

File d:\anaconda\Lib\site-packages\langchain_core\tools.py:419, in BaseTool.run(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)
    417 except (Exception, KeyboardInterrupt) as e:
    418     run_manager.on_tool_error(e)
--&gt; 419     raise e
    420 else:
    421     run_manager.on_tool_end(
    422         str(observation), color=color, name=self.name, **kwargs
    423     )

File d:\anaconda\Lib\site-packages\langchain_core\tools.py:376, in BaseTool.run(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)
    373     parsed_input = self._parse_input(tool_input)
    374     tool_args, tool_kwargs = self._to_args_and_kwargs(parsed_input)
    375     observation = (
--&gt; 376         self._run(*tool_args, run_manager=run_manager, **tool_kwargs)
    377         if new_arg_supported
    378         else self._run(*tool_args, **tool_kwargs)
    379     )
    380 except ValidationError as e:
    381     if not self.handle_validation_error:

File d:\anaconda\Lib\site-packages\langchain_core\tools.py:701, in StructuredTool._run(self, run_manager, *args, **kwargs)
    692 if self.func:
    693     new_argument_supported = signature(self.func).parameters.get(&quot;callbacks&quot;)
    694     return (
    695         self.func(
    696             *args,
    697             callbacks=run_manager.get_child() if run_manager else None,
    698             **kwargs,
    699         )
    700         if new_argument_supported
--&gt; 701         else self.func(*args, **kwargs)
    702     )
    703 raise NotImplementedError(&quot;Tool does not support sync&quot;)

Cell In[22], line 16, in search_wikipedia(query)
     13         # 获取页面摘要
     14         summaries.append(f&quot;Page: {page_title}\nSummary: {wiki_page.summary}&quot;)
     15     except (
---&gt; 16         self.wiki_client.exceptions.PageError,
     17         self.wiki_client.exceptions.DisambiguationError,
     18     ):
     19         pass
     20 if not summaries:

NameError: name 'self' is not defined</code></pre></details>
## 通过 API 定义 function 案例
```python
# openapi_spec_to_openai_fn可以把json格式的API定义转换成openai的function call格式
from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn
# OpenAPISpec是标准化的API格式定义
from langchain.utilities.openapi import OpenAPISpec
```

```python
# json格式的API定义
text = """
{
  "openapi": "3.0.0",
  "info": {
    "version": "1.0.0",
    "title": "Swagger Petstore",
    "license": {
      "name": "MIT"
    }
  },
  "servers": [
    {
      "url": "http://petstore.swagger.io/v1"
    }
  ],
  "paths": {
    "/pets": {
      "get": {
        "summary": "List all pets",
        "operationId": "listPets",
        "tags": [
          "pets"
        ],
        "parameters": [
          {
            "name": "limit",
            "in": "query",
            "description": "How many items to return at one time (max 100)",
            "required": false,
            "schema": {
              "type": "integer",
              "maximum": 100,
              "format": "int32"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A paged array of pets",
            "headers": {
              "x-next": {
                "description": "A link to the next page of responses",
                "schema": {
                  "type": "string"
                }
              }
            },
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Pets"
                }
              }
            }
          },
          "default": {
            "description": "unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      },
      "post": {
        "summary": "Create a pet",
        "operationId": "createPets",
        "tags": [
          "pets"
        ],
        "responses": {
          "201": {
            "description": "Null response"
          },
          "default": {
            "description": "unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/pets/{petId}": {
      "get": {
        "summary": "Info for a specific pet",
        "operationId": "showPetById",
        "tags": [
          "pets"
        ],
        "parameters": [
          {
            "name": "petId",
            "in": "path",
            "required": true,
            "description": "The id of the pet to retrieve",
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Expected response to a valid request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Pet"
                }
              }
            }
          },
          "default": {
            "description": "unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "Pet": {
        "type": "object",
        "required": [
          "id",
          "name"
        ],
        "properties": {
          "id": {
            "type": "integer",
            "format": "int64"
          },
          "name": {
            "type": "string"
          },
          "tag": {
            "type": "string"
          }
        }
      },
      "Pets": {
        "type": "array",
        "maxItems": 100,
        "items": {
          "$ref": "#/components/schemas/Pet"
        }
      },
      "Error": {
        "type": "object",
        "required": [
          "code",
          "message"
        ],
        "properties": {
          "code": {
            "type": "integer",
            "format": "int32"
          },
          "message": {
            "type": "string"
          }
        }
      }
    }
  }
}
"""
```

1. 从`text`中导入 API 的详细定义

```python
# 从text中导入API的详细定义
spec = OpenAPISpec.from_text(text)
```

<details class="lake-collapse"><summary id="uc7beb777"><span class="ne-text">output：</span></summary><pre data-language="json" id="n8IPT" class="ne-codeblock language-json"><code>Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.</code></pre></details>
2. 转换成`openai`的`fuction call`格式

```python
# 转换成openai的fuction call格式
pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)
```

3. 查看`fuction`的定义

```python
# 查看fuction的定义
pet_openai_functions
```

<details class="lake-collapse"><summary id="ua9c7ac0a"><span class="ne-text">output：</span></summary><pre data-language="json" id="S3OqB" class="ne-codeblock language-json"><code>[{'name': 'listPets',
  'description': 'List all pets',
  'parameters': {'type': 'object',
  'properties': {'params': {'type': 'object',
  'properties': {'limit': {'type': 'integer',
    'maximum': 100.0,
    'schema_format': 'int32',
    'description': 'How many items to return at one time (max 100)'}},
  'required': []}}}},
  {'name': 'createPets',
  'description': 'Create a pet',
  'parameters': {'type': 'object', 'properties': {}}},
  {'name': 'showPetById',
  'description': 'Info for a specific pet',
  'parameters': {'type': 'object',
  'properties': {'path_params': {'type': 'object',
  'properties': {'petId': {'type': 'string',
    'description': 'The id of the pet to retrieve'}},
  'required': ['petId']}}}}]</code></pre></details>
4. 导入模型

```python
# 导入模型
from langchain.chat_models import ChatOpenAI
```

5. 设置模型温度系数并传入`function`

```python
# 设置模型温度系数并传入function
model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)
```

6. 输入`query`，查看模型调用的`function`以及返回信息

```python
# 输入query，查看模型调用的function以及返回信息
model.invoke("这三只宠物的名字叫什么？")
```

<details class="lake-collapse"><summary id="uaa66be3c"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="NclWV" class="ne-codeblock language-json"><code>AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{&quot;params&quot;:{&quot;limit&quot;:3}}', 'name': 'listPets'}})</code></pre></details>
7. 输入`query`，查看模型调用的`function`以及返回信息

```python
model.invoke("告诉我id为42的宠物的消息")
```

<details class="lake-collapse"><summary id="u39ac7bdc"><span class="ne-text" style="color: var(--jp-cell-prompt-not-active-font-color)">output：</span></summary><pre data-language="json" id="b449w" class="ne-codeblock language-json"><code>AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{&quot;path_params&quot;:{&quot;petId&quot;:&quot;42&quot;}}', 'name': 'showPetById'}})</code></pre></details>
# 路由
展示一个函数调用的例子，用于在两个候选函数之间做出决策。

## Tool 转换为 Function
鉴于我们上面提到的工具，让我们将它们格式化为 OpenAI 函数，并展示相同的行为。

```python
# 将工具格式化为 OpenAI 函数
functions = [
    format_tool_to_openai_function(f) for f in [
        search_wikipedia, get_current_temperature
    ]
]
model = ChatOpenAI(temperature=0).bind(functions=functions)
```

1. 模型调用：圣佛朗西斯科现在的温度是多少？

```python
# 模型调用
model.invoke("圣佛朗西斯科现在的温度是多少？")
```

<details class="lake-collapse"><summary id="uf136d009"><span class="ne-text">output：</span></summary><pre data-language="json" id="QDUos" class="ne-codeblock language-json"><code>AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{&quot;latitude&quot;:37.7749,&quot;longitude&quot;:-122.4194}', 'name': 'get_current_temperature'}})</code></pre></details>
2. 模型调用：什么是`langchain`？

```python
# 模型调用
model.invoke("什么是langchain？")
```

<details class="lake-collapse"><summary id="u695b7715"><span class="ne-text">output：</span></summary><pre data-language="json" id="GiJ8W" class="ne-codeblock language-json"><code>AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{&quot;query&quot;:&quot;Langchain&quot;}', 'name': 'search_wikipedia'}})</code></pre></details>
3. 使用`template`构造`prompt`

```python
# 使用template构造prompt
from langchain.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "你是个乐于助人的助理"),
    ("user", "{input}"),
])

# 创建处理链，将 prompt和model连接起来
chain = prompt | model
```

4. 输入`query`进行调用

```python
# 输入query进行调用
chain.invoke({"input": "圣佛朗西斯科现在的温度是多少？"})
```

<details class="lake-collapse"><summary id="uc6dbb895"><span class="ne-text">output：</span></summary><pre data-language="json" id="VZE7Y" class="ne-codeblock language-json"><code>AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{&quot;latitude&quot;:37.7749,&quot;longitude&quot;:-122.4194}', 'name': 'get_current_temperature'}})</code></pre></details>
5. 导入输出解析的包

```python
# 导入输出解析的包
from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser
```

6. 创建处理链，将 `prompt`、`model` 和 `OpenAIFunctionsAgentOutputParser` 连接起来

```python
# 创建处理链，将 prompt、model 和 OpenAIFunctionsAgentOutputParser 连接起来
chain = prompt | model | OpenAIFunctionsAgentOutputParser()
```

7. 调用

```python
# 调用
result = chain.invoke({"input": "圣佛朗西斯科现在的温度是多少？"})
```

8. 打印返回的类型，可以判断是否产生`function`的调用

```python
# 打印返回的类型，可以判断是否产生function的调用
type(result)
```

<details class="lake-collapse"><summary id="u37e04d1f"><span class="ne-text">output：</span></summary><pre data-language="json" id="gBzQf" class="ne-codeblock language-json"><code>langchain_core.agents.AgentActionMessageLog</code></pre></details>
9. 查看调用的tool

```python
# 查看调用的tool
result.tool
```

<details class="lake-collapse"><summary id="udda8f62e"><span class="ne-text">output：</span></summary><pre data-language="json" id="e6dNB" class="ne-codeblock language-json"><code>'get_current_temperature'</code></pre></details>
10. 查看`tool`的输入，`result.message_log`可以查看调用结果

```python
# 查看tool的输入，result.message_log可以查看调用结果
result.tool_input
```

<details class="lake-collapse"><summary id="uceb39804"><span class="ne-text">output：</span></summary><pre data-language="json" id="ngSIr" class="ne-codeblock language-json"><code>{'latitude': 37.7749, 'longitude': -122.4194}</code></pre></details>
11. 调用的获取温度的工具

```python
# 调用的获取温度的工具
get_current_temperature(result.tool_input)
```

<details class="lake-collapse"><summary id="u656884b0"><span class="ne-text">output：</span></summary><pre data-language="json" id="xm1j8" class="ne-codeblock language-json"><code>'The current temperature is 9.4°C'</code></pre></details>
12. 继续调用

```python
# 继续调用
result = chain.invoke({"input": "你好!"})
```

13. 打印返回的类型，可以判断是否产生function的调用

```python
# 打印返回的类型，可以判断是否产生function的调用
type(result)
```

<details class="lake-collapse"><summary id="ua453cbd9"><span class="ne-text">output：</span></summary><pre data-language="json" id="gURro" class="ne-codeblock language-json"><code>langchain_core.agents.AgentFinish</code></pre></details>
14. 查看返回值

```python
# 查看返回值
result.return_values
```

<details class="lake-collapse"><summary id="u1f612738"><span class="ne-text" style="color: var(--jp-cell-prompt-not-active-font-color)">output：</span></summary><pre data-language="json" id="t0IhY" class="ne-codeblock language-json"><code>{'output': 'Well, hello there! How can I assist you today?'}</code></pre></details>
## 通过 route 进行 tools 的选择
```python
"""
route会根据result进行tools的选择：
AgentFinish：表示已经完成，可以输出
AgentActionMessageLog：表示未完成，需要继续进行route调用tools
"""
from langchain.schema.agent import AgentFinish
def route(result):
    if isinstance(result, AgentFinish):
        return result.return_values['output']
    else:
        tools = {
            "search_wikipedia": search_wikipedia, 
            "get_current_temperature": get_current_temperature,
        }
        return tools[result.tool].run(result.tool_input)
```

```python
chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route
```

```python
chain.invoke({"input": "你好！"})
```

<details class="lake-collapse"><summary id="u45755e75"><span class="ne-text">output：</span></summary><pre data-language="json" id="yyEoJ" class="ne-codeblock language-json"><code>'你好！有什么可以帮助你的吗？'</code></pre></details>
```python
result = chain.invoke({"input": "圣弗朗西斯科的天气现在怎么样？"})
result
```

<details class="lake-collapse"><summary id="u3c3bceea"><span class="ne-text">output：</span></summary><pre data-language="json" id="UnSxD" class="ne-codeblock language-json"><code>'The current temperature is 9.4°C'</code></pre></details>
```python
result = chain.invoke({"input": "什么是langchain?"})
result
```

<details class="lake-collapse"><summary id="u04c8c95e"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="j2qgA" class="ne-codeblock language-json"><code>'Page: LangChain\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n\nPage: OpenAI\nSummary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing &quot;safe and beneficial&quot; artificial general intelligence, which it defines as &quot;highly autonomous systems that outperform humans at most economically valuable work&quot;.\nAs one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial board members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft\'s Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\n\nPage: DataStax\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'</code></pre></details>
#  英文版提示
我们总结一下完整的调用流程：

构造Prompt --> 调用模型 --> 解析模型返回的结果 --> 进行路由选择对应的tool

```python
@tool
def search(query: str) -> str:
    """"Search for weather online"""
    return "42f"
```

```python
# 搜索工具的函数名
print(search.name)
#搜索工具的功能描述（即函数注释）
print(search.description)
# 搜索工具需要传递的参数
print(search.args)
```

```python
search
search(query: str) -> str - "Search for weather online
{'query': {'title': 'Query', 'type': 'string'}}
```

```python
from pydantic import BaseModel, Field

class SearchInput(BaseModel):
    query: str = Field(description="Thing to search for")
```

```python
search.args
```

<details class="lake-collapse"><summary id="u278f3df7"><span class="ne-text">output：</span></summary><pre data-language="json" id="OvStI" class="ne-codeblock language-json"><code>{'query': {'title': 'Query', 'type': 'string'}}</code></pre></details>
```python
search.run("sf")
```

<details class="lake-collapse"><summary id="ufd8f53da"><span class="ne-text">output：</span></summary><pre data-language="json" id="pbcdA" class="ne-codeblock language-json"><code>'42f'</code></pre></details>
```python
# 导入所需的库
import requests
from pydantic import BaseModel, Field
import datetime

# 定义输入类（input schema）
class OpenMeteoInput(BaseModel):
    latitude: float = Field(..., description="Latitude of the location to fetch weather data for") #要获取天气数据的位置的纬度
    longitude: float = Field(..., description="Longitude of the location to fetch weather data for") #要获取天气数据的位置的经度

# 使用 @tool 装饰器并指定输入模型
@tool(args_schema=OpenMeteoInput)
def get_current_temperature(latitude: float, longitude: float) -> dict:
    """"Fetch current temperature for given coordinates."""
    
    # Open Meteo API 的URL
    BASE_URL = "https://api.open-meteo.com/v1/forecast"
    
    # 请求参数
    params = {
        'latitude': latitude,
        'longitude': longitude,
        'hourly': 'temperature_2m',
        'forecast_days': 1,
    }

    # 发送 API 请求
    response = requests.get(BASE_URL, params=params)
    
    # 检查响应状态码
    if response.status_code == 200:
        # 解析 JSON 响应
        results = response.json()
    else:
        # 处理请求失败的情况
        raise Exception(f"API Request failed with status code: {response.status_code}")

    # 获取当前 UTC 时间
    current_utc_time = datetime.datetime.utcnow()
    
    # 将时间字符串转换为 datetime 对象
    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]
    
    # 获取温度列表
    temperature_list = results['hourly']['temperature_2m']
    
    # 找到最接近当前时间的索引
    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))
    
    # 获取当前温度
    current_temperature = temperature_list[closest_time_index]
    
    # 返回当前温度的字符串形式
    return f'The current temperature is {current_temperature}°C'
```

```python
# 工具的名字
print(get_current_temperature.name)
# 工具的功能描述
print(get_current_temperature.description)
# 工具的输入参数
print(get_current_temperature.args)
```

```python
get_current_temperature
get_current_temperature(latitude: float, longitude: float) -> dict - "Fetch current temperature for given coordinates.
{'latitude': {'title': 'Latitude', 'description': 'Latitude of the location to fetch weather data for', 'type': 'number'}, 'longitude': {'title': 'Longitude', 'description': 'Longitude of the location to fetch weather data for', 'type': 'number'}}
```

```python
# 导入openai的模板
from langchain.tools.render import format_tool_to_openai_function

format_tool_to_openai_function(get_current_temperature)
```

<details class="lake-collapse"><summary id="ucb391a43"><span class="ne-text">output：</span></summary><pre data-language="json" id="O8JWW" class="ne-codeblock language-json"><code>{'name': 'get_current_temperature',
  'description': 'get_current_temperature(latitude: float, longitude: float) -&gt; dict - &quot;Fetch current temperature for given coordinates.',
  'parameters': {'type': 'object',
  'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',
  'type': 'number'},
'longitude': {'description': 'Longitude of the location to fetch weather data for',
  'type': 'number'}},
'required': ['latitude', 'longitude']}}</code></pre></details>
```python
get_current_temperature({"latitude": 13, "longitude": 14})
```

<details class="lake-collapse"><summary id="uf3425d50"><span class="ne-text">output：</span></summary><pre data-language="json" id="Hhg8M" class="ne-codeblock language-json"><code>'The current temperature is 41.4°C'</code></pre></details>
```python
import wikipedia

# 定义维基百科搜索的tool
@tool
def search_wikipedia(query: str) -> str:
    """Run Wikipedia search and get page summaries."""
    page_titles = wikipedia.search(query)
    summaries = []
    for page_title in page_titles[: 3]: #取前三个页面标题
        try:
            #使用 wikipedia 模块的 page 函数，获取指定标题的维基百科页面对象。
            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False) 
            # 获取页面摘要
            summaries.append(f"Page: {page_title}\nSummary: {wiki_page.summary}")
        except (
            self.wiki_client.exceptions.PageError,
            self.wiki_client.exceptions.DisambiguationError,
        ):
            pass
    if not summaries:
        return "No good Wikipedia Search Result was found"
    return "\n\n".join(summaries)
```

```python
# 将工具格式化为 OpenAI 函数
format_tool_to_openai_function(search_wikipedia)
```

<details class="lake-collapse"><summary id="ub4800c19"><span class="ne-text">output：</span></summary><pre data-language="json" id="ThGmZ" class="ne-codeblock language-json"><code>{'name': 'search_wikipedia',
  'description': 'search_wikipedia(query: str) -&gt; str - Run Wikipedia search and get page summaries.',
  'parameters': {'type': 'object',
  'properties': {'query': {'type': 'string'}},
  'required': ['query']}}</code></pre></details>
```python
from langchain.chat_models import ChatOpenAI
# 将工具格式化为 OpenAI 函数
functions = [
    format_tool_to_openai_function(f) for f in [
        search_wikipedia, get_current_temperature
    ]
]
model = ChatOpenAI(temperature=0).bind(functions=functions)
```

```python
d:\anaconda\Lib\site-packages\langchain_core\_api\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.
  warn_deprecated(
```

```python
# 使用template构造prompt
from langchain.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are helpful but sassy assistant"),
    ("user", "{input}"),
])

# 创建处理链，将 prompt和model连接起来
chain = prompt | model
```

```python
# 导入输出解析的包
from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser

chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route
```

```python
# 调用
result = chain.invoke({"input": "what is the weather in sf right now"})
```

```python
result
```

<details class="lake-collapse"><summary id="u35eefc04"><span class="ne-text">output：</span></summary><pre data-language="json" id="jWkEZ" class="ne-codeblock language-json"><code>'The current temperature is 8.8°C'</code></pre></details>
```python
# 调用并查看结果
chain.invoke({"input": "hi!"})
```

<details class="lake-collapse"><summary id="u4dbef499"><span class="ne-text">output：</span></summary><pre data-language="json" id="aCqh8" class="ne-codeblock language-json"><code>'Well, hello there! How can I assist you today?'</code></pre></details>
```python
# 调用
result = chain.invoke({"input": "langchain?"})
result
```

<details class="lake-collapse"><summary id="ubd65c861"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="N9z1P" class="ne-codeblock language-json"><code>'Page: LangChain\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n\nPage: OpenAI\nSummary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing &quot;safe and beneficial&quot; artificial general intelligence, which it defines as &quot;highly autonomous systems that outperform humans at most economically valuable work&quot;.\nAs one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial board members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft\'s Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\n\nPage: DataStax\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'</code></pre></details>
```python
# 调用
result = chain.invoke({"input": "What is the weather in san francisco right now?"})
result
```

<details class="lake-collapse"><summary id="u3cd68dea"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="x2i9I" class="ne-codeblock language-json"><code>AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{&quot;latitude&quot;:37.7749,&quot;longitude&quot;:-122.4194}', 'name': 'get_current_temperature'}})</code></pre></details>


```python
# 导入tool包
from langchain.agents import tool
```

```python
from langchain.schema.agent import AgentFinish
def route(result):
    if isinstance(result, AgentFinish):
        return result.return_values['output']
    else:
        tools = {
            "search_wikipedia": search_wikipedia, 
            "get_current_temperature": get_current_temperature,
        }
        return tools[result.tool].run(result.tool_input)
```

```python
chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route
```

```python
# 调用并查看结果
chain.invoke({"input": "hi!"})
```

<details class="lake-collapse"><summary id="uf2ddce4e"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="KkWrC" class="ne-codeblock language-json"><code>'Well, hello there! How can I assist you today?'</code></pre></details>
```python
# 调用
result = chain.invoke({"input": "What is langchain?"})
result
```

```python
# 调用
result = chain.invoke({"input": "What is the weather in san francisco right now?"})
result
```

<details class="lake-collapse"><summary id="uf2274afc"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">output：</span></summary><pre data-language="json" id="JXBgE" class="ne-codeblock language-json"><code>'The current temperature is 8.8°C'</code></pre></details>
