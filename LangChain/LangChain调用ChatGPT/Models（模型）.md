ä» `langchain.chat_models` å¯¼å…¥ `OpenAI` çš„å¯¹è¯æ¨¡å‹ `ChatOpenAI` ã€‚ é™¤å»OpenAIä»¥å¤–ï¼Œ`langchain.chat_models` è¿˜é›†æˆäº†å…¶ä»–å¯¹è¯æ¨¡å‹ï¼Œæ›´å¤šç»†èŠ‚å¯ä»¥æŸ¥çœ‹

[langchain 0.2.17 â€” ğŸ¦œğŸ”— LangChain 0.2.17](https://api.python.langchain.com/en/latest/langchain_api_reference.html#module-langchain.chat_models)

```python
import os
import openai
from dotenv import load_dotenv, find_dotenv

# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚

# find_dotenv()å¯»æ‰¾å¹¶å®šä½.envæ–‡ä»¶çš„è·¯å¾„
# load_dotenv()è¯»å–è¯¥.envæ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­  
# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚
_ = load_dotenv(find_dotenv())

# è·å–ç¯å¢ƒå˜é‡ OPENAI_API_KEY
openai_api_key = os.environ['OPENAI_API_KEY']
```

æ²¡æœ‰å®‰è£…` langchain-openai `çš„è¯ï¼Œå…ˆè¿è¡Œä¸‹é¢ä»£ç 

```python
from langchain_openai import ChatOpenAI
```

ä¹Ÿä¼šè¿™æ ·è°ƒç”¨

```python
from langchain_community.chat_models.openai import ChatOpenAI
```

æ¥ä¸‹æ¥éœ€è¦å®ä¾‹åŒ–ä¸€ä¸ª ChatOpenAI ç±»ï¼Œå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶ä¼ å…¥è¶…å‚æ•°æ¥æ§åˆ¶å›ç­”ï¼Œä¾‹å¦‚ `temperature` å‚æ•°ã€‚

```python
# è¿™é‡Œå°†å‚æ•°temperatureè®¾ç½®ä¸º0.0ï¼Œä»è€Œå‡å°‘ç”Ÿæˆç­”æ¡ˆçš„éšæœºæ€§ã€‚
# å¦‚æœä½ æƒ³è¦æ¯æ¬¡å¾—åˆ°ä¸ä¸€æ ·çš„æœ‰æ–°æ„çš„ç­”æ¡ˆï¼Œå¯ä»¥å°è¯•è°ƒæ•´è¯¥å‚æ•°ã€‚
llm = ChatOpenAI(temperature=0.0, openai_api_base="https://xiaoai.plus/v1")
llm

```

<details class="lake-collapse"><summary id="ud90c2766"><span class="ne-text">outputï¼š</span></summary><pre data-language="python" id="iOXbm" class="ne-codeblock language-python"><code>ChatOpenAI(client=&lt;openai.resources.chat.completions.Completions object at 0x000001B17F799BD0&gt;, async_client=&lt;openai.resources.chat.completions.AsyncCompletions object at 0x000001B17F79BA60&gt;, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.chatgptid.net/v1', openai_proxy='')</code></pre></details>
ä¸Šé¢çš„ cell å‡è®¾ OpenAI API å¯†é’¥æ˜¯åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®çš„ï¼Œå¦‚æœå¸Œæœ›æ‰‹åŠ¨æŒ‡å®šAPIå¯†é’¥ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```python
llm = ChatOpenAI(temperature=0, openai_api_base="https://xiaoai.plus/v1",openai_api_key="sk-xxx")
llm
```

<br/>color2
å¯ä»¥çœ‹åˆ°ï¼Œé»˜è®¤è°ƒç”¨çš„æ˜¯ ChatGPT-3.5 æ¨¡å‹ã€‚å¦å¤–ï¼Œå‡ ç§å¸¸ç”¨çš„è¶…å‚æ•°è®¾ç½®åŒ…æ‹¬ï¼š

+ `model_name`ï¼šæ‰€è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º â€˜`gpt-3.5-turbo`â€™ï¼Œå‚æ•°è®¾ç½®ä¸ OpenAI åŸç”Ÿæ¥å£å‚æ•°è®¾ç½®ä¸€è‡´ã€‚
+ `temperature`ï¼šæ¸©åº¦ç³»æ•°ï¼Œå–å€¼åŒåŸç”Ÿæ¥å£ã€‚
+ `openai_api_key`ï¼šOpenAI API keyï¼Œå¦‚æœä¸ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½® API Keyï¼Œä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶è®¾ç½®ã€‚
+ `openai_proxy`ï¼šè®¾ç½®ä»£ç†ï¼Œå¦‚æœä¸ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½®ä»£ç†ï¼Œä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶è®¾ç½®ã€‚
+ `streaming`ï¼šæ˜¯å¦ä½¿ç”¨æµå¼ä¼ è¾“ï¼Œå³é€å­—è¾“å‡ºæ¨¡å‹å›ç­”ï¼Œé»˜è®¤ä¸º Falseï¼Œæ­¤å¤„ä¸èµ˜è¿°
+ `max_tokens`ï¼šæ¨¡å‹è¾“å‡ºçš„æœ€å¤§ token æ•°ï¼Œæ„ä¹‰åŠå–å€¼åŒä¸Šã€‚
+ `openai_api_base`ï¼šå¦‚æœç”¨çš„æ˜¯ä»£ç†ï¼Œå°±æŠŠè¿™ä¸ª url å¡«ä¸Š

<br/>

å½“åˆå§‹åŒ–äº†é€‰æ‹©çš„`LLM`åï¼Œå°±å¯ä»¥å°è¯•ä½¿ç”¨å®ƒï¼é—®ä¸€ä¸‹â€œè¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼â€

```python
output = llm.invoke("è¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼")
```

```python
output
```

<details class="lake-collapse"><summary id="ucd734aa9"><span class="ne-text">outputï¼š</span></summary><pre data-language="python" id="TPStQ" class="ne-codeblock language-python"><code>AIMessage(content='ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“æ³¨äºä¸ºç”¨æˆ·æä¾›å„ç§æœåŠ¡å’Œå¸®åŠ©ã€‚æˆ‘å¯ä»¥å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€è§£å†³é—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°å®Œæˆå·¥ä½œå’Œç”Ÿæ´»ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨ã€‚æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼', response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 20, 'total_tokens': 124}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None})</code></pre></details>
## ModelLaboratory
> langchain å¯ä»¥é›†æˆå¾ˆå¤šæ¨¡å‹çš„è°ƒç”¨
>

é€šè¿‡`LangChain`æä¾›çš„`ModelLaboratory`ï¼ˆæ¨¡å‹å®éªŒå®¤ï¼‰ï¼Œä½ å¯ä»¥æµ‹è¯•å¹¶æ¯”è¾ƒä¸åŒçš„æ¨¡å‹ã€‚

ä¸‹é¢æ˜¯ä¸€æ®µé€šè¿‡`ModelLaboratory`æ¯”è¾ƒä¸åŒå¤§æ¨¡å‹çš„ç¤ºä¾‹ä»£ç (éœ€è¦ç¡®ä¿å·²ç»å®‰è£…`OpenAl`ã€`langchain-openai`ã€`Cohere`å’Œ`HuggingFace-Hub`åº“ï¼ŒåŒæ—¶åœ¨`.env`æ–‡ä»¶ä¸­å·²ç»é…ç½®`OpenAl_API_KEY`ã€`COHERRE_API_KEY`å’Œ`HUGGINGFACEHUB_API_TOKEN`ã€‚

```python
# å¯¼å…¥dotenvåŒ…ï¼Œç”¨äºåŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥langchain_openaiåº“ä¸­çš„OpenAIç±»ï¼Œç”¨äºä¸OpenAIè¿›è¡Œäº¤äº’
from langchain_openai import OpenAI
# å¯¼å…¥langchain_community.llmsä¸­çš„Cohereå’ŒHuggingFaceHubç±»ï¼Œç”¨äºä½¿ç”¨Cohereå’ŒHuggingFaceçš„æ¨¡å‹
from langchain_community.llms import Cohere, HuggingFaceHub

# åˆå§‹åŒ–OpenAIã€Cohereå’ŒHuggingFaceHubçš„å®ä¾‹ï¼Œå¹¶è®¾ç½®æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„åˆ›æ–°æ€§ï¼‰
openai = OpenAI(temperature=0.1)
cohere = Cohere(model="command", temperature=0.1)
huggingface = HuggingFaceHub(repo_id="tiiuae/falcon-7b", model_kwargs={'temperature':0.1})

# å¯¼å…¥ModelLaboratoryç±»ï¼Œç”¨äºåˆ›å»ºå’Œç®¡ç†å¤šä¸ªè¯­è¨€æ¨¡å‹
from langchain.model_laboratory import ModelLaboratory

# åˆ›å»ºä¸€ä¸ªæ¨¡å‹å®éªŒå®¤å®ä¾‹ï¼Œæ•´åˆäº†OpenAIã€Cohereå’ŒHuggingFaceçš„æ¨¡å‹
model_lab = ModelLaboratory.from_llms([openai, cohere, huggingface])

# ä½¿ç”¨æ¨¡å‹å®éªŒå®¤æ¯”è¾ƒä¸åŒæ¨¡å‹å¯¹åŒä¸€ä¸ªé—®é¢˜â€œç™¾åˆèŠ±æ˜¯æ¥æºè‡ªå“ªä¸ªå›½å®¶?â€çš„å›ç­”
model_lab.compare("ç™¾åˆèŠ±æ˜¯æ¥æºè‡ªå“ªä¸ªå›½å®¶?")
```

3ä¸ªæ¨¡å‹ç»™å‡º3ç§ç­”æ¡ˆã€‚å¾ˆæ˜æ˜¾ï¼Œ`OpenAl`å…¬å¸çš„`ChatGPT`ï¼ˆæœªæŒ‡å®šå…·ä½“æ¨¡å‹,é»˜è®¤ä½¿ç”¨`GPT-3.5Turboinstruct`ï¼Œè¿™æ˜¯ä¸Šä¸€ä»£çš„æ¨¡å‹ï¼‰çš„ç­”æ¡ˆæœ€ä½³ï¼Œ`Cohere`çš„ç­”æ¡ˆä¸æ­£ç¡®ã€‚`HuggingFaceHub`çš„å¼€æºæ¨¡å‹falcon-7bç”šè‡³åªæ˜¯å°†é—®é¢˜å¤è¿°ä¸€éå¹¶ä½œä¸ºå›åº”ï¼Œç›¸å½“æ•·è¡ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736757657194-84fd864e-8336-4c91-bd16-1da84317f5ff.png)

