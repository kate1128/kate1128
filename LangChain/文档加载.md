> 参考：[https://python.langchain.com/docs/how_to/#document-loaders](https://python.langchain.com/docs/how_to/#document-loaders)
>
> 就是文件 load 的一些代码调用方式
>
> + `from langchain.document_loaders.pdf import PyMuPDFLoader`
> + `from langchain.document_loaders.markdown import UnstructuredMarkdownLoader`
> + `from langchain.document_loaders.csv_loader import CSVLoader`
> + `from langchain.document_loaders.powerpoint import UnstructuredPowerPointLoader`
> + `from langchain_community.document_loaders.word_document import UnstructuredWordDocumentLoader`
>

# 基础文档
## PDF 文档
[pumpkin_book.pdf](https://www.yuque.com/attachments/yuque/0/2025/pdf/2639475/1736158949972-6a0a2663-6624-4042-b052-50b988e9a58f.pdf)

可以使用 `LangChain` 的 `PyMuPDFLoader` 来读取知识库的 PDF 文件。

`PyMuPDFLoader` 是 PDF 解析器中速度最快的一种，结果会包含 PDF 及其页面的详细元数据，并且每页返回一个文档。

```python
from langchain.document_loaders.pdf import PyMuPDFLoader

# 创建一个 PyMuPDFLoader Class 实例，输入为待加载的 pdf 文档路径
loader = PyMuPDFLoader("../../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf")

# 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载
pdf_pages = loader.load()
```

文档加载后储存在 `pages` 变量中:

+ `page` 的变量类型为 `List`
+ 打印 `pages` 的长度可以看到 pdf 一共包含多少页

```python
print(f"载入后的变量类型为：{type(pdf_pages)}，",  f"该 PDF 一共包含 {len(pdf_pages)} 页")
```

<details class="lake-collapse"><summary id="ud90c2766"><span class="ne-text">output：</span></summary><pre data-language="plain" id="iOXbm" class="ne-codeblock language-plain"><code>载入后的变量类型为：&lt;class 'list'&gt;， 该 PDF 一共包含 196 页</code></pre></details>
`page` 中的每一元素为一个文档，变量类型为 `langchain_core.documents.base.Document`, 文档变量类型包含两个属性：

+ `page_content` 包含该文档的内容。
+ `meta_data` 为文档相关的描述性数据

```python
pdf_page = pdf_pages[1]
print(f"每一个元素的类型：{type(pdf_page)}.", 
    f"该文档的描述性数据：{pdf_page.metadata}", 
    f"查看该文档的内容:\n{pdf_page.page_content}", 
    sep="\n------\n")
```

<details class="lake-collapse"><summary id="u426b13ed"><span class="ne-text">output：</span></summary><pre data-language="plain" id="Cz2YF" class="ne-codeblock language-plain"><code>每一个元素的类型：&lt;class 'langchain_core.documents.base.Document'&gt;.
------
该文档的描述性数据：{'source': './data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'file_path': './data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': &quot;D:20230303170709-00'00'&quot;, 'modDate': '', 'trapped': ''}
------
查看该文档的内容:
前言
“周志华老师的《机器学习》
（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读
者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推
导细节的读者来说可能“不太友好”
，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充
具体的推导细节。
”
读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周
老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书
中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”
。所以...... 本南瓜书只能算是我
等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二
下学生”
。
使用说明
• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书
为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；
• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得
有点飘的时候再回来啃都来得及；
• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识
我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；
• 若南瓜书里没有你想要查阅的公式，
或者你发现南瓜书哪个地方有错误，
请毫不犹豫地去我们GitHub 的
Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块
提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的
话可以微信联系我们（微信号：at-Sm1les）
；
配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU
在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）
最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases
编委会
主编：Sm1les、archwalker、jbb0523
编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226
封面设计：构思-Sm1les、创作-林王茂盛
致谢
特别感谢awyd234、
feijuan、
Ggmatch、
Heitao5200、
huaqing89、
LongJH、
LilRachel、
LeoLRH、
Nono17、
spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。
扫描下方二维码，然后回复关键词“南瓜书”
，即可加入“南瓜书读者交流群”
版权声明
本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。</code></pre></details>
## MD 文档
[1. 简介 Introduction.md](https://www.yuque.com/attachments/yuque/0/2025/md/2639475/1736158949975-f51c1cbc-4087-4c99-ad95-5cb75dea625a.md)

可以以几乎完全一致的方式读入 markdown 文档：

```python
from langchain.document_loaders.markdown import UnstructuredMarkdownLoader

loader = UnstructuredMarkdownLoader("../../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md")
md_pages = loader.load()
```

读取的对象和 PDF 文档读取出来是完全一致的：

```python
print(f"载入后的变量类型为：{type(md_pages)}，",  f"该 Markdown 一共包含 {len(md_pages)} 页")
```

<details class="lake-collapse"><summary id="uc625fcbc"><span class="ne-text">output：</span></summary><pre data-language="json" id="I6CYh" class="ne-codeblock language-json"><code>载入后的变量类型为：&lt;class 'list'&gt;， 该 Markdown 一共包含 1 页</code></pre></details>
```python
md_page = md_pages[0]
print(f"每一个元素的类型：{type(md_page)}.", 
    f"该文档的描述性数据：{md_page.metadata}", 
    f"查看该文档的内容:\n{md_page.page_content[0:][:200]}", 
    sep="\n------\n")
```

<details class="lake-collapse"><summary id="u9d1f9e41"><span class="ne-text">output：</span></summary><pre data-language="json" id="zGaM1" class="ne-codeblock language-json"><code>每一个元素的类型：&lt;class 'langchain_core.documents.base.Document'&gt;.
------
该文档的描述性数据：{'source': './data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md'}
------
查看该文档的内容:
第一章 简介

欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Larg</code></pre></details>
#  结构化数据
结构化数据是指数据由二维表形式按严谨的逻辑存储的数据，主要由数字、文本、日期等离散数据构成。结构化数据不仅便于人们理解和操作还可以被关系数据库读取、处理。

csv文件就是典型的结构化数据。本节选用DataWhale开源课程[GitHub - datawhalechina/joyful-pandas: pandas中文教程](https://github.com/datawhalechina/joyful-pandas/tree/master)中部分数据演示。

## csv文件
[Company.csv](https://www.yuque.com/attachments/yuque/0/2025/csv/2639475/1736159537667-b5288a2f-13a1-410e-8e6a-a8915aafb948.csv)

我们可以使用`langchain.document_loaders.csv_loader`的`CSVLoader`来读取。

```python
from langchain.document_loaders.csv_loader import CSVLoader

loader = CSVLoader('./data/Company.csv')
csv_data = loader.load()
```

读取后返回的类型为`list`，`list`中每个元素为`Document`,`Document`中包含存放某行信息的`page_content`和存放文件相关信息的`metadata`。

```python
print(f'读取后返回的类型为:{type(csv_data)}')
print(f'每个元素的类型为:{type(csv_data[0])}')
print(f'第一个 page_content 中存放的数据为:\n{csv_data[0].page_content}')
print(f'page_content 数据类型为:{type(csv_data[0].page_content)}')
print(f'第一个 metadata 中存放的数据为:{csv_data[0].metadata}')
print(f'metadata 数据类型为:{type(csv_data[0].metadata)}')
```

<details class="lake-collapse"><summary id="u8034cf78"><span class="ne-text">output：</span></summary><pre data-language="python" id="n7981" class="ne-codeblock language-python"><code>读取后返回的类型为:&lt;class 'list'&gt;
每个元素的类型为:&lt;class 'langchain_core.documents.base.Document'&gt;
第一个 page_content 中存放的数据为:
EmployeeID: 1318
birthdate_key: 1/3/1954
age: 61
city_name: Vancouver
department: Executive
job_title: CEO
gender: M
page_content 数据类型为:&lt;class 'str'&gt;
第一个 metadata 中存放的数据为:{'source': './data/Company.csv', 'row': 0}
metadata 数据类型为:&lt;class 'dict'&gt;</code></pre></details>
`page_content`及`metadata`的数据我们也可以通过字符串和字典方式进行操作。比如为了方便 llm 理解我们可以把数据进行二次处理。

```python
print('字符串处理的结果为:',csv_data[0].page_content.replace('\n', '').replace(' ', '').replace('EmployeeID:', '工号').replace('birthdate_key:', '的员工于').replace('age:', '出生，现在').replace('city_name:', '岁，居住城市为').replace('department:', '工作部门为').replace('job_title:', '职位是').replace('gender:', '性别为') + '(M为男性F为女性)。')
print('metadata中存放的路径为:', csv_data[0].metadata['source'])
print('metadata中存放的行号为:', csv_data[0].metadata['row'])
```

<details class="lake-collapse"><summary id="ud6111d5f"><span class="ne-text">output：</span></summary><pre data-language="python" id="zSH8R" class="ne-codeblock language-python"><code>字符串处理的结果为: 工号1318的员工于1/3/1954出生，现在61岁，居住城市为Vancouver工作部门为Executive职位是CEO性别为M(M为男性F为女性)。
metadata中存放的路径为: ./data/Company.csv
metadata中存放的行号为: 0</code></pre></details>
# 非结构化数据
## PPT文件
+ 本部分我们选用DataWhale开源课程[GitHub - datawhalechina/sora-tutorial at 65415e6e56671d1d52b3a0cf2772a83fc7ad2981](https://github.com/datawhalechina/sora-tutorial/tree/65415e6e56671d1d52b3a0cf2772a83fc7ad2981)中部分数据演示。

[AI视频.pptx](https://www.yuque.com/attachments/yuque/0/2025/pptx/2639475/1736159537688-bc1f0c6e-cabf-43fc-8d2b-d7ee2ac28e30.pptx)

```python
from langchain.document_loaders.powerpoint import UnstructuredPowerPointLoader
loader = UnstructuredPowerPointLoader('data/AI视频.pptx')
ppt_data = loader.load()
```

返回的数据为`list`类型，其中`Document`中的`page_content`存放文件中文字内容，同样在`Document`中的`metadata`则存放文件地址`source`。与上文`CSVLoader`的不同是`UnstructuredPowerPointLoader`会将整个PPT内容存到一个`page_content`中，而`CSVLoader`返回的数据是一个`page_content`存放一行的数据。

```python
print(f'读取后返回的类型为:{type(ppt_data)}')
print(f'读取后返回的长度为:{len(ppt_data)}')
print(f'每个元素的类型为:{type(ppt_data[0])}')
print(f'第一个 page_content 中存放的数据为:\n{ppt_data[0].page_content[:200]}')
print(f'page_content 数据类型为:{type(ppt_data[0].page_content)}')
print(f'metadata 中存放的数据为:{ppt_data[0].metadata}')
print(f'metadata 数据类型为:{type(ppt_data[0].metadata)}')
print(f'metadata 存放的 source 为:', str(ppt_data[0].metadata['source']))
```

<details class="lake-collapse"><summary id="ub31ffdeb"><span class="ne-text">output：</span></summary><pre data-language="python" id="CVhNP" class="ne-codeblock language-python"><code>读取后返回的类型为:&lt;class 'list'&gt;
读取后返回的长度为:1
每个元素的类型为:&lt;class 'langchain_core.documents.base.Document'&gt;
第一个 page_content 中存放的数据为:
Sora原理与实战

动手学习AI视频



现有AI视频软件盘点

随着2023年ChatGPT的爆发，让AI的普及率迅速提升，切实的让人感受到AI的给普通人带来的影响，在2023年火了一年的LLM后，视频领域也是也在2024年迅速崛起，前有前辈Runway，后有新生代产品pika，当然也有大名鼎鼎的开源救星SD的当家产品，Stable Video Diffusion，当这几家视频生成
page_content 数据类型为:&lt;class 'str'&gt;
metadata 中存放的数据为:{'source': 'data/AI视频.pptx'}
metadata 数据类型为:&lt;class 'dict'&gt;
metadata 存放的 source 为: data/AI视频.pptx</code></pre></details>
我们同样可以通过字符串操作处理读取的数据：

```python
# 通过多个replace('\n\n', '\n')将数据中多个连续的换行符减少至一个
# replace(' ', '')将所有的空格去掉
after_pro_data = ppt_data[0].page_content.replace('\n\n', '\n').replace('\n\n', '\n').replace('\n\n', '\n').replace(' ', '')
print(f'处理后的数据:\n{after_pro_data[:200]}')
```

<details class="lake-collapse"><summary id="ueb470f46"><span class="ne-text">output：</span></summary><pre data-language="python" id="qQjYr" class="ne-codeblock language-python"><code>处理后的数据:
Sora原理与实战
动手学习AI视频
现有AI视频软件盘点
随着2023年ChatGPT的爆发，让AI的普及率迅速提升，切实的让人感受到AI的给普通人带来的影响，在2023年火了一年的LLM后，视频领域也是也在2024年迅速崛起，前有前辈Runway，后有新生代产品pika，当然也有大名鼎鼎的开源救星SD的当家产品，StableVideoDiffusion，当这几家视频生成公司互相竞争，抢市场份</code></pre></details>
## doc\docx文件
+ 本部分示例文档将[《面向开发者的LLM入门教程、第一部分Prompt Engineering》md版本](https://github.com/datawhalechina/llm-cookbook)转为docx格式进行演示。

[1. 简介 Introduction.docx](https://www.yuque.com/attachments/yuque/0/2025/docx/2639475/1736159537677-e7f6e17d-f8a5-4657-96e9-584c8baf4215.docx)

`langchain`中`UnstructuredWordDocumentLoader`可以读取doc与docx文件，且支持一次性读取全文与按元素读取两种模式。

#### 一次性读取全文内容
```python
from langchain_community.document_loaders.word_document import UnstructuredWordDocumentLoader

loader = UnstructuredWordDocumentLoader('./data/1. 简介 Introduction.docx', mode='single')
docs = loader.load()
print(f'全文内容：\n{docs[0].page_content}')
```

<details class="lake-collapse"><summary id="uc98e0f7f"><span class="ne-text">output：</span></summary><pre data-language="json" id="nocws" class="ne-codeblock language-json"><code>[Document(page_content='第一章 简介\n\n欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。\n\n网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。\n\n在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n\n随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。\n\n与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforcement learning from human feedback，人类反馈强化学习）技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。\n\n因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括专业记者写作，或者向朋友写的随笔等。\n\n如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。', metadata={'source': './data/1. 简介 Introduction.docx'})]</code></pre></details>
#### 按元素读取内容
```python
loader = UnstructuredWordDocumentLoader('./data/1. 简介 Introduction.docx', mode='elements')
docs = loader.load()
for i in range(len(docs)): print(f'第{i}个元素：\n{docs[i].page_content}', end='\n')
```

<details class="lake-collapse"><summary id="ud934b5de"><span class="ne-text">output：</span></summary><pre data-language="json" id="PbIdm" class="ne-codeblock language-json"><code>第0个元素：
第一章 简介
第1个元素：
欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。
第2个元素：
网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。
第3个元素：
在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。
第4个元素：
随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。
第5个元素：
与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforcement learning from human feedback，人类反馈强化学习）技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。
第6个元素：
因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括专业记者写作，或者向朋友写的随笔等。
第7个元素：
如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。</code></pre></details>


