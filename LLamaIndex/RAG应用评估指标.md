> 1. `Answer relevance`ï¼š**è¯„ä¼°RAGç³»ç»Ÿçš„è¾“å‡ºæ˜¯å¦ä¸é—®é¢˜ç›¸å…³**ï¼›
> 2. `Context relevance`ï¼š**è¯„ä¼°RAGç³»ç»Ÿå¬å›çš„ä¸Šä¸‹æ–‡æ˜¯å¦ä¸é—®é¢˜ç›¸å…³**ï¼›
> 3. `Groundness`: **è¯„ä¼°RAGç³»ç»Ÿçš„è¾“å‡ºæ˜¯å¦åŸºäºå¬å›çš„ä¸Šä¸‹æ–‡**ï¼›
>

##  ä»‹ç»
æœ¬ç« èŠ‚ä¸»è¦å†…å®¹ä¸ºè¯„ä¼° RAG åº”ç”¨ä¸­å¸¸ç”¨çš„ä¸‰ä¸ªæŒ‡æ ‡ï¼Œåˆ†åˆ«ä¸ºï¼š

<br/>color2
1. `Answer relevance`ï¼šè¯„ä¼°RAGç³»ç»Ÿçš„è¾“å‡ºæ˜¯å¦ä¸é—®é¢˜ç›¸å…³ï¼›
2. `Context relevance`ï¼šè¯„ä¼°RAGç³»ç»Ÿå¬å›çš„ä¸Šä¸‹æ–‡æ˜¯å¦ä¸é—®é¢˜ç›¸å…³ï¼›
3. `Groundness`: è¯„ä¼°RAGç³»ç»Ÿçš„è¾“å‡ºæ˜¯å¦åŸºäºå¬å›çš„ä¸Šä¸‹æ–‡ï¼›

<br/>

![](https://raw.githubusercontent.com/datawhalechina/llm-cookbook/54ad6728cde23add6e96b1f521ace605b5e60ca3/content/%E9%80%89%E4%BF%AE-Building%20and%20Evaluating%20Advanced%20RAG%20Applications/images/ch03_traid.jpg)

å®‰è£…è¯„ä¼°æ¡†æ¶ï¼Œå¦‚æœå·²ç»å®‰è£…å°±å¯ä»¥è·³è¿‡è¿™ä¸€æ­¥éª¤ã€‚

```python
# requirements
# pip install trulens_eval
```

åœ¨è¿™é‡Œï¼Œä¸ºäº†ç¾è§‚å’Œæ–¹ä¾¿å±•ç¤ºï¼Œæˆ‘ä»¬è®¾ç½®è¾“å‡ºå¿½ç•¥è­¦å‘Šä¿¡æ¯ã€‚

```python
# å¿½ç•¥è­¦å‘Šï¼Œé¿å…è­¦å‘Šå½±å“è¾“å‡ºç»“æœ
import warnings
warnings.filterwarnings('ignore')
```

1. è‡ªè¡Œè®¾ç½® `openAI key`
2. éœ€è¦é‡ç½®æ•°æ®åº“ï¼Œè¿™ä¼šåœ¨ä¹‹åç”¨äºå­˜å‚¨é—®é¢˜ã€å¬å›ç»“æœå’Œå›ç­”ï¼Œæ–¹ä¾¿ç®¡ç†å’Œè¯„ä¼°ã€‚

```python
# å¯¼å…¥Truç±»
from trulens_eval import Tru


# å®ä¾‹åŒ–Truç±»
tru = Tru()

# é‡ç½®æ•°æ®åº“
# æ•°æ®åº“ä¹‹åä¼šç”¨æ¥å­˜å‚¨é—®é¢˜ã€ä¸­é—´å¬å›ç»“æœã€ç­”æ¡ˆä»¥åŠè¯„ä¼°ç»“æœ
tru.reset_database()
```

```python
ğŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .
ğŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.
```

æ¥ä¸‹æ¥ï¼Œå¯¼å…¥è¯»å–pdfæ‰€éœ€è¦çš„SimpleDirectoryReaderï¼Œè¯»å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„pdfæ–‡ä»¶ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé»˜è®¤çš„å‚æ•°é€‚åˆè¯»å–è‹±æ–‡æ–‡æ¡£ï¼Œå¦‚æœæ–‡æ¡£ä¸ºä¸­æ–‡ï¼Œéœ€è¦åœ¨åç»­å°†å…¨è§’å­—ç¬¦è½¬æ¢ä¸ºåŠè§’å­—ç¬¦ã€‚

```python
# è®¾ç½®Llama Index reader
from llama_index import SimpleDirectoryReader

# ä»ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­è¯»å–PDFæ–‡æ¡£ï¼Œç„¶ååŠ è½½åˆ°documentå¯¹è±¡ä¸­
# ä½¿ç”¨çš„æ–‡æ¡£ä¸ºâ€œäººå·¥æ™ºèƒ½â€è¯æ¡çš„ç»´åŸºç™¾ç§‘é¡µé¢
documents = SimpleDirectoryReader(
    input_files=["./data/äººå·¥æ™ºèƒ½.pdf"]
).load_data()

documents_en = SimpleDirectoryReader(
    input_files=["./data/eBook-How-to-Build-a-Career-in-AI.pdf"]
).load_data()
```

ä¸ºäº†æ–¹é¢èµ·è§ï¼Œå°†è¯»å–çš„pdfæ–‡æ¡£åŠ è½½åˆ°åŒä¸€ä¸ªdocumentå¯¹è±¡ä¸­ï¼Œç”¨`"\n\n"`éš”å¼€ï¼›

```python
from llama_index import Document

# å°†documentsä¸­çš„å†…å®¹åˆå¹¶æˆä¸€ä¸ªå¤§æ–‡æ¡£ï¼Œè€Œä¸æ˜¯æ¯ä¸€é¡µéƒ½æ˜¯ä¸€ä¸ªæ–‡æ¡£
document = Document(text="\n\n".\
                    join([doc.text for doc in documents]))

document_en = Document(text="\n\n".\
                       join([doc.text for doc in documents_en]))
```

å°†ä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ›¿æ¢æˆè‹±æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œæ–¹ä¾¿åç»­å¤„ç†

```python
# å°†ä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ›¿æ¢æˆè‹±æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œæ–¹ä¾¿åç»­å¤„ç†
# å¦‚æœæ˜¯è‹±æ–‡æ–‡æ¡£ï¼Œå¯ä»¥è·³è¿‡è¿™ä¸€æ­¥
# ä¸å¤„ç†çš„è¯ï¼Œä¼šå¯¼è‡´æ— æ³•æ­£ç¡®åˆ‡åˆ†ä¸­æ–‡å¥å­ï¼Œä¼šå½±å“åç»­sentence_windowçš„å¤§å°ï¼Œå¯¼è‡´è¾“å…¥é•¿åº¦å¤§äºgpt-3.5-turboçš„æœ€å¤§é™åˆ¶
document.text=document.text.replace('ã€‚','. ')
document.text=document.text.replace('ï¼','! ')
document.text=document.text.replace('ï¼Ÿ','? ')
```

è®¾ç½®indexå­˜å‚¨ï¼Œé¦–å…ˆè®¾ç½®ç”¨æ¥è¯„ä¼°çš„å¤§æ¨¡å‹ä¸ºgpt-3.5-turboï¼Œéœ€è¦æ³¨æ„çš„æ˜¯è¿™é‡Œä½¿ç”¨çš„ç‰ˆæœ¬çš„ä¸Šä¸‹æ–‡çª—å£ä¸º4096ï¼Œå› æ­¤éœ€è¦æ³¨æ„è¾“å…¥çš„é•¿åº¦ã€‚ ç„¶åè®¾ç½®embeddingæ¨¡å‹ï¼Œæˆ‘ä»¬é€‰æ‹©äº†BAAI/bge-small-zh-v1.5ï¼Œè¿™é‡Œå¯ä»¥æ ¹æ®åœºæ™¯çš„éœ€è¦å’Œè®¡ç®—èµ„æºçš„trade offé€‰æ‹©æ¨¡å‹çš„å¤§å°å’Œè¯­ç§ã€‚

```python
# è®¾ç½®sentence_index
from utils import build_sentence_window_index

from llama_index.llms import OpenAI

# è®¾ç½®ä½¿ç”¨çš„å¤§æ¨¡å‹
# "gpt-3.5-turbo"æ˜¯æ¨¡å‹çš„åç§°
# temperatureæ˜¯æ¸©åº¦ï¼Œç”¨æ¥æ§åˆ¶æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å¤šæ ·æ€§
llm = OpenAI(model="gpt-3.5-turbo", temperature=0.1)

# è®¾ç½®embeddingæ¨¡å‹
# è¿™é‡Œæ˜¯åœ¨æœ¬åœ°ä½¿ç”¨BAAI/bge-small-zh-v1.5
# documentçš„æ‰€æœ‰çš„å†…å®¹ä¼šç´¢å¼•åˆ°sentence indexå¯¹è±¡ä¸­
# å›½å†…ä½¿ç”¨å¯ä»¥åˆ‡æ¢huggingfaceé•œåƒç«™
sentence_index = build_sentence_window_index(
    document,
    llm,
    embed_model="local:BAAI/bge-small-zh-v1.5",
    save_dir="sentence_index"
)

sentence_index_en = build_sentence_window_index(
    document_en,
    llm,
    embed_model="local:BAAI/bge-small-en-v1.5",
    save_dir="sentence_index_en"
)
```

ä½¿ç”¨å·¥å…·åŒ…ä¸­å°è£…å¥½çš„å‡½æ•°ï¼ŒåŸºäºä¸Šä¸€æ­¥å»ºç«‹å¥½çš„ç´¢å¼•ï¼Œè¿”å›ç”¨äºä¹‹åæ£€ç´¢çš„å¼•æ“ã€‚

```python
from utils import get_sentence_window_query_engine

# æ ¹æ®sentence_indexå¯¹è±¡åˆ›å»ºä¸€ä¸ªæœç´¢å¼•æ“
# ä¹‹åä¼šè¢«ç”¨äºåœ¨RAGåº”ç”¨ä¸­è¿›è¡Œå¬å›
sentence_window_engine = \
get_sentence_window_query_engine(sentence_index)
```



```python
sentence_window_engine_en = \
get_sentence_window_query_engine(sentence_index_en)
```

è¿™é‡Œæˆ‘ä»¬å…ˆæµ‹è¯•å•ä¸ªé—®é¢˜æ¥debugï¼Œçœ‹ä¸€ä¸‹è¾“å‡ºæ˜¯ä»€ä¹ˆã€‚

```python
output = sentence_window_engine.query(
    "AIçš„æ ¸å¿ƒé—®é¢˜å’Œé•¿è¿œç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ")
```

```python
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
- Avoid using `tokenizers` before the fork if possible
- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
```



```python
output_en = sentence_window_engine_en.query(
    "How do you create your AI portfolio?")
# ç¤ºä¾‹ï¼šä½¿ç”¨æœç´¢å¼•æ“è¿›è¡Œå¬å›
```

In [13]:

```python
# åœ¨å®é™…å¼€å‘ä¸­ï¼Œå¯ä»¥é€šè¿‡æŸ¥çœ‹metadataè¿›è¡Œdebug
output.metadata
```

Out[13]:

```python
{'7e8484a0-f7d2-4b64-b683-fa76b1dec6fe': {'window': 'â¼ˆâ¼¯æ™ºèƒ½çš„ç ”ç©¶æ˜¯â¾¼åº¦æŠ€æœ¯æ€§å’Œä¸“ä¸šçš„ï¼Œå„åˆ†â½€é¢†åŸŸéƒ½æ˜¯æ·±â¼Šä¸”å„ä¸ç›¸é€šçš„ï¼Œå› â½½æ¶‰åŠèŒƒå›´æâ¼´[9].  â¼ˆâ¼¯æ™ºèƒ½çš„\nç ”ç©¶å¯ä»¥åˆ†ä¸ºâ¼ä¸ªæŠ€æœ¯é—®é¢˜.  å…¶åˆ†â½€é¢†åŸŸä¸»è¦é›†ä¸­åœ¨è§£å†³å…·ä½“é—®é¢˜ï¼Œå…¶ä¸­ä¹‹â¼€æ˜¯ï¼Œå¦‚ä½•ä½¿â½¤å„ç§ä¸åŒçš„â¼¯å…·å®Œæˆ\nç‰¹å®šçš„åº”â½¤ç¨‹åº. \n AIçš„æ ¸â¼¼é—®é¢˜åŒ…æ‹¬å»ºæ„èƒ½å¤Ÿè·Ÿâ¼ˆç±»ä¼¼ç”šâ¾„è¶…å“çš„æ¨ç†ã€çŸ¥è¯†ã€è®¡åˆ’ã€å­¦ä¹ ã€äº¤æµã€æ„ŸçŸ¥ã€ç§»åŠ¨ ã€ç§»ç‰©ã€ä½¿â½¤â¼¯\nå…·å’Œæ“æ§æœºæ¢°çš„èƒ½â¼’ç­‰[10].  é€šâ½¤â¼ˆâ¼¯æ™ºèƒ½ï¼ˆGAIï¼‰â½¬å‰ä»ç„¶æ˜¯è¯¥é¢†åŸŸçš„é•¿è¿œâ½¬æ ‡[11].  â½¬å‰å¼±â¼ˆâ¼¯æ™ºèƒ½å·²ç»æœ‰åˆ\næ­¥æˆæœï¼Œç”šâ¾„åœ¨â¼€äº›å½±åƒè¯†åˆ«ã€è¯­â¾”åˆ†æã€æ£‹ç±»æ¸¸æˆç­‰ç­‰å•â½…â¾¯çš„èƒ½â¼’è¾¾åˆ°äº†è¶…è¶Šâ¼ˆç±»çš„â½”å¹³ï¼Œâ½½ä¸”â¼ˆâ¼¯æ™ºèƒ½çš„\né€šâ½¤æ€§ä»£è¡¨ç€ï¼Œèƒ½è§£å†³ä¸Šè¿°çš„é—®é¢˜çš„æ˜¯â¼€æ ·çš„AIç¨‹åºï¼Œâ½†é¡»é‡æ–°å¼€å‘ç®—æ³•å°±å¯ä»¥ç›´æ¥ä½¿â½¤ç°æœ‰çš„AIå®Œæˆä»»åŠ¡ï¼Œä¸\nâ¼ˆç±»çš„å¤„ç†èƒ½â¼’ç›¸åŒï¼Œä½†è¾¾åˆ°å…·å¤‡æ€è€ƒèƒ½â¼’çš„ç»Ÿåˆå¼ºâ¼ˆâ¼¯æ™ºèƒ½è¿˜éœ€è¦æ—¶é—´ç ”ç©¶ï¼Œâ½è¾ƒæµâ¾çš„â½…æ³•åŒ…æ‹¬ç»Ÿè®¡â½…æ³•ï¼Œ\nè®¡ç®—æ™ºèƒ½å’Œä¼ ç»Ÿæ„ä¹‰çš„AI. ',
                                          'original_text': 'AIçš„æ ¸â¼¼é—®é¢˜åŒ…æ‹¬å»ºæ„èƒ½å¤Ÿè·Ÿâ¼ˆç±»ä¼¼ç”šâ¾„è¶…å“çš„æ¨ç†ã€çŸ¥è¯†ã€è®¡åˆ’ã€å­¦ä¹ ã€äº¤æµã€æ„ŸçŸ¥ã€ç§»åŠ¨ ã€ç§»ç‰©ã€ä½¿â½¤â¼¯\nå…·å’Œæ“æ§æœºæ¢°çš„èƒ½â¼’ç­‰[10]. '},
 '4e0b1c3d-5ba5-4c6b-b5c6-29df66a75281': {'window': 'â¼ˆâ¼¯æ™ºèƒ½çš„\nç ”ç©¶å¯ä»¥åˆ†ä¸ºâ¼ä¸ªæŠ€æœ¯é—®é¢˜.  å…¶åˆ†â½€é¢†åŸŸä¸»è¦é›†ä¸­åœ¨è§£å†³å…·ä½“é—®é¢˜ï¼Œå…¶ä¸­ä¹‹â¼€æ˜¯ï¼Œå¦‚ä½•ä½¿â½¤å„ç§ä¸åŒçš„â¼¯å…·å®Œæˆ\nç‰¹å®šçš„åº”â½¤ç¨‹åº. \n AIçš„æ ¸â¼¼é—®é¢˜åŒ…æ‹¬å»ºæ„èƒ½å¤Ÿè·Ÿâ¼ˆç±»ä¼¼ç”šâ¾„è¶…å“çš„æ¨ç†ã€çŸ¥è¯†ã€è®¡åˆ’ã€å­¦ä¹ ã€äº¤æµã€æ„ŸçŸ¥ã€ç§»åŠ¨ ã€ç§»ç‰©ã€ä½¿â½¤â¼¯\nå…·å’Œæ“æ§æœºæ¢°çš„èƒ½â¼’ç­‰[10].  é€šâ½¤â¼ˆâ¼¯æ™ºèƒ½ï¼ˆGAIï¼‰â½¬å‰ä»ç„¶æ˜¯è¯¥é¢†åŸŸçš„é•¿è¿œâ½¬æ ‡[11].  â½¬å‰å¼±â¼ˆâ¼¯æ™ºèƒ½å·²ç»æœ‰åˆ\næ­¥æˆæœï¼Œç”šâ¾„åœ¨â¼€äº›å½±åƒè¯†åˆ«ã€è¯­â¾”åˆ†æã€æ£‹ç±»æ¸¸æˆç­‰ç­‰å•â½…â¾¯çš„èƒ½â¼’è¾¾åˆ°äº†è¶…è¶Šâ¼ˆç±»çš„â½”å¹³ï¼Œâ½½ä¸”â¼ˆâ¼¯æ™ºèƒ½çš„\né€šâ½¤æ€§ä»£è¡¨ç€ï¼Œèƒ½è§£å†³ä¸Šè¿°çš„é—®é¢˜çš„æ˜¯â¼€æ ·çš„AIç¨‹åºï¼Œâ½†é¡»é‡æ–°å¼€å‘ç®—æ³•å°±å¯ä»¥ç›´æ¥ä½¿â½¤ç°æœ‰çš„AIå®Œæˆä»»åŠ¡ï¼Œä¸\nâ¼ˆç±»çš„å¤„ç†èƒ½â¼’ç›¸åŒï¼Œä½†è¾¾åˆ°å…·å¤‡æ€è€ƒèƒ½â¼’çš„ç»Ÿåˆå¼ºâ¼ˆâ¼¯æ™ºèƒ½è¿˜éœ€è¦æ—¶é—´ç ”ç©¶ï¼Œâ½è¾ƒæµâ¾çš„â½…æ³•åŒ…æ‹¬ç»Ÿè®¡â½…æ³•ï¼Œ\nè®¡ç®—æ™ºèƒ½å’Œä¼ ç»Ÿæ„ä¹‰çš„AI.  â½¬å‰æœ‰â¼¤é‡çš„â¼¯å…·åº”â½¤äº†â¼ˆâ¼¯æ™ºèƒ½ï¼Œå…¶ä¸­åŒ…æ‹¬æœç´¢å’Œæ•°å­¦ä¼˜åŒ–ã€é€»è¾‘æ¨æ¼”. ',
                                          'original_text': 'é€šâ½¤â¼ˆâ¼¯æ™ºèƒ½ï¼ˆGAIï¼‰â½¬å‰ä»ç„¶æ˜¯è¯¥é¢†åŸŸçš„é•¿è¿œâ½¬æ ‡[11]. '}}
```

In [14]:

```python
output_en.metadata
```

Out[14]:

```python
{'e0d0633c-9a38-4330-8980-2e4ceea28d30': {'window': 'Chapter 4: Scoping Successful AI Projects.\n Chapter 5: Finding Projects that Complement \nYour Career Goals.\n Chapter 6: Building a Portfolio of Projects that \nShows Skill Progression.\n Chapter 7: A Simple Framework for Starting Your AI \nJob Search.\n Chapter 8: Using Informational Interviews to Find \nthe Right Job.\n Chapter 9: Finding the Right AI Job for You.\n',
                                          'original_text': 'Chapter 7: A Simple Framework for Starting Your AI \nJob Search.\n'},
 '600b5970-e3cd-47cd-a2e0-ea2ffb2c5e79': {'window': 'Chapter 6: Building a Portfolio of Projects that \nShows Skill Progression.\n Chapter 7: A Simple Framework for Starting Your AI \nJob Search.\n Chapter 8: Using Informational Interviews to Find \nthe Right Job.\n Chapter 9: Finding the Right AI Job for You.\n Chapter 10: Keys to Building a Career in AI.\n Chapter 11: Overcoming Imposter Syndrome.\n',
                                          'original_text': 'Chapter 9: Finding the Right AI Job for You.\n'}}
```

## Feedback functions åé¦ˆå‡½æ•°
`feedback function`æ˜¯ä¸€ä¸ªè¡¡é‡RAGç³»ç»Ÿçš„é—®é¢˜ã€ä¸Šä¸‹æ–‡ã€ç­”æ¡ˆä¸‰è€…ä¹‹é—´å…³ç³»çš„å‡½æ•°ã€‚åœ¨RAGç³»ç»Ÿä¸­ï¼Œ`feedback function`é€šå¸¸æ˜¯ä¸€ä¸ªè¯„ä¼°æ¨¡å‹çš„æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°RAGç³»ç»Ÿçš„å„ä¸ªæ–¹é¢çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä¸»è¦ä¸ºï¼Œ`answer relevanceã€context relevanceã€groundness`ä¸‰ä¸ªæŒ‡æ ‡ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736475567009-7ded4b33-fbb9-48b4-b8c2-7ce11f7f5d38.png)

```python
import nest_asyncio

# ä¿è¯åç»­å¯ä»¥ä½¿ç”¨streamlitè¿›è¡Œè¯„ä¼°ç»“æœç®¡ç†å’Œå¯è§†åŒ–
nest_asyncio.apply()
```



```python
from trulens_eval import OpenAI as fOpenAI

# åˆå§‹åŒ–OpenAI gpt-3.5-turboæ¨¡å‹ä½œä¸ºprovider
# providerä¹‹åä¼šç”¨æ¥è¾…åŠ©è¯„ä¼°RAGåº”ç”¨çš„å„ä¸ªæŒ‡æ ‡ï¼šanswer relevance, context relevance, groundedness.
provider = fOpenAI()
```

### Answer Relevance
`answer relevance`ç”¨æ¥è¯„ä¼°RAGç³»ç»Ÿçš„è¾“å‡ºæ˜¯å¦ä¸é—®é¢˜ç›¸å…³ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736475651943-975251de-ae2b-4da3-8ce1-46cccf09d93e.png)

answer relevanceçš„feedback functionçš„ç»“æ„ä¸ºï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736475687563-e9477917-e04a-4a22-8dff-0cb9a559d52f.png)

è¿™é‡Œä½¿ç”¨å°è£…å¥½çš„Feedbackå‡½æ•°å³å¯ï¼Œæˆ‘ä»¬éœ€è¦åšçš„æ˜¯ï¼šæŒ‡å®šè¯„ä¼°çš„æ–¹å¼ï¼ŒæŒ‡å®šåç§°ï¼Œä»¥åŠè¯„ä¼°çš„å¯¹è±¡ã€‚

```python
from trulens_eval import Feedback


# è¿™é‡Œä¸ºanswer relevanceè®¾ç½®feedback
# ä½¿ç”¨provider.relevance_with_cot_reasonsä½œä¸ºè¯„ä¼°å‡½æ•°ï¼Œå³ï¼Œé€šè¿‡è°ƒç”¨LLMä½¿ç”¨chain of thoughtçš„æ–¹å¼è¿›è¡Œè¯„ä¼°
# on_input_output()è¡¨ç¤ºåœ¨è¾“å…¥å’Œè¾“å‡ºä¸Šè¿›è¡Œè¯„ä¼°
f_qa_relevance = Feedback(
    provider.relevance_with_cot_reasons,
    name="Answer Relevance"
).on_input_output()
```

```python
âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .
âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .
```

### Context Relevance
context relevanceç”¨æ¥è¯„ä¼°RAGç³»ç»Ÿå¬å›çš„ä¸Šä¸‹æ–‡æ˜¯å¦ä¸é—®é¢˜ç›¸å…³ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736475724060-38bbb122-e341-483e-ac90-a15eac18911b.png)

å…¶feedback functionçš„ç»“æ„ä¸ºï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736475741214-2492f4f1-8116-478a-be4f-0ca9b37ab744.png)

```python
from trulens_eval import TruLlama

# é€‰æ‹©å¬å›çš„ä¸Šä¸‹æ–‡
context_selection = TruLlama.select_source_nodes().node.text
```

è¿™é‡Œçš„è®¾ç½®å’Œä¸Šä¸€æ­¥ç±»ä¼¼ï¼Œåªéœ€è¦ä¿®æ”¹è¯„ä¼°çš„å¯¹è±¡å³å¯ã€‚ ä¹Ÿå¯ä»¥é€‰æ‹©ä¿®æ”¹è¯„ä¼°çš„æ–¹å¼ï¼Œè¿›è¡Œå¯¹æ¯”ã€‚

```python
import numpy as np


# ä½¿ç”¨provider.qs_relevanceä½œä¸ºè¯„ä¼°å‡½æ•°
# on_input()è¡¨ç¤ºåœ¨è¾“å…¥ä¸Šè¿›è¡Œè¯„ä¼°
# on(context_selection)è¡¨ç¤ºåœ¨context_selectionä¸Šè¿›è¡Œè¯„ä¼°
# aggregate(np.mean)è¡¨ç¤ºä½¿ç”¨np.meanä½œä¸ºèšåˆå‡½æ•°
# è¿™é‡Œå®é™…çš„æ„æ€æ˜¯ï¼šå¯¹äºcontext_selectionä¸­çš„æ¯ä¸ªå¥å­ï¼Œéƒ½ä¼šè¿›è¡Œè¯„ä¼°ï¼Œç„¶åå–å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆçš„è¯„ä¼°ç»“æœ
f_qs_relevance = (
    Feedback(provider.qs_relevance,
             name="Context Relevance")
    .on_input()
    .on(context_selection)
    .aggregate(np.mean)
)
```

```python
âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .
âœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .
```



```python
import numpy as np

# åŒä¸Šï¼Œå¯¹äºcontext_selectionä¸­çš„æ¯ä¸ªå¥å­è¿›è¡Œè¯„ä¼°ï¼Œå–å¹³å‡å€¼ä½œä¸ºè¯„ä¼°ç»“æœ
f_qs_relevance = (
    Feedback(provider.qs_relevance_with_cot_reasons,
             name="Context Relevance")
    .on_input()
    .on(context_selection)
    .aggregate(np.mean)
)
```

```python
âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .
âœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .
```

### Groundedness
```python
from trulens_eval.feedback import Groundedness

grounded = Groundedness(groundedness_provider=provider)
```

æœ€åæ˜¯groundednessï¼Œç”¨æ¥è¯„ä¼°RAGç³»ç»Ÿçš„è¾“å‡ºæ˜¯å¦åŸºäºå¬å›çš„ä¸Šä¸‹æ–‡ã€‚ è®¾ç½®å’Œä¹‹å‰çš„ç±»ä¼¼ã€‚

```python
# groundednessçš„è¯„ä¼°ï¼Œè§£é‡ŠåŒanswer relevanceå’Œcontext relevance
f_groundedness = (
    Feedback(grounded.groundedness_measure_with_cot_reasons,
             name="Groundedness"
            )
    .on(context_selection)
    .on_output()
    .aggregate(grounded.grounded_statements_aggregator)
)
```

```python
âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .
âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .
```

## Evaluation of the RAG application
åœ¨RAGç³»ç»Ÿçš„è¯„ä¼°ä¸­ï¼Œfeedback functionå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å®ç°ã€‚ ä½¿ç”¨äººå·¥æ‰“åˆ†çš„æ–¹æ³•å¯ä»¥è·å¾—æœ€å‡†ç¡®çš„è¯„ä¼°ç»“æœï¼Œä½†æ˜¯è¿™ç§æ–¹æ³•æˆæœ¬è¾ƒé«˜ï¼Œå› æ­¤åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸ä½¿ç”¨è‡ªåŠ¨è¯„ä¼°çš„æ–¹æ³•ã€‚ åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä½¿ç”¨gpt-3.5-turboæ¥å¯¹RAGç³»ç»Ÿè¿›è¡Œè¯„ä¼°ã€‚ è¿™ç§æ–¹æ³•çš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥å¿«é€Ÿã€ä½æˆæœ¬åœ°å¯¹RAGç³»ç»Ÿè¿›è¡Œè¯„ä¼°ï¼Œä½†æ˜¯å…¶è¯„ä¼°ç»“æœå¯èƒ½ä¸å¦‚äººå·¥æ‰“åˆ†å‡†ç¡®ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1736475768707-c0dcb50e-e8c9-440d-896a-3a52b05bbc3a.png)

ä¸‹é¢æ˜¯æ•´ä¸ªRAGç³»ç»Ÿçš„è¯„ä¼°æµç¨‹çš„å®ç°ã€‚

```python
from trulens_eval import TruLlama
from trulens_eval import FeedbackMode


# å®ä¾‹åŒ–TruLlamaç±»ï¼Œç”¨æ¥è®°å½•è¯„ä¼°ç»“æœ
# sentence_window_engineæ˜¯ä¹‹å‰åˆ›å»ºçš„æœç´¢å¼•æ“
# app_idæ˜¯åº”ç”¨çš„IDï¼Œç”¨æ¥æ ‡è¯†åº”ç”¨
tru_recorder = TruLlama(
    sentence_window_engine,
    app_id="App_1",
    feedbacks=[
        f_qa_relevance,
        f_qs_relevance,
        f_groundedness
    ]
)

tru_recorder_en = TruLlama(
    sentence_window_engine_en,
    app_id="App_2",
    feedbacks=[
        f_qa_relevance,
        f_qs_relevance,
        f_groundedness
    ]
)
```

è¯»å–ç”¨æ¥è¯„ä¼°çš„é—®é¢˜ï¼Œè¿™é‡Œä¸ºäº†èŠ‚çº¦æ—¶é—´å¹¶é™ä½è°ƒç”¨APIçš„æˆæœ¬ï¼Œæˆ‘ä»¬åªè®¾ç½®äº†6ä¸ªé—®é¢˜ã€‚ åœ¨å®é™…åœºæ™¯ä¸­ï¼Œå¯ä»¥æ‰‹å†™æˆ–é€šè¿‡prompt seedçš„æ–¹æ³•ç”Ÿæˆæ›´å¤šçš„é—®é¢˜ï¼Œè¦†ç›–æ›´å¤šçš„åœºæ™¯ã€‚

```python
eval_questions = []
# è¯»å–è¯„ä¼°é—®é¢˜ï¼Œåœ¨./data/eval_questions.txtä¸‹ï¼Œå¯ä»¥è‡ªå®šä¹‰
with open('./data/eval_questions.txt', 'r') as file:
    for line in file:
        item = line.strip()
        eval_questions.append(item)
```



```python
eval_questions_en = []
with open('./data/eval_questions_en.txt', 'r') as file:
    for line in file:
        item = line.strip()
        eval_questions_en.append(item)
```



```python
eval_questions
```



```python
['äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ',
 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äººç±»çš„æ§åˆ¶ï¼Ÿ',
 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ',
 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ',
 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ']
```



```python
eval_questions_en
```



```python
['What are the keys to building a career in AI?',
 "How can teamwork contribute to success in AI?'",
 "What is the importance of networking in AI?'",
 "What are some good habits to develop for a successful career?'",
 "How can altruism be beneficial in building a career?'",
 "What is imposter syndrome and how does it relate to AI?'",
 "Who are some accomplished individuals who have experienced imposter syndrome?'",
 "What is the first step to becoming good at AI?'",
 "What are some common challenges in AI?'",
 'Is it normal to find parts of AI challenging?']
```



```python
eval_questions.append("å¦‚ä½•åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸè·å¾—æˆåŠŸï¼Ÿ")
```



```python
eval_questions
```



```python
['äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ',
 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äººç±»çš„æ§åˆ¶ï¼Ÿ',
 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ',
 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ',
 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ',
 'å¦‚ä½•åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸè·å¾—æˆåŠŸï¼Ÿ']
```

æ¥ä¸‹æ¥å¼€å§‹è¯„ä¼°ï¼Œè¯·æ±‚RAGç³»ç»Ÿçš„è¾“å‡ºï¼Œç„¶åä½¿ç”¨feedback functionå¯¹è¾“å‡ºè¿›è¡Œè¯„ä¼°ã€‚

```python
# å¯¹äºæ¯ä¸ªè¯„ä¼°é—®é¢˜ï¼Œè¿›è¡Œè¯„ä¼°ï¼Œå¹¶è®°å½•ç»“æœ
# æ³¨æ„ï¼šè¯¥è¿‡ç¨‹å¯èƒ½ä¼šæ¯”è¾ƒè€—æ—¶ï¼Œè¯·è€å¿ƒç­‰å¾…
for question in eval_questions:
    with tru_recorder as recording:
        sentence_window_engine.query(question)
```



```python
for question in eval_questions_en:
    with tru_recorder_en as recording:
        sentence_window_engine_en.query(question)
```

ä¹‹åï¼Œéœ€è¦è¿›è¡Œç¼–è§£ç ï¼Œå°†è¯„ä¼°ç»“æœè½¬æ¢ä¸ºä¸­æ–‡å¯è¯»çš„å½¢å¼ï¼Œæ–¹ä¾¿åˆ†æã€‚



```python
records, feedback = tru.get_records_and_feedback(app_ids=[])

# å°†è®°å½•ä¸­çš„unicodeè½¬æ¢æˆä¸­æ–‡ï¼Œæ–¹ä¾¿æŸ¥çœ‹
def decode_unicode(s):
    return s.encode('ascii').decode('unicode-escape')

records['input'] = records['input'].apply(decode_unicode)
records['output'] = records['output'].apply(decode_unicode)

records.head()
```





```python
# è¿è¡Œdashboard
# æ³¨æ„ï¼šè¯·æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼Œå¦‚æœè¢«å ç”¨ï¼Œè¯·ä¿®æ”¹ç«¯å£å·
tru.run_dashboard()
```

```python
Starting dashboard ...
Config file already exists. Skipping writing process.
Credentials file already exists. Skipping writing process.
```

```python
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
```

<details class="lake-collapse"><summary id="u993c8a90"><span class="ne-text">outputï¼š</span></summary><pre data-language="json" id="SxOag" class="ne-codeblock language-json"><code>Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦
Dashboard started at http://10.31.153.170:8501 .</code></pre></details>


<details class="lake-collapse"><summary id="u74628242"><span class="ne-text" style="color: rgba(0, 0, 0, 0.87)">outputï¼š</span></summary><pre data-language="json" id="PrKuP" class="ne-codeblock language-json"><code>&lt;Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...&gt;</code></pre></details>
