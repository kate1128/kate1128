## 写在前面
本文是参考《Hugging Face Transformers 萌新完全指南》（原文地址：[https://huggingface.co/blog/noob_intro_transformers](https://huggingface.co/blog/noob_intro_transformers)）的格式行文的，依照这种上下文关联的问答模式去梳理一些技术发展的脉络，主要是为了加深理解。

本文主要是针对 RAG 技术的通识性展开，也是笔者在学习它的一些论文或开源项目之后的一个自我问答和记录总结，主要是为了能通俗理解一些技术演进的方式，这里把这个路径记录下来，希望为背景与我相似的学习者提供一个参考。

## RAG 与 微调？
首先看看面对大模型的一些问题，通常情况下提出的两个解决思路，RAG 和微调，它们的区别是什么？简单来说就 RAG 可以理解成是对照的书本找答案，微调是针对答案去学习。

| 特征比较 | RAG | 微调 |
| --- | --- | --- |
| 知识更新 | 直接更新检索知识库，无需重新训练。信息更新成本低，适合动态变化的数据。 | 通常需要重新训练来保持知识和数据的更新。更新成本高，适合静态数据。 |
| 外部知识 | 擅长利用外部资源，特别适合处理文档或其他结构化/非结构化数据库。 | 将外部知识学习到 LLM 内部。 |
| 数据处理 | 对数据的处理和操作要求极低。 | 依赖于构建高质量的数据集，有限的数据集可能无法显著提高性能。 |
| 模型定制 | 侧重于信息检索和融合外部知识，但可能无法充分定制模型行为或写作风格。 | 可以根据特定风格或术语调整 LLM 行为、写作风格或特定领域知识。 |
| 可解释性 | 可以追溯到具体的数据来源，有较好的可解释性和可追踪性。 | 黑盒子，可解释性相对较低。 |
| 计算资源 | 需要额外的资源来支持检索机制和数据库的维护。 | 依赖高质量的训练数据集和微调目标，对计算资源的要求较高。 |
| 推理延迟 | 增加了检索步骤的耗时 | 单纯 LLM 生成的耗时 |
| 降低幻觉 | 通过检索到的真实信息生成回答，降低了产生幻觉的概率。 | 模型学习特定领域的数据有助于减少幻觉，但面对未见过的输入时仍可能出现幻觉。 |
| 伦理隐私 | 检索和使用外部数据可能引发伦理和隐私方面的问题。 | 训练数据中的敏感信息需要妥善处理，以防泄露。 |


## RAG是什么？
从上文可以看出，RAG 的诞生就是其实为了尽量补充大模型的一些缺点，简单概括一下基础的 RAG 它的几个阶段：

1. 检索（Retrieval）：从外部知识库中检索与用户查询相关的信息。
2. 增强（Augmentation）：将检索到的信息与模型的内部知识结合起来，构建上下文。
3. 生成（Generation）：基于增强后的上下文，生成最终的回答。

![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/2639475/1744854357136-1932bbac-b0a3-447c-aab4-044c509e8aa2.jpeg)

## 基于文档检索的 RAG 有什么缺点？
但基础的 RAG 技术还是有缺陷，从上面的步骤拆解去看，就能发现：

1. 它难以容纳多模态数据。
2. 检索到的上下文可能不够精准，导致生成的回答不够准确。
3. 对于复杂的跨文档推理任务，传统 RAG 方法可能表现不足。
4. 需要维护一个庞大的知识库，增加了存储和计算成本。

![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/2639475/1744768904192-f65eda2c-e8d1-4e1e-978b-4c97ddba5c2f.jpeg)

## 如何优化 RAG？
那针对这些缺点再往前衍生，探索 RAG 与其他技术结合的方式，能不能继续增强 RAG 的能力，有几篇论文来介绍这种衍生，这里可以举几个例子如下。

## T-RAG 是什么？
它的全称是 Tree-RAG（T-RAG），将检索增强生成（RAG）与经过微调的开源大型语言模型（LLM）相结合，以生成响应。具体来说，T-RAG 在检索过程中，利用实体树来增强从向量数据库检索到的上下文。所以相比 RAG，它结合了树形结构，利用内部实体树增强上下文信息，适用与更复杂的场景。‌

它的原理简单概括就是：

1. 实体检测：用户查询前扫描查询内容，识别出与组织内实体名称相对应的关键字。
2. 实体信息提取：从实体树中提取与匹配实体相关的详细信息。
3. 上下文构建：将实体信息与从向量数据库检索到的文档块合并，构建更全面的上下文。
4. 生成回答：基于增强后的上下文，生成最终的回答。

所以论文里有一个等式就是：T-RAG=RAG+微调+实体检测

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1737698399245-a38c8d67-365a-4df3-9b4f-4424ce464ea1.png?x-oss-process=image%2Fformat%2Cwebp)

## GraphRAG 是什么？
如果说 T-RAG 是通过实体树增强，那 GraphRAG 就是通过整合知识图谱（KG）来增强 RAG。这里引入一个新概念知识图谱，它是一种基于关系存储和链接相关或不相关数据的数据结构，简单理解就是知识的动态网络。

它的原理简单概括就是：

1. 索引过程：将文档中的实体和关系提取出来，构建知识图谱。
2. 查询过程：在检索时，利用知识图谱中的关系信息，跨文档传播信息，生成更准确的回答

附上论文中对这个过程的概括：

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1737699550986-999a8b06-f235-4eeb-9d0f-ea5a83afe7bc.png?x-oss-process=image%2Fformat%2Cwebp)

## HippoRAG 是什么
关于构建图的还有另一个代表，就是 HippoRAG，它是一种受大脑海马体启发的 RAG 变体，旨在帮助大型语言模型跨段落整合新知识。它是一个受神经生物学启发的大语言模型长期记忆框架，各个组件均旨在模拟人类记忆的不同侧面。主要由三个部分构成：人工新皮层（LLM）、旁海马区域（PHR 编码器）以及人工海马（开放知识图谱，Open KG）。就是图中的这 3 个大脑。

下面的过程就是它的检索原理：分两个路径，一是离线索引，LLM 将文段处理为知识图谱三元组，并将其整合到人工海马索引中；同时，PHR 负责检测同义关系以实现信息互联。二是在线检索，LLM（作为人工新皮层）从查询中抽取命名实体，而 PHR 编码器则将这些实体链接到海马索引上。随后，对知识图谱应用个性化 PageRank（PPR）算法，进行基于语境的检索。

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1744876102325-625a2a2b-aec6-485a-9884-df6b6fb62fb3.png)

简单示例：

+ 查询：寻找一位从事阿尔茨海默症研究的斯坦福教授。
+ 传统 RAG：可能需要一个段落同时提到“斯坦福教授”和“阿尔茨海默症”才能识别出相关信息。
+ HippoRAG：通过关联图将“斯坦福教授”和“阿尔茨海默症”相关联，从而识别出托马斯教授。

![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/2639475/1744876090737-3bc72677-5252-432d-b3d9-f761963fa95b.jpeg)

## GraphRAG 类的缺点？
1. 依赖开放信息抽取方法，引入了大量的数据噪声，知识精准度差。
2. 使用图结构实现跨文档的信息传播，缓解了向量召回的不足。例如需要多跳、复杂逻辑依然存在不足。LLMs推理能力有限。
3. 检索到错误。噪声的信息后生成错误答案，仍然可能存在幻觉。
4. GraphRAG 运行速度非常慢，因为它需要多个 LLM API 调用，可能会达到速率限制。
5. 成本极高
6. 以实体为中心的方法在索引和推理过程中导致语境信息的丢失，并且在语义匹配上存在困难。

![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/2639475/1744770959990-d2c02483-07d8-428c-816e-1cb6c88e856c.jpeg)

## KAG是什么？
KAG（Knowledge-Augmented Generation，知识增强生成）是一种结合知识图谱和生成模型的技术，通过引入结构化的知识，提升生成内容的准确性和相关性。

KAG 的核心功能包括：

1. 知识与 Chunk 互索引结构，以整合更丰富的上下文文本信息
2. 利用概念语义推理进行知识对齐，缓解 OpenIE 引入的噪音问题
3. 支持 Schema-Constraint 知识构建，支持领域专家知识的表示与构建
4. 逻辑符号引导的混合推理与检索，实现逻辑推理和多跳推理问答

可以看下这个官方简图：

看起来是 KBQA+HippoRAG 结合产出的一种技术，先看一下 KBQA 是什么

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1744706093639-d3cc7c73-ffcf-457d-a8f1-4e5329527aab.png)

## KBQA 是什么？
知识图谱问答（Knowledge-based Question Answering, KBQA）是指给定自然语言问题，通过对问题进行语义理解和解析，进而利用知识库进行查询、推理得出答案。

传统的基于搜索引擎的问答系统只能返回一些时效性的网页，以文档集合的形式呈现给用户，仍然需要用户阅读并分析文档以获取答案。而基于知识图谱的问答系统可以实现获取到更精确的答案，即在知识图谱中找到精确答案直接返回给用户，满足用户的精确信息需求，提供个性化知识服务。

![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/2639475/1744854841613-06d1e124-7f0a-4515-bbca-4cae64d09504.jpeg)

## KBQA 的缺点？
那 KBQA 有什么问题？

1. 依赖高质量的知识图谱，图谱构建门槛高，高质量的知识图谱需要大量人力
2. 信息损失大，知识图谱中只包含了实体、关系、属性等，相对信息丰富的原始文本，信息损失较大
3. 可阅读性差，生成的答案包含关键事实，上下文信息较少

![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/2639475/1744771197807-b00d0575-427e-4ece-84c6-fb3c83fe2045.jpeg)

## KAG 是怎么解决这些问题的？
这个图其实很好的说明了 KAG 的思路，就是在KBQA+HippoRAG情况下，再重点强调推理，所以它也重点强调它是应用于垂直问答领域，特点是：

1. 兼容强Schema专业知识和弱Schema开放信息
2. 图结构知识与文本知识的互索引结构
3. 专业领域可平滑调节的专业决策与信息检索, 丰富知识完备性
4. 通过开放信息+结构化构建做知识语义对齐，平衡信息抽取(低门槛)与专业构建，缓解开放信息抽取引入的噪声问题

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1744854164644-7b334f05-338c-48f4-adad-ac4c9b0ac6bb.png)

## HippoRAG2 是什么？
当然技术发展非常快速，重新搜索HippoRAG 的时候，发现最近也出了HippoRAG2 ，相比其他技术表现非常优异，它与 HippoRAG 1 相比在结构上遵循类似的离线索引与在线检索两阶段流程，但在此基础上引入了几个关键改进，以更好地契合人类记忆机制：

1. 无缝整合开放知识图谱中的概念信息与语境信息，提升索引的完整性和粒度；
2. 利用知识图谱结构中超出单一节点的信息，促进了更具语境敏感性的检索；
3. 引入了识别记忆机制，以改善图搜索中种子节点的选择。

![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1744855166355-88629b39-1143-425e-9aeb-8d4a67b700f7.png)

## 小结
还有很多Advanced RAG 感兴趣可以自己去看一下，比如，LightRAG、PIKE-RAG 等等，后续有机会再展开，本文参考文档如下：

1. TRAG 论文地址：[https://arxiv.org/abs/2402.07483](https://arxiv.org/abs/2402.07483)
2. GraphRAG 论文地址：[https://arxiv.org/pdf/2404.16130](https://arxiv.org/pdf/2404.16130)
3. HippoRAG 论文地址：[https://arxiv.org/pdf/2405.14831](https://arxiv.org/pdf/2405.14831)
4. HippoRAG2  论文地址：[https://arxiv.org/pdf/2502.14802](https://arxiv.org/pdf/2502.14802)
5. KAG 论文地址： [https://arxiv.org/pdf/2409.13731](https://arxiv.org/pdf/2409.13731)
6. KAG 的 github：[https://github.com/OpenSPG/KAG/blob/master/README_cn.md](https://github.com/OpenSPG/KAG/blob/master/README_cn.md)
7. KAG 的用户手册：[https://openspg.yuque.com/ndx6g9/0.6/quzq24g4esal7q17#JQH6Y](https://openspg.yuque.com/ndx6g9/0.6/quzq24g4esal7q17#JQH6Y)
8. 其他参考图片：![](https://cdn.nlark.com/yuque/0/2025/png/2639475/1744878555905-1779bda7-2b20-40ea-9825-d4a0c2117bce.png)

